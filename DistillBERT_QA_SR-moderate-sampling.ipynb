{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1b83d5d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d590e20c053e42feb20ed00f5245c503",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from huggingface_hub import notebook_login\n",
    "notebook_login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "388b8dd6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda:0 device\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'4.35.0'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForQuestionAnswering, TrainingArguments, Trainer, default_data_collator\n",
    "from datasets import load_dataset, load_metric, ClassLabel, Sequence\n",
    "import transformers\n",
    "import pandas as pd\n",
    "from IPython.display import display, HTML\n",
    "import random\n",
    "import numpy as np\n",
    "import collections\n",
    "from transformers import MarianMTModel, MarianTokenizer\n",
    "from tqdm.auto import tqdm\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Check if GPU is available\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using {device} device\")\n",
    "\n",
    "transformers.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "42ed6018",
   "metadata": {},
   "outputs": [],
   "source": [
    "squad_v2 = True\n",
    "model_checkpoint = \"distilbert-base-uncased\"\n",
    "batch_size = 32\n",
    "max_length = 384\n",
    "doc_stride = 128\n",
    "n_best_size = 20\n",
    "max_answer_length = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cc4f9b77",
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets1={}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7610dfcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets1['train'] = load_dataset(\"squad_v2\", split='train[:90%]' if squad_v2 else \"squad\")\n",
    "datasets1['validation'] = load_dataset(\"squad_v2\", split='train[90%:100%]' if squad_v2 else \"squad\")\n",
    "datasets1['test'] = load_dataset(\"squad_v2\", split='validation' if squad_v2 else \"squad\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7f5e9d24",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import Dataset, DatasetDict\n",
    "datasets= DatasetDict(datasets1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "41e54044",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to /home/rabeea/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "from random import shuffle\n",
    "from tqdm import tqdm\n",
    "random.seed(1)\n",
    "import nltk\n",
    "nltk.download('wordnet')\n",
    "\n",
    "#stop words list\n",
    "stop_words = ['i', 'me', 'my', 'myself', 'we', 'our',\n",
    "\t\t\t'ours', 'ourselves', 'you', 'your', 'yours',\n",
    "\t\t\t'yourself', 'yourselves', 'he', 'him', 'his',\n",
    "\t\t\t'himself', 'she', 'her', 'hers', 'herself',\n",
    "\t\t\t'it', 'its', 'itself', 'they', 'them', 'their',\n",
    "\t\t\t'theirs', 'themselves', 'what', 'which', 'who',\n",
    "\t\t\t'whom', 'this', 'that', 'these', 'those', 'am',\n",
    "\t\t\t'is', 'are', 'was', 'were', 'be', 'been', 'being',\n",
    "\t\t\t'have', 'has', 'had', 'having', 'do', 'does', 'did',\n",
    "\t\t\t'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or',\n",
    "\t\t\t'because', 'as', 'until', 'while', 'of', 'at',\n",
    "\t\t\t'by', 'for', 'with', 'about', 'against', 'between',\n",
    "\t\t\t'into', 'through', 'during', 'before', 'after',\n",
    "\t\t\t'above', 'below', 'to', 'from', 'up', 'down', 'in',\n",
    "\t\t\t'out', 'on', 'off', 'over', 'under', 'again',\n",
    "\t\t\t'further', 'then', 'once', 'here', 'there', 'when',\n",
    "\t\t\t'where', 'why', 'how', 'all', 'any', 'both', 'each',\n",
    "\t\t\t'few', 'more', 'most', 'other', 'some', 'such', 'no',\n",
    "\t\t\t'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too',\n",
    "\t\t\t'very', 's', 't', 'can', 'will', 'just', 'don',\n",
    "\t\t\t'should', 'now', '']\n",
    "\n",
    "#cleaning up text\n",
    "import re\n",
    "def get_only_chars(line):\n",
    "\n",
    "    clean_line = \"\"\n",
    "\n",
    "    line = line.replace(\"’\", \"\")\n",
    "    line = line.replace(\"'\", \"\")\n",
    "    line = line.replace(\"-\", \" \") #replace hyphens with spaces\n",
    "    line = line.replace(\"\\t\", \" \")\n",
    "    line = line.replace(\"\\n\", \" \")\n",
    "    line = line.lower()\n",
    "\n",
    "    for char in line:\n",
    "        if char in 'qwertyuiopasdfghjklzxcvbnm ':\n",
    "            clean_line += char\n",
    "        else:\n",
    "            clean_line += ' '\n",
    "\n",
    "    clean_line = re.sub(' +',' ',clean_line) #delete extra spaces\n",
    "    if clean_line[0] == ' ':\n",
    "        clean_line = clean_line[1:]\n",
    "    return clean_line\n",
    "\n",
    "########################################################################\n",
    "# Synonym replacement\n",
    "# Replace n words in the sentence with synonyms from wordnet\n",
    "########################################################################\n",
    "\n",
    "#for the first time you use wordnet\n",
    "#import nltk\n",
    "#nltk.download('wordnet')\n",
    "from nltk.corpus import wordnet\n",
    "\n",
    "def synonym_replacement(words, n):\n",
    "\tnew_words = words.copy()\n",
    "\trandom_word_list = list(set([word for word in words if word not in stop_words]))\n",
    "\trandom.shuffle(random_word_list)\n",
    "\tnum_replaced = 0\n",
    "\tfor random_word in random_word_list:\n",
    "\t\tsynonyms = get_synonyms(random_word)\n",
    "\t\tif len(synonyms) >= 1:\n",
    "\t\t\tsynonym = random.choice(list(synonyms))\n",
    "\t\t\tnew_words = [synonym if word == random_word else word for word in new_words]\n",
    "\t\t\t#print(\"replaced\", random_word, \"with\", synonym)\n",
    "\t\t\tnum_replaced += 1\n",
    "\t\tif num_replaced >= n: #only replace up to n words\n",
    "\t\t\tbreak\n",
    "\n",
    "\t#this is stupid but we need it, trust me\n",
    "\tsentence = ' '.join(new_words)\n",
    "\tnew_words = sentence.split(' ')\n",
    "\n",
    "\treturn new_words\n",
    "\n",
    "def get_synonyms(word):\n",
    "\tsynonyms = set()\n",
    "\tfor syn in wordnet.synsets(word):\n",
    "\t\tfor l in syn.lemmas():\n",
    "\t\t\tsynonym = l.name().replace(\"_\", \" \").replace(\"-\", \" \").lower()\n",
    "\t\t\tsynonym = \"\".join([char for char in synonym if char in ' qwertyuiopasdfghjklzxcvbnm'])\n",
    "\t\t\tsynonyms.add(synonym)\n",
    "\tif word in synonyms:\n",
    "\t\tsynonyms.remove(word)\n",
    "\treturn list(synonyms)\n",
    "\n",
    "########################################################################\n",
    "# Random deletion\n",
    "# Randomly delete words from the sentence with probability p\n",
    "########################################################################\n",
    "\n",
    "def random_deletion(words, p):\n",
    "\n",
    "\t#obviously, if there's only one word, don't delete it\n",
    "\tif len(words) == 1:\n",
    "\t\treturn words\n",
    "\n",
    "\t#randomly delete words with probability p\n",
    "\tnew_words = []\n",
    "\tfor word in words:\n",
    "\t\tr = random.uniform(0, 1)\n",
    "\t\tif r > p:\n",
    "\t\t\tnew_words.append(word)\n",
    "\n",
    "\t#if you end up deleting all words, just return a random word\n",
    "\tif len(new_words) == 0:\n",
    "\t\trand_int = random.randint(0, len(words)-1)\n",
    "\t\treturn [words[rand_int]]\n",
    "\n",
    "\treturn new_words\n",
    "\n",
    "########################################################################\n",
    "# Random swap\n",
    "# Randomly swap two words in the sentence n times\n",
    "########################################################################\n",
    "\n",
    "def random_swap(words, n):\n",
    "\tnew_words = words.copy()\n",
    "\tfor _ in range(n):\n",
    "\t\tnew_words = swap_word(new_words)\n",
    "\treturn new_words\n",
    "\n",
    "def swap_word(new_words):\n",
    "\trandom_idx_1 = random.randint(0, len(new_words)-1)\n",
    "\trandom_idx_2 = random_idx_1\n",
    "\tcounter = 0\n",
    "\twhile random_idx_2 == random_idx_1:\n",
    "\t\trandom_idx_2 = random.randint(0, len(new_words)-1)\n",
    "\t\tcounter += 1\n",
    "\t\tif counter > 3:\n",
    "\t\t\treturn new_words\n",
    "\tnew_words[random_idx_1], new_words[random_idx_2] = new_words[random_idx_2], new_words[random_idx_1]\n",
    "\treturn new_words\n",
    "\n",
    "########################################################################\n",
    "# Random insertion\n",
    "# Randomly insert n words into the sentence\n",
    "########################################################################\n",
    "\n",
    "def random_insertion(words, n):\n",
    "\tnew_words = words.copy()\n",
    "\tfor _ in range(n):\n",
    "\t\tadd_word(new_words)\n",
    "\treturn new_words\n",
    "\n",
    "def add_word(new_words):\n",
    "\tsynonyms = []\n",
    "\tcounter = 0\n",
    "\twhile len(synonyms) < 1:\n",
    "\t\trandom_word = new_words[random.randint(0, len(new_words)-1)]\n",
    "\t\tsynonyms = get_synonyms(random_word)\n",
    "\t\tcounter += 1\n",
    "\t\tif counter >= 10:\n",
    "\t\t\treturn\n",
    "\trandom_synonym = synonyms[0]\n",
    "\trandom_idx = random.randint(0, len(new_words)-1)\n",
    "\tnew_words.insert(random_idx, random_synonym)\n",
    "\n",
    "########################################################################\n",
    "# main data augmentation function\n",
    "########################################################################\n",
    "\n",
    "def eda(sentences, alpha_sr=0.1):\n",
    "\taugmented_sentences=[]\n",
    "\tfor i in tqdm(range(len(sentences))):\n",
    "\t\tsentence = get_only_chars(sentences[i])\n",
    "\t\twords = sentence.split(' ')\n",
    "\t\twords = [word for word in words if word != '']\n",
    "\t\tnum_words = len(words)\n",
    "\t\t#sr\n",
    "\t\tif (alpha_sr > 0):\n",
    "\t\t\tn_sr = max(1, int(alpha_sr*num_words))\n",
    "\t\t\ta_words = synonym_replacement(words, n_sr)\n",
    "\t\t\taugmented_sentences.append(' '.join(a_words)+'?')\n",
    "\n",
    "\treturn augmented_sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "16f46285",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['id', 'title', 'context', 'question', 'answers'],\n",
       "    num_rows: 4907\n",
       "})"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import load_from_disk\n",
    "\n",
    "# Load the saved dataset\n",
    "sampled_data = load_from_disk(\"dataset_moderate\")\n",
    "sampled_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "53d19117",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply back translation to the context and question in the SQuAD dataset\n",
    "context_texts = sampled_data[\"context\"]\n",
    "question_texts = sampled_data[\"question\"]\n",
    "answer_texts= sampled_data['answers']\n",
    "id_texts= sampled_data['id']\n",
    "title_texts= sampled_data['title']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "44fa941f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████| 4907/4907 [00:03<00:00, 1596.59it/s]\n"
     ]
    }
   ],
   "source": [
    "# Translate from English to French\n",
    "# context_translations = back_translate(context_texts, model, tokenizer)\n",
    "question_translations = eda(question_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a37da035",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create augmented dataset with back-translated context, questions, and answers\n",
    "augmented_dataset = {\n",
    "    \"context\": context_texts,\n",
    "    \"question\": question_translations,\n",
    "    \"answers\": answer_texts,  # Add this line\n",
    "    \"id\": id_texts,\n",
    "    \"title\": title_texts,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c430b1ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optionally, you can combine the original and augmented datasets\n",
    "combined_dataset = {\n",
    "    \"context\": datasets[\"train\"][\"context\"]+context_texts,\n",
    "    \"question\": datasets[\"train\"][\"question\"] + question_translations,\n",
    "    \"answers\": datasets[\"train\"][\"answers\"] + answer_texts,\n",
    "    \"id\":datasets[\"train\"][\"id\"] + id_texts,\n",
    "    \"title\":datasets[\"train\"][\"title\"]+ title_texts\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3cce7943",
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets['train'] = Dataset.from_dict(combined_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0e3bb117",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['context', 'question', 'answers', 'id', 'title'],\n",
       "        num_rows: 122194\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['id', 'title', 'context', 'question', 'answers'],\n",
       "        num_rows: 13032\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['id', 'title', 'context', 'question', 'answers'],\n",
       "        num_rows: 11873\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9217b06b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['id', 'title', 'context', 'question', 'answers'],\n",
       "    num_rows: 13032\n",
       "})"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datasets[\"validation\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "62fc7743",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show random elements in the dataset\n",
    "def show_random_elements(dataset, num_examples=10):\n",
    "    assert num_examples <= len(dataset), \"Can't pick more elements than there are in the dataset.\"\n",
    "    picks = []\n",
    "    for _ in range(num_examples):\n",
    "        pick = random.randint(0, len(dataset)-1)\n",
    "        while pick in picks:\n",
    "            pick = random.randint(0, len(dataset)-1)\n",
    "        picks.append(pick)\n",
    "\n",
    "    df = pd.DataFrame(dataset[picks])\n",
    "    for column, typ in dataset.features.items():\n",
    "        if isinstance(typ, ClassLabel):\n",
    "            df[column] = df[column].transform(lambda i: typ.names[i])\n",
    "        elif isinstance(typ, Sequence) and isinstance(typ.feature, ClassLabel):\n",
    "            df[column] = df[column].transform(lambda x: [typ.feature.names[i] for i in x])\n",
    "    display(HTML(df.to_html()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a6081a4b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>context</th>\n",
       "      <th>question</th>\n",
       "      <th>answers</th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Brigham Young University's origin can be traced back to 1862 when a man named Warren Dusenberry started a Provo school in a prominent adobe building called Cluff Hall, which was located in the northeast corner of 200 East and 200 North. On October 16, 1875, Brigham Young, then president of the LDS Church, personally purchased the Lewis Building after previously hinting that a school would be built in Draper, Utah in 1867. Hence, October 16, 1875 is commonly held as BYU's founding date. Said Young about his vision: \"I hope to see an Academy established in Provo... at which the children of the Latter-day Saints can receive a good education unmixed with the pernicious atheistic influences that are found in so many of the higher schools of the country.\"</td>\n",
       "      <td>What type of influences did Brigham Young hope to avoid with BYU?</td>\n",
       "      <td>{'answer_start': [674], 'text': ['atheistic']}</td>\n",
       "      <td>572826ce2ca10214002d9f42</td>\n",
       "      <td>Brigham_Young_University</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Virgil's biographical tradition is thought to depend on a lost biography by Varius, Virgil's editor, which was incorporated into the biography by Suetonius and the commentaries of Servius and Donatus, the two great commentators on Virgil's poetry. Although the commentaries no doubt record much factual information about Virgil, some of their evidence can be shown to rely on inferences made from his poetry and allegorizing; thus, Virgil's biographical tradition remains problematic.</td>\n",
       "      <td>Who was Virgil's editor?</td>\n",
       "      <td>{'answer_start': [76], 'text': ['Varius']}</td>\n",
       "      <td>56f7fd15a6d7ea1400e1735f</td>\n",
       "      <td>Virgil</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The Commander-in-Chief of the Canadian Armed Forces is the reigning Canadian monarch, Queen Elizabeth II, who is represented by the Governor General of Canada. The Canadian Armed Forces is led by the Chief of the Defence Staff, who is advised and assisted by the Armed Forces Council.</td>\n",
       "      <td>Who currently is the Assistant-in-Chief of the Canadian Armed Forces?</td>\n",
       "      <td>{'answer_start': [], 'text': []}</td>\n",
       "      <td>5ad3e076604f3c001a3ff4b7</td>\n",
       "      <td>Canadian_Armed_Forces</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The higher-level phylogeny of the arthropods continues to be a matter of debate and research. In 2008, researchers at Tufts University uncovered what they believe is the world's oldest known full-body impression of a primitive flying insect, a 300 million-year-old specimen from the Carboniferous period. The oldest definitive insect fossil is the Devonian Rhyniognatha hirsti, from the 396-million-year-old Rhynie chert. It may have superficially resembled a modern-day silverfish insect. This species already possessed dicondylic mandibles (two articulations in the mandible), a feature associated with winged insects, suggesting that wings may already have evolved at this time. Thus, the first insects probably appeared earlier, in the Silurian period.</td>\n",
       "      <td>What kind of impression has been uncovered by a University?</td>\n",
       "      <td>{'answer_start': [191], 'text': ['full-body']}</td>\n",
       "      <td>572921ae6aef051400154a82</td>\n",
       "      <td>Insect</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>In one-party systems, one political party is legally allowed to hold effective power. Although minor parties may sometimes be allowed, they are legally required to accept the leadership of the dominant party. This party may not always be identical to the government, although sometimes positions within the party may in fact be more important than positions within the government. North Korea and China are examples; others can be found in Fascist states, such as Nazi Germany between 1934 and 1945. The one-party system is thus usually equated with dictatorships and tyranny.</td>\n",
       "      <td>During what years did North Korea move to a one party system?</td>\n",
       "      <td>{'answer_start': [], 'text': []}</td>\n",
       "      <td>5a73b29142eae6001a38997d</td>\n",
       "      <td>Political_party</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>The eligible age-range for contestants is currently fifteen to twenty-eight years old. The initial age limit was sixteen to twenty-four in the first three seasons, but the upper limit was raised to twenty-eight in season four, and the lower limit was reduced to fifteen in season ten. The contestants must be legal U.S. residents, cannot have advanced to particular stages of the competition in previous seasons (varies depending on the season, currently by the semi-final stage until season thirteen), and must not hold any current recording or talent representation contract by the semi-final stage (in previous years by the audition stage).</td>\n",
       "      <td>Currently, contestants can not have a recording track by what stage of the competition?</td>\n",
       "      <td>{'answer_start': [462], 'text': ['semi-final stage']}</td>\n",
       "      <td>56daf3c0e7c41114004b4b8b</td>\n",
       "      <td>American_Idol</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>At present the A35 autoroute, which parallels the Rhine between Karlsruhe and Basel, and the A4 autoroute, which links Paris with Strasbourg, penetrate close to the centre of the city. The Grand contournement ouest (GCO) project, programmed since 1999, plans to construct a 24 km (15 mi) long highway connection between the junctions of the A4 and the A35 autoroutes in the north and of the A35 and A352 autoroutes in the south. This routes well to the west of the city and is meant to divest a significant portion of motorized traffic from the unité urbaine.</td>\n",
       "      <td>How long is the Rhine?</td>\n",
       "      <td>{'answer_start': [], 'text': []}</td>\n",
       "      <td>5acd751c07355d001abf4344</td>\n",
       "      <td>Strasbourg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>In November 2013, Somalia received its first fiber optic connection. The country previously had to rely on expensive satellite links due to the civil conflict, which limited internet usage. However, residents now have access to broadband internet cable for the first time after an agreement reached between Hormuud Telecom and Liquid Telecom. The deal will see Liquid Telecom link Hormuud to its 17,000 km (10,500 mile) network of terrestrial cables, which will deliver faster internet capacity. The fiber optic connection will also make online access more affordable to the average user. This in turn is expected to further increase the number of internet users. Dalkom Somalia reached a similar agreement with the West Indian Ocean Cable Company (WIOCC) Ltd, which it holds shares in. Effective the first quarter of 2014, the deal will establish fiber optic connectivity to and from Somalia via the EASSy cable. The new services are expected to reduce the cost of international bandwidth and to better optimize performance, thereby further broadening internet access. Dalkom Somalia is concurrently constructing a 1,000 square mile state-of-the-art data center in Mogadishu. The site will facilitate direct connection into the international fiber optic network by hosting equipment for all of the capital's ISPs and telecommunication companies.</td>\n",
       "      <td>in 2013, an agreement between Hormuud Telecom and Liquid Telecom provided residents access to what type of cable provider?</td>\n",
       "      <td>{'answer_start': [228], 'text': ['broadband']}</td>\n",
       "      <td>56e1ce38e3433e14004231af</td>\n",
       "      <td>Communications_in_Somalia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Old English developed from a set of Anglo-Frisian or North Sea Germanic dialects originally spoken by Germanic tribes traditionally known as the Angles, Saxons, and Jutes. As the Anglo-Saxons became dominant in England, their language replaced the languages of Roman Britain: Common Brittonic, a Celtic language, and Latin, brought to Britain by Roman invasion. Old English had four main dialects, associated with particular Anglo-Saxon kingdoms: Mercian, Northumbrian, Kentish and West Saxon. It was West Saxon that formed the basis for the literary standard of the later Old English period, although the dominant forms of Middle and Modern English would develop mainly from Mercian. The speech of eastern and northern parts of England was subject to strong Old Norse influence due to Scandinavian rule and settlement beginning in the 9th century.</td>\n",
       "      <td>What people ruled the eastern and northern parts of England beginning in the 900's?</td>\n",
       "      <td>{'answer_start': [], 'text': []}</td>\n",
       "      <td>5a676f6df038b7001ab0c235</td>\n",
       "      <td>Old_English</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>It has been mentioned that most nonprofits will never be able to match the pay of the private sector and therefore should focus their attention on benefits packages, incentives and implementing pleasurable work environments. Pleasurable work conditions are ranked as being more preferable than a high salary and implacable work. NPOs are encouraged to pay as much as they are able, and offer a low stress work environment that the employee can associate him or herself positively with. Other incentives that should be implemented are generous vacation allowances or flexible work hours.</td>\n",
       "      <td>What will the private sector never be able to match compared to NPO's</td>\n",
       "      <td>{'answer_start': [], 'text': []}</td>\n",
       "      <td>5a45a3e619a820001a1edad8</td>\n",
       "      <td>Nonprofit_organization</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_random_elements(datasets[\"train\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c109ba4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize tokenizer and model\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "00a8d5b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert isinstance(tokenizer, transformers.PreTrainedTokenizerFast)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d4e400e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [101, 2054, 2003, 2115, 2171, 1029, 102, 2026, 2171, 2003, 19538, 4430, 1012, 102], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer(\"What is your name?\", \"My name is Minhah.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9e537a85",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, example in enumerate(datasets[\"train\"]):\n",
    "    if len(tokenizer(example[\"question\"], example[\"context\"])[\"input_ids\"]) > 384:\n",
    "        break\n",
    "example = datasets[\"train\"][i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8e8087f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "437"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tokenizer(example[\"question\"], example[\"context\"])[\"input_ids\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e1783567",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "384"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tokenizer(example[\"question\"], example[\"context\"], max_length=max_length, truncation=\"only_second\")[\"input_ids\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ed85484d",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_example = tokenizer(\n",
    "    example[\"question\"],\n",
    "    example[\"context\"],\n",
    "    max_length=max_length,\n",
    "    truncation=\"only_second\",\n",
    "    return_overflowing_tokens=True,\n",
    "    stride=doc_stride\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2772a935",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[384, 192]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[len(x) for x in tokenized_example[\"input_ids\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f9aa1df1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CLS] beyonce got married in 2008 to whom? [SEP] on april 4, 2008, beyonce married jay z. she publicly revealed their marriage in a video montage at the listening party for her third studio album, i am... sasha fierce, in manhattan's sony club on october 22, 2008. i am... sasha fierce was released on november 18, 2008 in the united states. the album formally introduces beyonce's alter ego sasha fierce, conceived during the making of her 2003 single \" crazy in love \", selling 482, 000 copies in its first week, debuting atop the billboard 200, and giving beyonce her third consecutive number - one album in the us. the album featured the number - one song \" single ladies ( put a ring on it ) \" and the top - five songs \" if i were a boy \" and \" halo \". achieving the accomplishment of becoming her longest - running hot 100 single in her career, \" halo \"'s success in the us helped beyonce attain more top - ten singles on the list than any other woman during the 2000s. it also included the successful \" sweet dreams \", and singles \" diva \", \" ego \", \" broken - hearted girl \" and \" video phone \". the music video for \" single ladies \" has been parodied and imitated around the world, spawning the \" first major dance craze \" of the internet age according to the toronto star. the video has won several awards, including best video at the 2009 mtv europe music awards, the 2009 scottish mobo awards, and the 2009 bet awards. at the 2009 mtv video music awards, the video was nominated for nine awards, ultimately winning three including video of the year. its failure to win the best female video category, which went to american country pop singer taylor swift's \" you belong with me \", led to kanye west interrupting the ceremony and beyonce [SEP]\n",
      "[CLS] beyonce got married in 2008 to whom? [SEP] single ladies \" has been parodied and imitated around the world, spawning the \" first major dance craze \" of the internet age according to the toronto star. the video has won several awards, including best video at the 2009 mtv europe music awards, the 2009 scottish mobo awards, and the 2009 bet awards. at the 2009 mtv video music awards, the video was nominated for nine awards, ultimately winning three including video of the year. its failure to win the best female video category, which went to american country pop singer taylor swift's \" you belong with me \", led to kanye west interrupting the ceremony and beyonce improvising a re - presentation of swift's award during her own acceptance speech. in march 2009, beyonce embarked on the i am... world tour, her second headlining worldwide concert tour, consisting of 108 shows, grossing $ 119. 5 million. [SEP]\n"
     ]
    }
   ],
   "source": [
    "for x in tokenized_example[\"input_ids\"][:2]:\n",
    "    print(tokenizer.decode(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8c2537a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 0), (0, 7), (8, 11), (12, 19), (20, 22), (23, 27), (28, 30), (31, 35), (35, 36), (0, 0), (0, 2), (3, 8), (9, 10), (10, 11), (12, 16), (16, 17), (18, 25), (26, 33), (34, 37), (38, 39), (39, 40), (41, 44), (45, 53), (54, 62), (63, 68), (69, 77), (78, 80), (81, 82), (83, 88), (89, 93), (93, 96), (97, 99), (100, 103), (104, 113), (114, 119), (120, 123), (124, 127), (128, 133), (134, 140), (141, 146), (146, 147), (148, 149), (150, 152), (152, 153), (153, 154), (154, 155), (156, 161), (162, 168), (168, 169), (170, 172), (173, 182), (182, 183), (183, 184), (185, 189), (190, 194), (195, 197), (198, 205), (206, 208), (208, 209), (210, 214), (214, 215), (216, 217), (218, 220), (220, 221), (221, 222), (222, 223), (224, 229), (230, 236), (237, 240), (241, 249), (250, 252), (253, 261), (262, 264), (264, 265), (266, 270), (271, 273), (274, 277), (278, 284), (285, 291), (291, 292), (293, 296), (297, 302), (303, 311), (312, 322), (323, 330), (330, 331), (331, 332), (333, 338), (339, 342), (343, 348), (349, 355), (355, 356), (357, 366), (367, 373), (374, 377), (378, 384), (385, 387), (388, 391), (392, 396), (397, 403)]\n"
     ]
    }
   ],
   "source": [
    "tokenized_example = tokenizer(\n",
    "    example[\"question\"],\n",
    "    example[\"context\"],\n",
    "    max_length=max_length,\n",
    "    truncation=\"only_second\",\n",
    "    return_overflowing_tokens=True,\n",
    "    return_offsets_mapping=True,\n",
    "    stride=doc_stride\n",
    ")\n",
    "print(tokenized_example[\"offset_mapping\"][0][:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "34173c5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "beyonce Beyonce\n"
     ]
    }
   ],
   "source": [
    "first_token_id = tokenized_example[\"input_ids\"][0][1]\n",
    "offsets = tokenized_example[\"offset_mapping\"][0][1]\n",
    "print(tokenizer.convert_ids_to_tokens([first_token_id])[0], example[\"question\"][offsets[0]:offsets[1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "36314b3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[None, 0, 0, 0, 0, 0, 0, 0, 0, None, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, None]\n"
     ]
    }
   ],
   "source": [
    "sequence_ids = tokenized_example.sequence_ids()\n",
    "print(sequence_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "7cb97250",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18 19\n"
     ]
    }
   ],
   "source": [
    "answers = example[\"answers\"]\n",
    "start_char = answers[\"answer_start\"][0]\n",
    "end_char = start_char + len(answers[\"text\"][0])\n",
    "\n",
    "# Start token index of the current span in the text.\n",
    "token_start_index = 0\n",
    "while sequence_ids[token_start_index] != 1:\n",
    "    token_start_index += 1\n",
    "\n",
    "# End token index of the current span in the text.\n",
    "token_end_index = len(tokenized_example[\"input_ids\"][0]) - 1\n",
    "while sequence_ids[token_end_index] != 1:\n",
    "    token_end_index -= 1\n",
    "\n",
    "# Detect if the answer is out of the span (in which case this feature is labeled with the CLS index).\n",
    "offsets = tokenized_example[\"offset_mapping\"][0]\n",
    "if (offsets[token_start_index][0] <= start_char and offsets[token_end_index][1] >= end_char):\n",
    "    # Move the token_start_index and token_end_index to the two ends of the answer.\n",
    "    # Note: we could go after the last offset if the answer is the last word (edge case).\n",
    "    while token_start_index < len(offsets) and offsets[token_start_index][0] <= start_char:\n",
    "        token_start_index += 1\n",
    "    start_position = token_start_index - 1\n",
    "    while offsets[token_end_index][1] >= end_char:\n",
    "        token_end_index -= 1\n",
    "    end_position = token_end_index + 1\n",
    "    print(start_position, end_position)\n",
    "else:\n",
    "    print(\"The answer is not in this feature.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ece5f036",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "jay z\n",
      "Jay Z\n"
     ]
    }
   ],
   "source": [
    "print(tokenizer.decode(tokenized_example[\"input_ids\"][0][start_position: end_position+1]))\n",
    "print(answers[\"text\"][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b78c7278",
   "metadata": {},
   "outputs": [],
   "source": [
    "pad_on_right = tokenizer.padding_side == \"right\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "89fce835",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForQuestionAnswering were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['qa_outputs.bias', 'qa_outputs.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DistilBertForQuestionAnswering(\n",
       "  (distilbert): DistilBertModel(\n",
       "    (embeddings): Embeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (transformer): Transformer(\n",
       "      (layer): ModuleList(\n",
       "        (0-5): 6 x TransformerBlock(\n",
       "          (attention): MultiHeadSelfAttention(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (ffn): FFN(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (activation): GELUActivation()\n",
       "          )\n",
       "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (qa_outputs): Linear(in_features=768, out_features=2, bias=True)\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       ")"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = AutoModelForQuestionAnswering.from_pretrained(model_checkpoint)\n",
    "\n",
    "# Move model to GPU\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "3413c9b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing the training data\n",
    "def prepare_train_features(examples):\n",
    "    examples[\"question\"] = [q.lstrip() for q in examples[\"question\"]]\n",
    "    tokenized_examples = tokenizer(\n",
    "        examples[\"question\" if tokenizer.padding_side == \"right\" else \"context\"],\n",
    "        examples[\"context\" if tokenizer.padding_side == \"right\" else \"question\"],\n",
    "        truncation=\"only_second\" if tokenizer.padding_side == \"right\" else \"only_first\",\n",
    "        max_length=max_length,\n",
    "        stride=doc_stride,\n",
    "        return_overflowing_tokens=True,\n",
    "        return_offsets_mapping=True,\n",
    "        padding=\"max_length\",\n",
    "    )\n",
    "    sample_mapping = tokenized_examples.pop(\"overflow_to_sample_mapping\")\n",
    "    tokenized_examples[\"start_positions\"] = []\n",
    "    tokenized_examples[\"end_positions\"] = []\n",
    "\n",
    "    for i, offsets in enumerate(tokenized_examples[\"offset_mapping\"]):\n",
    "        input_ids = tokenized_examples[\"input_ids\"][i]\n",
    "        cls_index = input_ids.index(tokenizer.cls_token_id)\n",
    "        sequence_ids = tokenized_examples.sequence_ids(i)\n",
    "        sample_index = sample_mapping[i]\n",
    "        answers = examples[\"answers\"][sample_index]\n",
    "\n",
    "        if len(answers[\"answer_start\"]) == 0:\n",
    "            tokenized_examples[\"start_positions\"].append(cls_index)\n",
    "            tokenized_examples[\"end_positions\"].append(cls_index)\n",
    "        else:\n",
    "            start_char = answers[\"answer_start\"][0]\n",
    "            end_char = start_char + len(answers[\"text\"][0])\n",
    "            token_start_index = 0\n",
    "            while sequence_ids[token_start_index] != (1 if tokenizer.padding_side == \"right\" else 0):\n",
    "                token_start_index += 1\n",
    "            token_end_index = len(input_ids) - 1\n",
    "            while sequence_ids[token_end_index] != (1 if tokenizer.padding_side == \"right\" else 0):\n",
    "                token_end_index -= 1\n",
    "\n",
    "            if not (offsets[token_start_index][0] <= start_char and offsets[token_end_index][1] >= end_char):\n",
    "                tokenized_examples[\"start_positions\"].append(cls_index)\n",
    "                tokenized_examples[\"end_positions\"].append(cls_index)\n",
    "            else:\n",
    "                while token_start_index < len(offsets) and offsets[token_start_index][0] <= start_char:\n",
    "                    token_start_index += 1\n",
    "                tokenized_examples[\"start_positions\"].append(token_start_index - 1)\n",
    "                while offsets[token_end_index][1] >= end_char:\n",
    "                    token_end_index -= 1\n",
    "                tokenized_examples[\"end_positions\"].append(token_end_index + 1)\n",
    "\n",
    "    return tokenized_examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "7d997eea",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = prepare_train_features(datasets['train'][:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "4eab5181",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9ac76eb040964176bf057413e0cbb01d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/122194 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Map training features to GPU\n",
    "tokenized_datasets = datasets.map(\n",
    "    prepare_train_features,\n",
    "    batched=True,\n",
    "    remove_columns=datasets[\"train\"].column_names\n",
    ")\n",
    "tokenized_datasets.set_format(type='torch', columns=['input_ids', 'attention_mask', 'start_positions', 'end_positions'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "ddc99e9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = model_checkpoint.split(\"/\")[-1]\n",
    "args = TrainingArguments(\n",
    "    f\"{model_name}-finetuned-squad\",\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    learning_rate=5e-5,\n",
    "    per_device_train_batch_size=batch_size,\n",
    "    per_device_eval_batch_size=batch_size,\n",
    "    num_train_epochs=5,\n",
    "    weight_decay=0.01,\n",
    "    push_to_hub=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "c0bc77ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_collator = default_data_collator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "0dece3f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define trainer\n",
    "trainer = Trainer(\n",
    "    model,\n",
    "    args,\n",
    "    train_dataset=tokenized_datasets[\"train\"],\n",
    "    eval_dataset=tokenized_datasets[\"validation\"],\n",
    "    data_collator=data_collator,\n",
    "    tokenizer=tokenizer,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "d387232a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rabeea/anaconda3/envs/tor/lib/python3.10/site-packages/torch/nn/parallel/data_parallel.py:32: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 0 which\n",
      "    has less than 75% of the memory or cores of GPU 1. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n",
      "/home/rabeea/anaconda3/envs/tor/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='9655' max='9655' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [9655/9655 2:52:57, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.304400</td>\n",
       "      <td>1.197179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.937100</td>\n",
       "      <td>1.198592</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.684900</td>\n",
       "      <td>1.169251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.495500</td>\n",
       "      <td>1.299047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.376100</td>\n",
       "      <td>1.467484</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rabeea/anaconda3/envs/tor/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/home/rabeea/anaconda3/envs/tor/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/home/rabeea/anaconda3/envs/tor/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/home/rabeea/anaconda3/envs/tor/lib/python3.10/site-packages/torch/nn/parallel/data_parallel.py:32: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 0 which\n",
      "    has less than 75% of the memory or cores of GPU 1. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n",
      "/home/rabeea/anaconda3/envs/tor/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/home/rabeea/anaconda3/envs/tor/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/home/rabeea/anaconda3/envs/tor/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/home/rabeea/anaconda3/envs/tor/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/home/rabeea/anaconda3/envs/tor/lib/python3.10/site-packages/torch/nn/parallel/data_parallel.py:32: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 0 which\n",
      "    has less than 75% of the memory or cores of GPU 1. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n",
      "/home/rabeea/anaconda3/envs/tor/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/home/rabeea/anaconda3/envs/tor/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/home/rabeea/anaconda3/envs/tor/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/home/rabeea/anaconda3/envs/tor/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/home/rabeea/anaconda3/envs/tor/lib/python3.10/site-packages/torch/nn/parallel/data_parallel.py:32: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 0 which\n",
      "    has less than 75% of the memory or cores of GPU 1. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n",
      "/home/rabeea/anaconda3/envs/tor/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/home/rabeea/anaconda3/envs/tor/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/home/rabeea/anaconda3/envs/tor/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/home/rabeea/anaconda3/envs/tor/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/home/rabeea/anaconda3/envs/tor/lib/python3.10/site-packages/torch/nn/parallel/data_parallel.py:32: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 0 which\n",
      "    has less than 75% of the memory or cores of GPU 1. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n",
      "/home/rabeea/anaconda3/envs/tor/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/home/rabeea/anaconda3/envs/tor/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/home/rabeea/anaconda3/envs/tor/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/home/rabeea/anaconda3/envs/tor/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/home/rabeea/anaconda3/envs/tor/lib/python3.10/site-packages/torch/nn/parallel/data_parallel.py:32: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 0 which\n",
      "    has less than 75% of the memory or cores of GPU 1. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=9655, training_loss=0.8090439158853998, metrics={'train_runtime': 10388.0388, 'train_samples_per_second': 59.47, 'train_steps_per_second': 0.929, 'total_flos': 6.05356641542016e+16, 'train_loss': 0.8090439158853998, 'epoch': 5.0})"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "afc8935a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1f93b5be58c54c9886f4bd0aa8cd7a2b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/265M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1c0502ac879e48388cf01f20c7b8be28",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Upload 2 LFS files:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b4dbbc58dbcb4a5f913904784bcb6bf8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "events.out.tfevents.1702285734.a100.2029366.0:   0%|          | 0.00/8.84k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "trainer.save_model(\"test-squad-trained-eda-moderate\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "c4367952",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "odict_keys(['loss', 'start_logits', 'end_logits'])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluation\n",
    "for batch in trainer.get_eval_dataloader():\n",
    "    break\n",
    "\n",
    "batch = {k: v.to(device) for k, v in batch.items()}\n",
    "with torch.no_grad():\n",
    "    output = model(**batch)\n",
    "output.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "83ba66c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([64, 384]), torch.Size([64, 384]))"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.start_logits.shape, output.end_logits.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "5f79a983",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([102, 134,   0,   0,  14,  34,  55,  66, 102,   0,  37,  53,  70,  10,\n",
       "          45,  65,  77,  94,   0,   0,   0,  28,  31,  55, 117, 142,   0,  51,\n",
       "          45,  97, 135,  30,   0,   0,   0,  26,  28,  46,  63, 132,   0,  76,\n",
       "           0,  18,  29,  78, 106, 163,   0,  18,   0, 139,   0,  52,  55,  91,\n",
       "         152,   0,   0,   0,  26,  75,  75,  88], device='cuda:0'),\n",
       " tensor([105, 138,   0,   0,  15,  35,  56,  71, 106,   0,  69,  53,  70,  13,\n",
       "          45,  66,  80,  96,   0,   0,   0,  35,  34,  61, 118, 144,  25,  60,\n",
       "          46,  99, 138,  37,   0,   0,   0,  26,  29,  59,  64, 132,   0,  78,\n",
       "           0,  24,  43,  79, 106, 166,   0,  24,   0, 141,  62,  54,  55,  94,\n",
       "         158,   0,   0,   0,  29,  76,  76,  72], device='cuda:0'))"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.start_logits.argmax(dim=-1), output.end_logits.argmax(dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "82076135",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_best_size = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "d198bdf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "start_logits = output.start_logits[0].cpu().numpy()\n",
    "end_logits = output.end_logits[0].cpu().numpy()\n",
    "# Gather the indices the best start/end logits:\n",
    "start_indexes = np.argsort(start_logits)[-1 : -n_best_size - 1 : -1].tolist()\n",
    "end_indexes = np.argsort(end_logits)[-1 : -n_best_size - 1 : -1].tolist()\n",
    "valid_answers = []\n",
    "for start_index in start_indexes:\n",
    "    for end_index in end_indexes:\n",
    "        if start_index <= end_index: # We need to refine that test to check the answer is inside the context\n",
    "            valid_answers.append(\n",
    "                {\n",
    "                    \"score\": start_logits[start_index] + end_logits[end_index],\n",
    "                    \"text\": \"\" # We need to find a way to get back the original substring corresponding to the answer in the context\n",
    "                }\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "b86d51cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_validation_features(examples):\n",
    "    # Some of the questions have lots of whitespace on the left, which is not useful and will make the\n",
    "    # truncation of the context fail (the tokenized question will take a lots of space). So we remove that\n",
    "    # left whitespace\n",
    "    examples[\"question\"] = [q.lstrip() for q in examples[\"question\"]]\n",
    "\n",
    "    # Tokenize our examples with truncation and maybe padding, but keep the overflows using a stride. This results\n",
    "    # in one example possible giving several features when a context is long, each of those features having a\n",
    "    # context that overlaps a bit the context of the previous feature.\n",
    "    tokenized_examples = tokenizer(\n",
    "        examples[\"question\" if pad_on_right else \"context\"],\n",
    "        examples[\"context\" if pad_on_right else \"question\"],\n",
    "        truncation=\"only_second\" if pad_on_right else \"only_first\",\n",
    "        max_length=max_length,\n",
    "        stride=doc_stride,\n",
    "        return_overflowing_tokens=True,\n",
    "        return_offsets_mapping=True,\n",
    "        padding=\"max_length\",\n",
    "    )\n",
    "\n",
    "    # Since one example might give us several features if it has a long context, we need a map from a feature to\n",
    "    # its corresponding example. This key gives us just that.\n",
    "    sample_mapping = tokenized_examples.pop(\"overflow_to_sample_mapping\")\n",
    "\n",
    "    # We keep the example_id that gave us this feature and we will store the offset mappings.\n",
    "    tokenized_examples[\"example_id\"] = []\n",
    "\n",
    "    for i in range(len(tokenized_examples[\"input_ids\"])):\n",
    "        # Grab the sequence corresponding to that example (to know what is the context and what is the question).\n",
    "        sequence_ids = tokenized_examples.sequence_ids(i)\n",
    "        context_index = 1 if pad_on_right else 0\n",
    "\n",
    "        # One example can give several spans, this is the index of the example containing this span of text.\n",
    "        sample_index = sample_mapping[i]\n",
    "        tokenized_examples[\"example_id\"].append(examples[\"id\"][sample_index])\n",
    "\n",
    "        # Set to None the offset_mapping that are not part of the context so it's easy to determine if a token\n",
    "        # position is part of the context or not.\n",
    "        tokenized_examples[\"offset_mapping\"][i] = [\n",
    "            (o if sequence_ids[k] == context_index else None)\n",
    "            for k, o in enumerate(tokenized_examples[\"offset_mapping\"][i])\n",
    "        ]\n",
    "\n",
    "    return tokenized_examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "dd3aca71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Map validation features to GPU\n",
    "validation_features = datasets[\"test\"].map(\n",
    "    prepare_validation_features,\n",
    "    batched=True,\n",
    "    remove_columns=datasets[\"test\"].column_names\n",
    ")\n",
    "validation_features.set_format(type=validation_features.format[\"type\"], columns=list(validation_features.features.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "2dd94365",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Predictions on GPU\n",
    "raw_predictions = trainer.predict(validation_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "022a10b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_features.set_format(type=validation_features.format[\"type\"], columns=list(validation_features.features.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "022fc43d",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_answer_length = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "53edb9a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'score': 20.18325, 'text': 'assimilation and mixing with'},\n",
       " {'score': 14.404429,\n",
       "  'text': 'Through generations of assimilation and mixing with'},\n",
       " {'score': 13.322649, 'text': 'generations of assimilation and mixing with'},\n",
       " {'score': 12.423273, 'text': 'with'},\n",
       " {'score': 11.137663, 'text': 'assimilation and mixing with the'},\n",
       " {'score': 11.062305, 'text': 'assimilation'},\n",
       " {'score': 9.9260235, 'text': 'mixing with'},\n",
       " {'score': 8.718625,\n",
       "  'text': 'assimilation and mixing with the native Frankish and Roman-Gaulish populations,'},\n",
       " {'score': 8.30205, 'text': 'assimilation and mixing'},\n",
       " {'score': 8.212527,\n",
       "  'text': 'assimilation and mixing with the native Frankish and Roman-Gaulish populations, their'},\n",
       " {'score': 8.206174, 'text': 'of assimilation and mixing with'},\n",
       " {'score': 7.260684,\n",
       "  'text': 'of West Francia. Through generations of assimilation and mixing with'},\n",
       " {'score': 7.08926,\n",
       "  'text': 'assimilation and mixing with the native Frankish and Roman'},\n",
       " {'score': 6.8792896,\n",
       "  'text': 'assimilation and mixing with the native Frankish and Roman-Gaulish'},\n",
       " {'score': 6.2890396,\n",
       "  'text': 'West Francia. Through generations of assimilation and mixing with'},\n",
       " {'score': 5.3588424,\n",
       "  'text': 'Through generations of assimilation and mixing with the'},\n",
       " {'score': 5.2834854, 'text': 'Through generations of assimilation'},\n",
       " {'score': 5.165103,\n",
       "  'text': '. Through generations of assimilation and mixing with'},\n",
       " {'score': 5.080359, 'text': 'and mixing with'},\n",
       " {'score': 4.2770615,\n",
       "  'text': 'generations of assimilation and mixing with the'}]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "start_logits = output.start_logits[0].cpu().numpy()\n",
    "end_logits = output.end_logits[0].cpu().numpy()\n",
    "offset_mapping = validation_features[0][\"offset_mapping\"]\n",
    "# The first feature comes from the first example. For the more general case, we will need to be match the example_id to\n",
    "# an example index\n",
    "context = datasets[\"test\"][0][\"context\"]\n",
    "\n",
    "# Gather the indices the best start/end logits:\n",
    "start_indexes = np.argsort(start_logits)[-1 : -n_best_size - 1 : -1].tolist()\n",
    "end_indexes = np.argsort(end_logits)[-1 : -n_best_size - 1 : -1].tolist()\n",
    "valid_answers = []\n",
    "for start_index in start_indexes:\n",
    "    for end_index in end_indexes:\n",
    "        # Don't consider out-of-scope answers, either because the indices are out of bounds or correspond\n",
    "        # to part of the input_ids that are not in the context.\n",
    "        if (\n",
    "            start_index >= len(offset_mapping)\n",
    "            or end_index >= len(offset_mapping)\n",
    "            or offset_mapping[start_index] is None\n",
    "            or offset_mapping[end_index] is None\n",
    "        ):\n",
    "            continue\n",
    "        # Don't consider answers with a length that is either < 0 or > max_answer_length.\n",
    "        if end_index < start_index or end_index - start_index + 1 > max_answer_length:\n",
    "            continue\n",
    "        if start_index <= end_index: # We need to refine that test to check the answer is inside the context\n",
    "            start_char = offset_mapping[start_index][0]\n",
    "            end_char = offset_mapping[end_index][1]\n",
    "            valid_answers.append(\n",
    "                {\n",
    "                    \"score\": start_logits[start_index] + end_logits[end_index],\n",
    "                    \"text\": context[start_char: end_char]\n",
    "                }\n",
    "            )\n",
    "\n",
    "valid_answers = sorted(valid_answers, key=lambda x: x[\"score\"], reverse=True)[:n_best_size]\n",
    "valid_answers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "2183cb07",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': ['France', 'France', 'France', 'France'],\n",
       " 'answer_start': [159, 159, 159, 159]}"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datasets[\"test\"][0][\"answers\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "861b66bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections\n",
    "\n",
    "examples = datasets[\"test\"]\n",
    "features = validation_features\n",
    "\n",
    "example_id_to_index = {k: i for i, k in enumerate(examples[\"id\"])}\n",
    "features_per_example = collections.defaultdict(list)\n",
    "for i, feature in enumerate(features):\n",
    "    features_per_example[example_id_to_index[feature[\"example_id\"]]].append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "c806f5d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Postprocess QA predictions\n",
    "def postprocess_qa_predictions(examples, features, raw_predictions, n_best_size=20, max_answer_length=30):\n",
    "    all_start_logits, all_end_logits = raw_predictions\n",
    "    example_id_to_index = {k: i for i, k in enumerate(examples[\"id\"])}\n",
    "    features_per_example = collections.defaultdict(list)\n",
    "\n",
    "    for i, feature in enumerate(features):\n",
    "        features_per_example[example_id_to_index[feature[\"example_id\"]]].append(i)\n",
    "\n",
    "    predictions = collections.OrderedDict()\n",
    "\n",
    "    print(f\"Post-processing {len(examples)} example predictions split into {len(features)} features.\")\n",
    "\n",
    "    for example_index, example in enumerate(tqdm(examples)):\n",
    "        feature_indices = features_per_example[example_index]\n",
    "        min_null_score = None\n",
    "        valid_answers = []\n",
    "        context = example[\"context\"]\n",
    "\n",
    "        for feature_index in feature_indices:\n",
    "            start_logits = all_start_logits[feature_index]\n",
    "            end_logits = all_end_logits[feature_index]\n",
    "            offset_mapping = features[feature_index][\"offset_mapping\"]\n",
    "\n",
    "            cls_index = features[feature_index][\"input_ids\"].index(tokenizer.cls_token_id)\n",
    "            feature_null_score = start_logits[cls_index] + end_logits[cls_index]\n",
    "\n",
    "            if min_null_score is None or min_null_score < feature_null_score:\n",
    "                min_null_score = feature_null_score\n",
    "\n",
    "            start_indexes = np.argsort(start_logits)[-1: -n_best_size - 1: -1].tolist()\n",
    "            end_indexes = np.argsort(end_logits)[-1: -n_best_size - 1: -1].tolist()\n",
    "\n",
    "            for start_index in start_indexes:\n",
    "                for end_index in end_indexes:\n",
    "                    if (\n",
    "                        start_index >= len(offset_mapping)\n",
    "                        or end_index >= len(offset_mapping)\n",
    "                        or offset_mapping[start_index] is None\n",
    "                        or offset_mapping[end_index] is None\n",
    "                    ):\n",
    "                        continue\n",
    "\n",
    "                    if end_index < start_index or end_index - start_index + 1 > max_answer_length:\n",
    "                        continue\n",
    "\n",
    "                    start_char = offset_mapping[start_index][0]\n",
    "                    end_char = offset_mapping[end_index][1]\n",
    "                    valid_answers.append(\n",
    "                        {\n",
    "                            \"score\": start_logits[start_index] + end_logits[end_index],\n",
    "                            \"text\": context[start_char: end_char]\n",
    "                        }\n",
    "                    )\n",
    "\n",
    "        if len(valid_answers) > 0:\n",
    "            best_answer = sorted(valid_answers, key=lambda x: x[\"score\"], reverse=True)[0]\n",
    "        else:\n",
    "            best_answer = {\"text\": \"\", \"score\": 0.0}\n",
    "\n",
    "        if not squad_v2:\n",
    "            predictions[example[\"id\"]] = best_answer[\"text\"]\n",
    "        else:\n",
    "            answer = best_answer[\"text\"] if best_answer[\"score\"] > min_null_score else \"\"\n",
    "            predictions[example[\"id\"]] = answer\n",
    "\n",
    "    return predictions\n",
    "\n",
    "# Map validation features to GPU\n",
    "validation_features = datasets[\"test\"].map(\n",
    "    prepare_validation_features,\n",
    "    batched=True,\n",
    "    remove_columns=datasets[\"test\"].column_names\n",
    ")\n",
    "validation_features.set_format(type=validation_features.format[\"type\"], columns=list(validation_features.features.keys()))\n",
    "\n",
    "# Predictions on GPU\n",
    "raw_predictions = trainer.predict(validation_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "7b05eaa7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Post-processing 11873 example predictions split into 12134 features.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████| 11873/11873 [00:29<00:00, 403.22it/s]\n"
     ]
    }
   ],
   "source": [
    "# Postprocess predictions\n",
    "final_predictions = postprocess_qa_predictions(datasets[\"test\"], validation_features, raw_predictions.predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "f06e2c8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2029366/2905994612.py:1: FutureWarning: load_metric is deprecated and will be removed in the next major version of datasets. Use 'evaluate.load' instead, from the new library 🤗 Evaluate: https://huggingface.co/docs/evaluate\n",
      "  metric = load_metric(\"squad_v2\" if squad_v2 else \"squad\")\n"
     ]
    }
   ],
   "source": [
    "metric = load_metric(\"squad_v2\" if squad_v2 else \"squad\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "214c07c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'exact': 63.9686684073107,\n",
       " 'f1': 67.85471660720431,\n",
       " 'total': 11873,\n",
       " 'HasAns_exact': 65.9919028340081,\n",
       " 'HasAns_f1': 73.77514343409833,\n",
       " 'HasAns_total': 5928,\n",
       " 'NoAns_exact': 61.951219512195124,\n",
       " 'NoAns_f1': 61.951219512195124,\n",
       " 'NoAns_total': 5945,\n",
       " 'best_exact': 63.9686684073107,\n",
       " 'best_exact_thresh': 0.0,\n",
       " 'best_f1': 67.85471660720454,\n",
       " 'best_f1_thresh': 0.0}"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metric = load_metric(\"squad_v2\" if squad_v2 else \"squad\")\n",
    "\n",
    "if squad_v2:\n",
    "    formatted_predictions = [{\"id\": k, \"prediction_text\": v, \"no_answer_probability\": 0.0} for k, v in final_predictions.items()]\n",
    "else:\n",
    "    formatted_predictions = [{\"id\": k, \"prediction_text\": v} for k, v in final_predictions.items()]\n",
    "references = [{\"id\": ex[\"id\"], \"answers\": ex[\"answers\"]} for ex in datasets[\"test\"]]\n",
    "metric.compute(predictions=formatted_predictions, references=references)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "b3c2e977",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Create a DataFrame with your data\n",
    "data = {\n",
    "    'Epoch': [1, 2, 3, 4, 5],\n",
    "    'Training Loss': [1.304400,0.937100,0.684900,0.495500,0.376100],\n",
    "    'Validation Loss': [1.197179,1.198592,1.169251,1.299047,1.467484]\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Plot the training and validation loss curves\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(df['Epoch'], df['Training Loss'], label='Training Loss', marker='o')\n",
    "plt.plot(df['Epoch'], df['Validation Loss'], label='Validation Loss', marker='o')\n",
    "\n",
    "# Add labels and legend\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training and Validation Loss Curves')\n",
    "plt.legend()\n",
    "\n",
    "# Show the plot\n",
    "plt.grid()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b6435be",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36fabad4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tor] *",
   "language": "python",
   "name": "conda-env-tor-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
