{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1b83d5d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "627c9252203b4821aa647e34f6079ae5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from huggingface_hub import notebook_login\n",
    "notebook_login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "388b8dd6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda:0 device\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'4.35.0'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForQuestionAnswering, TrainingArguments, Trainer, default_data_collator\n",
    "from datasets import load_dataset, load_metric, ClassLabel, Sequence\n",
    "import transformers\n",
    "import pandas as pd\n",
    "from IPython.display import display, HTML\n",
    "import random\n",
    "import numpy as np\n",
    "import collections\n",
    "from transformers import MarianMTModel, MarianTokenizer\n",
    "from tqdm.auto import tqdm\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Check if GPU is available\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using {device} device\")\n",
    "\n",
    "transformers.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "42ed6018",
   "metadata": {},
   "outputs": [],
   "source": [
    "squad_v2 = True\n",
    "model_checkpoint = \"distilbert-base-uncased\"\n",
    "batch_size = 32\n",
    "max_length = 384\n",
    "doc_stride = 128\n",
    "n_best_size = 20\n",
    "max_answer_length = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cc4f9b77",
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets1={}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7610dfcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets1['train'] = load_dataset(\"squad_v2\", split='train[:90%]' if squad_v2 else \"squad\")\n",
    "datasets1['validation'] = load_dataset(\"squad_v2\", split='train[90%:100%]' if squad_v2 else \"squad\")\n",
    "datasets1['test'] = load_dataset(\"squad_v2\", split='validation' if squad_v2 else \"squad\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7f5e9d24",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import Dataset, DatasetDict\n",
    "datasets= DatasetDict(datasets1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "41e54044",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to /home/rabeea/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "from random import shuffle\n",
    "from tqdm import tqdm\n",
    "random.seed(1)\n",
    "import nltk\n",
    "nltk.download('wordnet')\n",
    "\n",
    "#stop words list\n",
    "stop_words = ['i', 'me', 'my', 'myself', 'we', 'our',\n",
    "\t\t\t'ours', 'ourselves', 'you', 'your', 'yours',\n",
    "\t\t\t'yourself', 'yourselves', 'he', 'him', 'his',\n",
    "\t\t\t'himself', 'she', 'her', 'hers', 'herself',\n",
    "\t\t\t'it', 'its', 'itself', 'they', 'them', 'their',\n",
    "\t\t\t'theirs', 'themselves', 'what', 'which', 'who',\n",
    "\t\t\t'whom', 'this', 'that', 'these', 'those', 'am',\n",
    "\t\t\t'is', 'are', 'was', 'were', 'be', 'been', 'being',\n",
    "\t\t\t'have', 'has', 'had', 'having', 'do', 'does', 'did',\n",
    "\t\t\t'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or',\n",
    "\t\t\t'because', 'as', 'until', 'while', 'of', 'at',\n",
    "\t\t\t'by', 'for', 'with', 'about', 'against', 'between',\n",
    "\t\t\t'into', 'through', 'during', 'before', 'after',\n",
    "\t\t\t'above', 'below', 'to', 'from', 'up', 'down', 'in',\n",
    "\t\t\t'out', 'on', 'off', 'over', 'under', 'again',\n",
    "\t\t\t'further', 'then', 'once', 'here', 'there', 'when',\n",
    "\t\t\t'where', 'why', 'how', 'all', 'any', 'both', 'each',\n",
    "\t\t\t'few', 'more', 'most', 'other', 'some', 'such', 'no',\n",
    "\t\t\t'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too',\n",
    "\t\t\t'very', 's', 't', 'can', 'will', 'just', 'don',\n",
    "\t\t\t'should', 'now', '']\n",
    "\n",
    "#cleaning up text\n",
    "import re\n",
    "def get_only_chars(line):\n",
    "\n",
    "    clean_line = \"\"\n",
    "\n",
    "    line = line.replace(\"’\", \"\")\n",
    "    line = line.replace(\"'\", \"\")\n",
    "    line = line.replace(\"-\", \" \") #replace hyphens with spaces\n",
    "    line = line.replace(\"\\t\", \" \")\n",
    "    line = line.replace(\"\\n\", \" \")\n",
    "    line = line.lower()\n",
    "\n",
    "    for char in line:\n",
    "        if char in 'qwertyuiopasdfghjklzxcvbnm ':\n",
    "            clean_line += char\n",
    "        else:\n",
    "            clean_line += ' '\n",
    "\n",
    "    clean_line = re.sub(' +',' ',clean_line) #delete extra spaces\n",
    "    if clean_line[0] == ' ':\n",
    "        clean_line = clean_line[1:]\n",
    "    return clean_line\n",
    "\n",
    "########################################################################\n",
    "# Synonym replacement\n",
    "# Replace n words in the sentence with synonyms from wordnet\n",
    "########################################################################\n",
    "\n",
    "#for the first time you use wordnet\n",
    "#import nltk\n",
    "#nltk.download('wordnet')\n",
    "from nltk.corpus import wordnet\n",
    "\n",
    "def synonym_replacement(words, n):\n",
    "\tnew_words = words.copy()\n",
    "\trandom_word_list = list(set([word for word in words if word not in stop_words]))\n",
    "\trandom.shuffle(random_word_list)\n",
    "\tnum_replaced = 0\n",
    "\tfor random_word in random_word_list:\n",
    "\t\tsynonyms = get_synonyms(random_word)\n",
    "\t\tif len(synonyms) >= 1:\n",
    "\t\t\tsynonym = random.choice(list(synonyms))\n",
    "\t\t\tnew_words = [synonym if word == random_word else word for word in new_words]\n",
    "\t\t\t#print(\"replaced\", random_word, \"with\", synonym)\n",
    "\t\t\tnum_replaced += 1\n",
    "\t\tif num_replaced >= n: #only replace up to n words\n",
    "\t\t\tbreak\n",
    "\n",
    "\t#this is stupid but we need it, trust me\n",
    "\tsentence = ' '.join(new_words)\n",
    "\tnew_words = sentence.split(' ')\n",
    "\n",
    "\treturn new_words\n",
    "\n",
    "def get_synonyms(word):\n",
    "\tsynonyms = set()\n",
    "\tfor syn in wordnet.synsets(word):\n",
    "\t\tfor l in syn.lemmas():\n",
    "\t\t\tsynonym = l.name().replace(\"_\", \" \").replace(\"-\", \" \").lower()\n",
    "\t\t\tsynonym = \"\".join([char for char in synonym if char in ' qwertyuiopasdfghjklzxcvbnm'])\n",
    "\t\t\tsynonyms.add(synonym)\n",
    "\tif word in synonyms:\n",
    "\t\tsynonyms.remove(word)\n",
    "\treturn list(synonyms)\n",
    "\n",
    "########################################################################\n",
    "# Random deletion\n",
    "# Randomly delete words from the sentence with probability p\n",
    "########################################################################\n",
    "\n",
    "def random_deletion(words, p):\n",
    "\n",
    "\t#obviously, if there's only one word, don't delete it\n",
    "\tif len(words) == 1:\n",
    "\t\treturn words\n",
    "\n",
    "\t#randomly delete words with probability p\n",
    "\tnew_words = []\n",
    "\tfor word in words:\n",
    "\t\tr = random.uniform(0, 1)\n",
    "\t\tif r > p:\n",
    "\t\t\tnew_words.append(word)\n",
    "\n",
    "\t#if you end up deleting all words, just return a random word\n",
    "\tif len(new_words) == 0:\n",
    "\t\trand_int = random.randint(0, len(words)-1)\n",
    "\t\treturn [words[rand_int]]\n",
    "\n",
    "\treturn new_words\n",
    "\n",
    "########################################################################\n",
    "# Random swap\n",
    "# Randomly swap two words in the sentence n times\n",
    "########################################################################\n",
    "\n",
    "def random_swap(words, n):\n",
    "\tnew_words = words.copy()\n",
    "\tfor _ in range(n):\n",
    "\t\tnew_words = swap_word(new_words)\n",
    "\treturn new_words\n",
    "\n",
    "def swap_word(new_words):\n",
    "\trandom_idx_1 = random.randint(0, len(new_words)-1)\n",
    "\trandom_idx_2 = random_idx_1\n",
    "\tcounter = 0\n",
    "\twhile random_idx_2 == random_idx_1:\n",
    "\t\trandom_idx_2 = random.randint(0, len(new_words)-1)\n",
    "\t\tcounter += 1\n",
    "\t\tif counter > 3:\n",
    "\t\t\treturn new_words\n",
    "\tnew_words[random_idx_1], new_words[random_idx_2] = new_words[random_idx_2], new_words[random_idx_1]\n",
    "\treturn new_words\n",
    "\n",
    "########################################################################\n",
    "# Random insertion\n",
    "# Randomly insert n words into the sentence\n",
    "########################################################################\n",
    "\n",
    "def random_insertion(words, n):\n",
    "\tnew_words = words.copy()\n",
    "\tfor _ in range(n):\n",
    "\t\tadd_word(new_words)\n",
    "\treturn new_words\n",
    "\n",
    "def add_word(new_words):\n",
    "\tsynonyms = []\n",
    "\tcounter = 0\n",
    "\twhile len(synonyms) < 1:\n",
    "\t\trandom_word = new_words[random.randint(0, len(new_words)-1)]\n",
    "\t\tsynonyms = get_synonyms(random_word)\n",
    "\t\tcounter += 1\n",
    "\t\tif counter >= 10:\n",
    "\t\t\treturn\n",
    "\trandom_synonym = synonyms[0]\n",
    "\trandom_idx = random.randint(0, len(new_words)-1)\n",
    "\tnew_words.insert(random_idx, random_synonym)\n",
    "\n",
    "########################################################################\n",
    "# main data augmentation function\n",
    "########################################################################\n",
    "\n",
    "def eda(sentences, alpha_sr=0.1):\n",
    "\taugmented_sentences=[]\n",
    "\tfor i in tqdm(range(len(sentences))):\n",
    "\t\tsentence = get_only_chars(sentences[i])\n",
    "\t\twords = sentence.split(' ')\n",
    "\t\twords = [word for word in words if word != '']\n",
    "\t\tnum_words = len(words)\n",
    "\t\t#sr\n",
    "\t\tif (alpha_sr > 0):\n",
    "\t\t\tn_sr = max(1, int(alpha_sr*num_words))\n",
    "\t\t\ta_words = synonym_replacement(words, n_sr)\n",
    "\t\t\taugmented_sentences.append(' '.join(a_words)+'?')\n",
    "\n",
    "\treturn augmented_sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "16f46285",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['id', 'title', 'context', 'question', 'answers'],\n",
       "    num_rows: 4895\n",
       "})"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import load_from_disk\n",
    "\n",
    "# Load the saved dataset\n",
    "sampled_data = load_from_disk(\"dataset_soft\")\n",
    "sampled_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "53d19117",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply back translation to the context and question in the SQuAD dataset\n",
    "context_texts = sampled_data[\"context\"]\n",
    "question_texts = sampled_data[\"question\"]\n",
    "answer_texts= sampled_data['answers']\n",
    "id_texts= sampled_data['id']\n",
    "title_texts= sampled_data['title']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "44fa941f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████| 4895/4895 [00:03<00:00, 1526.62it/s]\n"
     ]
    }
   ],
   "source": [
    "# Translate from English to French\n",
    "# context_translations = back_translate(context_texts, model, tokenizer)\n",
    "question_translations = eda(question_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a37da035",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create augmented dataset with back-translated context, questions, and answers\n",
    "augmented_dataset = {\n",
    "    \"context\": context_texts,\n",
    "    \"question\": question_translations,\n",
    "    \"answers\": answer_texts,  # Add this line\n",
    "    \"id\": id_texts,\n",
    "    \"title\": title_texts,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c430b1ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optionally, you can combine the original and augmented datasets\n",
    "combined_dataset = {\n",
    "    \"context\": datasets[\"train\"][\"context\"]+context_texts,\n",
    "    \"question\": datasets[\"train\"][\"question\"] + question_translations,\n",
    "    \"answers\": datasets[\"train\"][\"answers\"] + answer_texts,\n",
    "    \"id\":datasets[\"train\"][\"id\"] + id_texts,\n",
    "    \"title\":datasets[\"train\"][\"title\"]+ title_texts\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3cce7943",
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets['train'] = Dataset.from_dict(combined_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0e3bb117",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['context', 'question', 'answers', 'id', 'title'],\n",
       "        num_rows: 122182\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['id', 'title', 'context', 'question', 'answers'],\n",
       "        num_rows: 13032\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['id', 'title', 'context', 'question', 'answers'],\n",
       "        num_rows: 11873\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9217b06b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['id', 'title', 'context', 'question', 'answers'],\n",
       "    num_rows: 13032\n",
       "})"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datasets[\"validation\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "62fc7743",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show random elements in the dataset\n",
    "def show_random_elements(dataset, num_examples=10):\n",
    "    assert num_examples <= len(dataset), \"Can't pick more elements than there are in the dataset.\"\n",
    "    picks = []\n",
    "    for _ in range(num_examples):\n",
    "        pick = random.randint(0, len(dataset)-1)\n",
    "        while pick in picks:\n",
    "            pick = random.randint(0, len(dataset)-1)\n",
    "        picks.append(pick)\n",
    "\n",
    "    df = pd.DataFrame(dataset[picks])\n",
    "    for column, typ in dataset.features.items():\n",
    "        if isinstance(typ, ClassLabel):\n",
    "            df[column] = df[column].transform(lambda i: typ.names[i])\n",
    "        elif isinstance(typ, Sequence) and isinstance(typ.feature, ClassLabel):\n",
    "            df[column] = df[column].transform(lambda x: [typ.feature.names[i] for i in x])\n",
    "    display(HTML(df.to_html()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a6081a4b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>context</th>\n",
       "      <th>question</th>\n",
       "      <th>answers</th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The CBC's flagship newscast, The National, airs Sunday through Fridays at 10:00 p.m. EST and Saturdays at 6:00 p.m. EST. Until October 2006, CBC owned-and-operated stations aired a second broadcast of the program at 11:00 p.m.; this later broadcast included only the main news portion of the program, and excluded the analysis and documentary segment. This second airing was later replaced with other programming, and as of the 2012-13 television season, was replaced on CBC's major market stations by a half-hour late newscast. There is also a short news update, at most, on late Saturday evenings. During hockey season, this update is usually found during the first intermission of the second game of the doubleheader on Hockey Night in Canada.</td>\n",
       "      <td>During hockey season, when does the late night news update occur?</td>\n",
       "      <td>{'answer_start': [651], 'text': ['during the first intermission of the second game of the doubleheader on Hockey Night in Canada']}</td>\n",
       "      <td>572a346daf94a219006aa89c</td>\n",
       "      <td>CBC_Television</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A high-definition remaster of the game, The Legend of Zelda: Twilight Princess HD, is being developed by Tantalus Media for the Wii U. Officially announced during a Nintendo Direct presentation on November 12, 2015, it features enhanced graphics and Amiibo functionality. The game will be released in North America and Europe on March 4, 2016; in Australia on March 5, 2016; and in Japan on March 10, 2016.</td>\n",
       "      <td>What is the name of the remastered game?</td>\n",
       "      <td>{'answer_start': [40], 'text': ['The Legend of Zelda: Twilight Princess HD']}</td>\n",
       "      <td>56d1335f17492d1400aabc14</td>\n",
       "      <td>The_Legend_of_Zelda:_Twilight_Princess</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The War on Terrorism is a global effort by the governments of several countries (primarily the United States and its principal allies) to neutralize international terrorist groups (primarily Islamic Extremist terrorist groups, including al-Qaeda) and ensure that countries considered by the US and some of its allies to be Rogue Nations no longer support terrorist activities. It has been adopted primarily as a response to the September 11, 2001 attacks on the United States. Since 2001, terrorist motivated attacks upon service members have occurred in Arkansas and Texas.</td>\n",
       "      <td>what is one prominent specific terrorist group targeted by the war on act of terrorism?</td>\n",
       "      <td>{'answer_start': [237], 'text': ['al-Qaeda']}</td>\n",
       "      <td>570b4c3c6b8089140040f862</td>\n",
       "      <td>Military_history_of_the_United_States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Downtown area is home to historic neighborhoods and buildings such as the Sir Walter Raleigh Hotel built in the early 20th century, the restored City Market, the Fayetteville Street downtown business district, which includes the PNC Plaza and Wells Fargo Capitol Center buildings, as well as the North Carolina Museum of History, North Carolina Museum of Natural Sciences, North Carolina State Capitol, Peace College, the Raleigh City Museum, Raleigh Convention Center, Shaw University, and St. Augustine's College. The neighborhoods in Old Raleigh include Cameron Park, Boylan Heights, Country Club Hills, Coley Forest, Five Points, Budleigh, Glenwood-Brooklyn, Hayes Barton Historic District, Moore Square, Mordecai, Rosengarten Park, Belvidere Park, Woodcrest, and Historic Oakwood. In the 2000s, an effort by the Downtown Raleigh Alliance was made to separate this area of the city into five smaller districts: Fayetteville Street, Moore Square, Glenwood South, Warehouse (Raleigh), and Capital District (Raleigh). Some of the names have become common place among locals such as the Warehouse, Fayetteville Street, and Glenwood South Districts.</td>\n",
       "      <td>What are some neighborhoods in Raleigh?</td>\n",
       "      <td>{'answer_start': [557], 'text': ['Cameron Park, Boylan Heights, Country Club Hills,']}</td>\n",
       "      <td>5726b0cc5951b619008f7a9d</td>\n",
       "      <td>Raleigh,_North_Carolina</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>International teams also play friendlies, generally in preparation for the qualifying or final stages of major tournaments. This is essential, since national squads generally have much less time together in which to prepare. The biggest difference between friendlies at the club and international levels is that international friendlies mostly take place during club league seasons, not between them. This has on occasion led to disagreement between national associations and clubs as to the availability of players, who could become injured or fatigued in a friendly.</td>\n",
       "      <td>Why are Friendly's nonessential for major tournaments?</td>\n",
       "      <td>{'answer_start': [], 'text': []}</td>\n",
       "      <td>5a123e6c6614be00188f24ae</td>\n",
       "      <td>Exhibition_game</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Deism holds that God is wholly transcendent: God exists, but does not intervene in the world beyond what was necessary to create it. In this view, God is not anthropomorphic, and neither answers prayers nor produces miracles. Common in Deism is a belief that God has no interest in humanity and may not even be aware of humanity. Pandeism and Panendeism, respectively, combine Deism with the Pantheistic or Panentheistic beliefs. Pandeism is proposed to explain as to Deism why God would create a universe and then abandon it, and as to Pantheism, the origin and purpose of the universe.</td>\n",
       "      <td>what does a pandeistic deity not do?</td>\n",
       "      <td>{'answer_start': [], 'text': []}</td>\n",
       "      <td>5a3c7309cc5d22001a521dbc</td>\n",
       "      <td>God</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Hellenistic military equipment was generally characterized by an increase in size. Hellenistic-era warships grew from the trireme to include more banks of oars and larger numbers of rowers and soldiers as in the Quadrireme and Quinquereme. The Ptolemaic Tessarakonteres was the largest ship constructed in Antiquity. New siege engines were developed during this period. An unknown engineer developed the torsion-spring catapult (ca. 360) and Dionysios of Alexandria designed a repeating ballista, the Polybolos. Preserved examples of ball projectiles range from 4.4 kg to 78 kg (or over 170 lbs). Demetrius Poliorcetes was notorious for the large siege engines employed in his campaigns, especially during the 12-month siege of Rhodes when he had Epimachos of Athens build a massive 160 ton siege tower named Helepolis, filled with artillery.</td>\n",
       "      <td>What was the largest ship constructed in Antiquity?</td>\n",
       "      <td>{'answer_start': [244], 'text': ['Ptolemaic Tessarakonteres']}</td>\n",
       "      <td>57261cc4271a42140099d48d</td>\n",
       "      <td>Hellenistic_period</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Much of the early extant evidence for the origins of Mahāyāna comes from early Chinese translations of Mahāyāna texts. These Mahāyāna teachings were first propagated into China by Lokakṣema, the first translator of Mahāyāna sūtras into Chinese during the 2nd century CE.[note 39] Some scholars have traditionally considered the earliest Mahāyāna sūtras to include the very first versions of the Prajñāpāramitā series, along with texts concerning Akṣobhya Buddha, which were probably composed in the 1st century BCE in the south of India.[note 40]</td>\n",
       "      <td>Most of the early extant evidence for the origins of Mhayana comes from what type of translations?</td>\n",
       "      <td>{'answer_start': [79], 'text': ['Chinese']}</td>\n",
       "      <td>56d2706859d6e41400145fdc</td>\n",
       "      <td>Buddhism</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>In the late 20th century a new concept was added to those included in the compass of both structure and function, the consideration of sustainability, hence sustainable architecture. To satisfy the contemporary ethos a building should be constructed in a manner which is environmentally friendly in terms of the production of its materials, its impact upon the natural and built environment of its surrounding area and the demands that it makes upon non-sustainable power sources for heating, cooling, water and waste management and lighting.</td>\n",
       "      <td>When was the conecept, unsustainable architecture used?</td>\n",
       "      <td>{'answer_start': [], 'text': []}</td>\n",
       "      <td>5acfa14d77cf76001a6855e8</td>\n",
       "      <td>Architecture</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>If a capacitor is driven with a time-varying voltage that changes rapidly enough, at some frequency the polarization of the dielectric cannot follow the voltage. As an example of the origin of this mechanism, the internal microscopic dipoles contributing to the dielectric constant cannot move instantly, and so as frequency of an applied alternating voltage increases, the dipole response is limited and the dielectric constant diminishes. A changing dielectric constant with frequency is referred to as dielectric dispersion, and is governed by dielectric relaxation processes, such as Debye relaxation. Under transient conditions, the displacement field can be expressed as (see electric susceptibility):</td>\n",
       "      <td>What is an example of an undielectric relaxation process?</td>\n",
       "      <td>{'answer_start': [], 'text': []}</td>\n",
       "      <td>5acf695777cf76001a684db6</td>\n",
       "      <td>Capacitor</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_random_elements(datasets[\"train\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c109ba4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize tokenizer and model\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "00a8d5b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert isinstance(tokenizer, transformers.PreTrainedTokenizerFast)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d4e400e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [101, 2054, 2003, 2115, 2171, 1029, 102, 2026, 2171, 2003, 19538, 4430, 1012, 102], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer(\"What is your name?\", \"My name is Minhah.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9e537a85",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, example in enumerate(datasets[\"train\"]):\n",
    "    if len(tokenizer(example[\"question\"], example[\"context\"])[\"input_ids\"]) > 384:\n",
    "        break\n",
    "example = datasets[\"train\"][i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8e8087f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "437"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tokenizer(example[\"question\"], example[\"context\"])[\"input_ids\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e1783567",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "384"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tokenizer(example[\"question\"], example[\"context\"], max_length=max_length, truncation=\"only_second\")[\"input_ids\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ed85484d",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_example = tokenizer(\n",
    "    example[\"question\"],\n",
    "    example[\"context\"],\n",
    "    max_length=max_length,\n",
    "    truncation=\"only_second\",\n",
    "    return_overflowing_tokens=True,\n",
    "    stride=doc_stride\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2772a935",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[384, 192]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[len(x) for x in tokenized_example[\"input_ids\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f9aa1df1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CLS] beyonce got married in 2008 to whom? [SEP] on april 4, 2008, beyonce married jay z. she publicly revealed their marriage in a video montage at the listening party for her third studio album, i am... sasha fierce, in manhattan's sony club on october 22, 2008. i am... sasha fierce was released on november 18, 2008 in the united states. the album formally introduces beyonce's alter ego sasha fierce, conceived during the making of her 2003 single \" crazy in love \", selling 482, 000 copies in its first week, debuting atop the billboard 200, and giving beyonce her third consecutive number - one album in the us. the album featured the number - one song \" single ladies ( put a ring on it ) \" and the top - five songs \" if i were a boy \" and \" halo \". achieving the accomplishment of becoming her longest - running hot 100 single in her career, \" halo \"'s success in the us helped beyonce attain more top - ten singles on the list than any other woman during the 2000s. it also included the successful \" sweet dreams \", and singles \" diva \", \" ego \", \" broken - hearted girl \" and \" video phone \". the music video for \" single ladies \" has been parodied and imitated around the world, spawning the \" first major dance craze \" of the internet age according to the toronto star. the video has won several awards, including best video at the 2009 mtv europe music awards, the 2009 scottish mobo awards, and the 2009 bet awards. at the 2009 mtv video music awards, the video was nominated for nine awards, ultimately winning three including video of the year. its failure to win the best female video category, which went to american country pop singer taylor swift's \" you belong with me \", led to kanye west interrupting the ceremony and beyonce [SEP]\n",
      "[CLS] beyonce got married in 2008 to whom? [SEP] single ladies \" has been parodied and imitated around the world, spawning the \" first major dance craze \" of the internet age according to the toronto star. the video has won several awards, including best video at the 2009 mtv europe music awards, the 2009 scottish mobo awards, and the 2009 bet awards. at the 2009 mtv video music awards, the video was nominated for nine awards, ultimately winning three including video of the year. its failure to win the best female video category, which went to american country pop singer taylor swift's \" you belong with me \", led to kanye west interrupting the ceremony and beyonce improvising a re - presentation of swift's award during her own acceptance speech. in march 2009, beyonce embarked on the i am... world tour, her second headlining worldwide concert tour, consisting of 108 shows, grossing $ 119. 5 million. [SEP]\n"
     ]
    }
   ],
   "source": [
    "for x in tokenized_example[\"input_ids\"][:2]:\n",
    "    print(tokenizer.decode(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8c2537a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 0), (0, 7), (8, 11), (12, 19), (20, 22), (23, 27), (28, 30), (31, 35), (35, 36), (0, 0), (0, 2), (3, 8), (9, 10), (10, 11), (12, 16), (16, 17), (18, 25), (26, 33), (34, 37), (38, 39), (39, 40), (41, 44), (45, 53), (54, 62), (63, 68), (69, 77), (78, 80), (81, 82), (83, 88), (89, 93), (93, 96), (97, 99), (100, 103), (104, 113), (114, 119), (120, 123), (124, 127), (128, 133), (134, 140), (141, 146), (146, 147), (148, 149), (150, 152), (152, 153), (153, 154), (154, 155), (156, 161), (162, 168), (168, 169), (170, 172), (173, 182), (182, 183), (183, 184), (185, 189), (190, 194), (195, 197), (198, 205), (206, 208), (208, 209), (210, 214), (214, 215), (216, 217), (218, 220), (220, 221), (221, 222), (222, 223), (224, 229), (230, 236), (237, 240), (241, 249), (250, 252), (253, 261), (262, 264), (264, 265), (266, 270), (271, 273), (274, 277), (278, 284), (285, 291), (291, 292), (293, 296), (297, 302), (303, 311), (312, 322), (323, 330), (330, 331), (331, 332), (333, 338), (339, 342), (343, 348), (349, 355), (355, 356), (357, 366), (367, 373), (374, 377), (378, 384), (385, 387), (388, 391), (392, 396), (397, 403)]\n"
     ]
    }
   ],
   "source": [
    "tokenized_example = tokenizer(\n",
    "    example[\"question\"],\n",
    "    example[\"context\"],\n",
    "    max_length=max_length,\n",
    "    truncation=\"only_second\",\n",
    "    return_overflowing_tokens=True,\n",
    "    return_offsets_mapping=True,\n",
    "    stride=doc_stride\n",
    ")\n",
    "print(tokenized_example[\"offset_mapping\"][0][:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "34173c5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "beyonce Beyonce\n"
     ]
    }
   ],
   "source": [
    "first_token_id = tokenized_example[\"input_ids\"][0][1]\n",
    "offsets = tokenized_example[\"offset_mapping\"][0][1]\n",
    "print(tokenizer.convert_ids_to_tokens([first_token_id])[0], example[\"question\"][offsets[0]:offsets[1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "36314b3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[None, 0, 0, 0, 0, 0, 0, 0, 0, None, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, None]\n"
     ]
    }
   ],
   "source": [
    "sequence_ids = tokenized_example.sequence_ids()\n",
    "print(sequence_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "7cb97250",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18 19\n"
     ]
    }
   ],
   "source": [
    "answers = example[\"answers\"]\n",
    "start_char = answers[\"answer_start\"][0]\n",
    "end_char = start_char + len(answers[\"text\"][0])\n",
    "\n",
    "# Start token index of the current span in the text.\n",
    "token_start_index = 0\n",
    "while sequence_ids[token_start_index] != 1:\n",
    "    token_start_index += 1\n",
    "\n",
    "# End token index of the current span in the text.\n",
    "token_end_index = len(tokenized_example[\"input_ids\"][0]) - 1\n",
    "while sequence_ids[token_end_index] != 1:\n",
    "    token_end_index -= 1\n",
    "\n",
    "# Detect if the answer is out of the span (in which case this feature is labeled with the CLS index).\n",
    "offsets = tokenized_example[\"offset_mapping\"][0]\n",
    "if (offsets[token_start_index][0] <= start_char and offsets[token_end_index][1] >= end_char):\n",
    "    # Move the token_start_index and token_end_index to the two ends of the answer.\n",
    "    # Note: we could go after the last offset if the answer is the last word (edge case).\n",
    "    while token_start_index < len(offsets) and offsets[token_start_index][0] <= start_char:\n",
    "        token_start_index += 1\n",
    "    start_position = token_start_index - 1\n",
    "    while offsets[token_end_index][1] >= end_char:\n",
    "        token_end_index -= 1\n",
    "    end_position = token_end_index + 1\n",
    "    print(start_position, end_position)\n",
    "else:\n",
    "    print(\"The answer is not in this feature.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ece5f036",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "jay z\n",
      "Jay Z\n"
     ]
    }
   ],
   "source": [
    "print(tokenizer.decode(tokenized_example[\"input_ids\"][0][start_position: end_position+1]))\n",
    "print(answers[\"text\"][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b78c7278",
   "metadata": {},
   "outputs": [],
   "source": [
    "pad_on_right = tokenizer.padding_side == \"right\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "89fce835",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForQuestionAnswering were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['qa_outputs.bias', 'qa_outputs.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DistilBertForQuestionAnswering(\n",
       "  (distilbert): DistilBertModel(\n",
       "    (embeddings): Embeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (transformer): Transformer(\n",
       "      (layer): ModuleList(\n",
       "        (0-5): 6 x TransformerBlock(\n",
       "          (attention): MultiHeadSelfAttention(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (ffn): FFN(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (activation): GELUActivation()\n",
       "          )\n",
       "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (qa_outputs): Linear(in_features=768, out_features=2, bias=True)\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       ")"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = AutoModelForQuestionAnswering.from_pretrained(model_checkpoint)\n",
    "\n",
    "# Move model to GPU\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "3413c9b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing the training data\n",
    "def prepare_train_features(examples):\n",
    "    examples[\"question\"] = [q.lstrip() for q in examples[\"question\"]]\n",
    "    tokenized_examples = tokenizer(\n",
    "        examples[\"question\" if tokenizer.padding_side == \"right\" else \"context\"],\n",
    "        examples[\"context\" if tokenizer.padding_side == \"right\" else \"question\"],\n",
    "        truncation=\"only_second\" if tokenizer.padding_side == \"right\" else \"only_first\",\n",
    "        max_length=max_length,\n",
    "        stride=doc_stride,\n",
    "        return_overflowing_tokens=True,\n",
    "        return_offsets_mapping=True,\n",
    "        padding=\"max_length\",\n",
    "    )\n",
    "    sample_mapping = tokenized_examples.pop(\"overflow_to_sample_mapping\")\n",
    "    tokenized_examples[\"start_positions\"] = []\n",
    "    tokenized_examples[\"end_positions\"] = []\n",
    "\n",
    "    for i, offsets in enumerate(tokenized_examples[\"offset_mapping\"]):\n",
    "        input_ids = tokenized_examples[\"input_ids\"][i]\n",
    "        cls_index = input_ids.index(tokenizer.cls_token_id)\n",
    "        sequence_ids = tokenized_examples.sequence_ids(i)\n",
    "        sample_index = sample_mapping[i]\n",
    "        answers = examples[\"answers\"][sample_index]\n",
    "\n",
    "        if len(answers[\"answer_start\"]) == 0:\n",
    "            tokenized_examples[\"start_positions\"].append(cls_index)\n",
    "            tokenized_examples[\"end_positions\"].append(cls_index)\n",
    "        else:\n",
    "            start_char = answers[\"answer_start\"][0]\n",
    "            end_char = start_char + len(answers[\"text\"][0])\n",
    "            token_start_index = 0\n",
    "            while sequence_ids[token_start_index] != (1 if tokenizer.padding_side == \"right\" else 0):\n",
    "                token_start_index += 1\n",
    "            token_end_index = len(input_ids) - 1\n",
    "            while sequence_ids[token_end_index] != (1 if tokenizer.padding_side == \"right\" else 0):\n",
    "                token_end_index -= 1\n",
    "\n",
    "            if not (offsets[token_start_index][0] <= start_char and offsets[token_end_index][1] >= end_char):\n",
    "                tokenized_examples[\"start_positions\"].append(cls_index)\n",
    "                tokenized_examples[\"end_positions\"].append(cls_index)\n",
    "            else:\n",
    "                while token_start_index < len(offsets) and offsets[token_start_index][0] <= start_char:\n",
    "                    token_start_index += 1\n",
    "                tokenized_examples[\"start_positions\"].append(token_start_index - 1)\n",
    "                while offsets[token_end_index][1] >= end_char:\n",
    "                    token_end_index -= 1\n",
    "                tokenized_examples[\"end_positions\"].append(token_end_index + 1)\n",
    "\n",
    "    return tokenized_examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "7d997eea",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = prepare_train_features(datasets['train'][:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "4eab5181",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "823a48b2126b448e9889b619c3b6213d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/122182 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Map training features to GPU\n",
    "tokenized_datasets = datasets.map(\n",
    "    prepare_train_features,\n",
    "    batched=True,\n",
    "    remove_columns=datasets[\"train\"].column_names\n",
    ")\n",
    "tokenized_datasets.set_format(type='torch', columns=['input_ids', 'attention_mask', 'start_positions', 'end_positions'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "ddc99e9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = model_checkpoint.split(\"/\")[-1]\n",
    "args = TrainingArguments(\n",
    "    f\"{model_name}-finetuned-squad\",\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    learning_rate=5e-5,\n",
    "    per_device_train_batch_size=batch_size,\n",
    "    per_device_eval_batch_size=batch_size,\n",
    "    num_train_epochs=5,\n",
    "    weight_decay=0.01,\n",
    "    push_to_hub=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "c0bc77ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_collator = default_data_collator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "0dece3f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define trainer\n",
    "trainer = Trainer(\n",
    "    model,\n",
    "    args,\n",
    "    train_dataset=tokenized_datasets[\"train\"],\n",
    "    eval_dataset=tokenized_datasets[\"validation\"],\n",
    "    data_collator=data_collator,\n",
    "    tokenizer=tokenizer,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "d387232a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rabeea/anaconda3/envs/tor/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='9655' max='9655' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [9655/9655 3:06:42, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.303400</td>\n",
       "      <td>1.258837</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.935300</td>\n",
       "      <td>1.165385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.675900</td>\n",
       "      <td>1.198490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.485000</td>\n",
       "      <td>1.274215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.377500</td>\n",
       "      <td>1.487636</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rabeea/anaconda3/envs/tor/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/home/rabeea/anaconda3/envs/tor/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/home/rabeea/anaconda3/envs/tor/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/home/rabeea/anaconda3/envs/tor/lib/python3.10/site-packages/torch/nn/parallel/data_parallel.py:32: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 0 which\n",
      "    has less than 75% of the memory or cores of GPU 1. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n",
      "/home/rabeea/anaconda3/envs/tor/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/home/rabeea/anaconda3/envs/tor/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/home/rabeea/anaconda3/envs/tor/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/home/rabeea/anaconda3/envs/tor/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/home/rabeea/anaconda3/envs/tor/lib/python3.10/site-packages/torch/nn/parallel/data_parallel.py:32: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 0 which\n",
      "    has less than 75% of the memory or cores of GPU 1. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n",
      "/home/rabeea/anaconda3/envs/tor/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/home/rabeea/anaconda3/envs/tor/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/home/rabeea/anaconda3/envs/tor/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/home/rabeea/anaconda3/envs/tor/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/home/rabeea/anaconda3/envs/tor/lib/python3.10/site-packages/torch/nn/parallel/data_parallel.py:32: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 0 which\n",
      "    has less than 75% of the memory or cores of GPU 1. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n",
      "/home/rabeea/anaconda3/envs/tor/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/home/rabeea/anaconda3/envs/tor/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/home/rabeea/anaconda3/envs/tor/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/home/rabeea/anaconda3/envs/tor/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/home/rabeea/anaconda3/envs/tor/lib/python3.10/site-packages/torch/nn/parallel/data_parallel.py:32: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 0 which\n",
      "    has less than 75% of the memory or cores of GPU 1. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n",
      "/home/rabeea/anaconda3/envs/tor/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/home/rabeea/anaconda3/envs/tor/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/home/rabeea/anaconda3/envs/tor/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/home/rabeea/anaconda3/envs/tor/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/home/rabeea/anaconda3/envs/tor/lib/python3.10/site-packages/torch/nn/parallel/data_parallel.py:32: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 0 which\n",
      "    has less than 75% of the memory or cores of GPU 1. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=9655, training_loss=0.805737204331922, metrics={'train_runtime': 11203.9268, 'train_samples_per_second': 55.139, 'train_steps_per_second': 0.862, 'total_flos': 6.05356641542016e+16, 'train_loss': 0.805737204331922, 'epoch': 5.0})"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "afc8935a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e96646b94a354960afb9f3c4907a9be8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "events.out.tfevents.1702286907.a100.2045908.0:   0%|          | 0.00/12.9k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0d25e89275b64b06a7044132aa943689",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Upload 2 LFS files:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "14287b8193364c478f8f026a1795085f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/265M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "trainer.save_model(\"test-squad-trained-eda-soft\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "c4367952",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "odict_keys(['loss', 'start_logits', 'end_logits'])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluation\n",
    "for batch in trainer.get_eval_dataloader():\n",
    "    break\n",
    "\n",
    "batch = {k: v.to(device) for k, v in batch.items()}\n",
    "with torch.no_grad():\n",
    "    output = model(**batch)\n",
    "output.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "83ba66c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([64, 384]), torch.Size([64, 384]))"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.start_logits.shape, output.end_logits.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "5f79a983",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([102, 127,   0,   0,  14,  34,  55,  66, 102,  31,   0,  53,   0,  10,\n",
       "          45,  65,  77,  94,   0,   0,   0,  28,  31,  55, 117, 142,   0,  51,\n",
       "          45,  97, 135,  30,   0,   0,   0,  26,  28,  52,  63, 132,   0,  76,\n",
       "           0,  18,  29,  78, 106, 166,   0,  18,   0, 139,  50,  51,  55,  92,\n",
       "         152,   0,   0,   0,  26,  75,  75,  88], device='cuda:0'),\n",
       " tensor([105, 138,   0,   0,  15,  35,  56,  71, 106,   0,  51,  53,   0,  13,\n",
       "          45,  66,  80,  96,   0,   0,   0,  35,  34,  61, 118, 142,   0,  56,\n",
       "          46,  99, 138,  37,   0,   0,   0,  26,  29,  59,  64, 132,   0,  78,\n",
       "           0,  24,  43,  79, 107, 166,   0,  24,   0, 141,  53,  54,  55,  94,\n",
       "         158,   0,   0,   0,  29,  76,  76,  72], device='cuda:0'))"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.start_logits.argmax(dim=-1), output.end_logits.argmax(dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "82076135",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_best_size = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "d198bdf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "start_logits = output.start_logits[0].cpu().numpy()\n",
    "end_logits = output.end_logits[0].cpu().numpy()\n",
    "# Gather the indices the best start/end logits:\n",
    "start_indexes = np.argsort(start_logits)[-1 : -n_best_size - 1 : -1].tolist()\n",
    "end_indexes = np.argsort(end_logits)[-1 : -n_best_size - 1 : -1].tolist()\n",
    "valid_answers = []\n",
    "for start_index in start_indexes:\n",
    "    for end_index in end_indexes:\n",
    "        if start_index <= end_index: # We need to refine that test to check the answer is inside the context\n",
    "            valid_answers.append(\n",
    "                {\n",
    "                    \"score\": start_logits[start_index] + end_logits[end_index],\n",
    "                    \"text\": \"\" # We need to find a way to get back the original substring corresponding to the answer in the context\n",
    "                }\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "b86d51cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_validation_features(examples):\n",
    "    # Some of the questions have lots of whitespace on the left, which is not useful and will make the\n",
    "    # truncation of the context fail (the tokenized question will take a lots of space). So we remove that\n",
    "    # left whitespace\n",
    "    examples[\"question\"] = [q.lstrip() for q in examples[\"question\"]]\n",
    "\n",
    "    # Tokenize our examples with truncation and maybe padding, but keep the overflows using a stride. This results\n",
    "    # in one example possible giving several features when a context is long, each of those features having a\n",
    "    # context that overlaps a bit the context of the previous feature.\n",
    "    tokenized_examples = tokenizer(\n",
    "        examples[\"question\" if pad_on_right else \"context\"],\n",
    "        examples[\"context\" if pad_on_right else \"question\"],\n",
    "        truncation=\"only_second\" if pad_on_right else \"only_first\",\n",
    "        max_length=max_length,\n",
    "        stride=doc_stride,\n",
    "        return_overflowing_tokens=True,\n",
    "        return_offsets_mapping=True,\n",
    "        padding=\"max_length\",\n",
    "    )\n",
    "\n",
    "    # Since one example might give us several features if it has a long context, we need a map from a feature to\n",
    "    # its corresponding example. This key gives us just that.\n",
    "    sample_mapping = tokenized_examples.pop(\"overflow_to_sample_mapping\")\n",
    "\n",
    "    # We keep the example_id that gave us this feature and we will store the offset mappings.\n",
    "    tokenized_examples[\"example_id\"] = []\n",
    "\n",
    "    for i in range(len(tokenized_examples[\"input_ids\"])):\n",
    "        # Grab the sequence corresponding to that example (to know what is the context and what is the question).\n",
    "        sequence_ids = tokenized_examples.sequence_ids(i)\n",
    "        context_index = 1 if pad_on_right else 0\n",
    "\n",
    "        # One example can give several spans, this is the index of the example containing this span of text.\n",
    "        sample_index = sample_mapping[i]\n",
    "        tokenized_examples[\"example_id\"].append(examples[\"id\"][sample_index])\n",
    "\n",
    "        # Set to None the offset_mapping that are not part of the context so it's easy to determine if a token\n",
    "        # position is part of the context or not.\n",
    "        tokenized_examples[\"offset_mapping\"][i] = [\n",
    "            (o if sequence_ids[k] == context_index else None)\n",
    "            for k, o in enumerate(tokenized_examples[\"offset_mapping\"][i])\n",
    "        ]\n",
    "\n",
    "    return tokenized_examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "dd3aca71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Map validation features to GPU\n",
    "validation_features = datasets[\"test\"].map(\n",
    "    prepare_validation_features,\n",
    "    batched=True,\n",
    "    remove_columns=datasets[\"test\"].column_names\n",
    ")\n",
    "validation_features.set_format(type=validation_features.format[\"type\"], columns=list(validation_features.features.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "2dd94365",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Predictions on GPU\n",
    "raw_predictions = trainer.predict(validation_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "022a10b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_features.set_format(type=validation_features.format[\"type\"], columns=list(validation_features.features.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "022fc43d",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_answer_length = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "53edb9a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'score': 16.547203, 'text': 'assimilation and mixing with'},\n",
       " {'score': 13.210949, 'text': 'generations of assimilation and mixing with'},\n",
       " {'score': 10.512599, 'text': 'with'},\n",
       " {'score': 10.38499,\n",
       "  'text': 'Through generations of assimilation and mixing with'},\n",
       " {'score': 9.328679,\n",
       "  'text': 'assimilation and mixing with the native Frankish and Roman-Gaulish populations,'},\n",
       " {'score': 8.551562,\n",
       "  'text': 'assimilation and mixing with the native Frankish and Roman-Gaulish populations, their'},\n",
       " {'score': 8.312033, 'text': 'assimilation and mixing with the'},\n",
       " {'score': 8.088154, 'text': 'mixing with'},\n",
       " {'score': 7.5082736, 'text': 'assimilation'},\n",
       " {'score': 7.405962,\n",
       "  'text': 'assimilation and mixing with the native Frankish and Roman'},\n",
       " {'score': 5.9924264,\n",
       "  'text': 'generations of assimilation and mixing with the native Frankish and Roman-Gaulish populations,'},\n",
       " {'score': 5.517491,\n",
       "  'text': 'assimilation and mixing with the native Frankish and Roman-Gaulish'},\n",
       " {'score': 5.21531,\n",
       "  'text': 'generations of assimilation and mixing with the native Frankish and Roman-Gaulish populations, their'},\n",
       " {'score': 4.9757795,\n",
       "  'text': 'generations of assimilation and mixing with the'},\n",
       " {'score': 4.922369, 'text': 'and mixing with'},\n",
       " {'score': 4.408681, 'text': 'of assimilation and mixing with'},\n",
       " {'score': 4.172021, 'text': 'generations of assimilation'},\n",
       " {'score': 4.0697093,\n",
       "  'text': 'generations of assimilation and mixing with the native Frankish and Roman'},\n",
       " {'score': 3.8769827,\n",
       "  'text': 'assimilation and mixing with the native Frankish and Roman-Gaulish populations'},\n",
       " {'score': 3.6491103, 'text': 'assimilation and mixing'}]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "start_logits = output.start_logits[0].cpu().numpy()\n",
    "end_logits = output.end_logits[0].cpu().numpy()\n",
    "offset_mapping = validation_features[0][\"offset_mapping\"]\n",
    "# The first feature comes from the first example. For the more general case, we will need to be match the example_id to\n",
    "# an example index\n",
    "context = datasets[\"test\"][0][\"context\"]\n",
    "\n",
    "# Gather the indices the best start/end logits:\n",
    "start_indexes = np.argsort(start_logits)[-1 : -n_best_size - 1 : -1].tolist()\n",
    "end_indexes = np.argsort(end_logits)[-1 : -n_best_size - 1 : -1].tolist()\n",
    "valid_answers = []\n",
    "for start_index in start_indexes:\n",
    "    for end_index in end_indexes:\n",
    "        # Don't consider out-of-scope answers, either because the indices are out of bounds or correspond\n",
    "        # to part of the input_ids that are not in the context.\n",
    "        if (\n",
    "            start_index >= len(offset_mapping)\n",
    "            or end_index >= len(offset_mapping)\n",
    "            or offset_mapping[start_index] is None\n",
    "            or offset_mapping[end_index] is None\n",
    "        ):\n",
    "            continue\n",
    "        # Don't consider answers with a length that is either < 0 or > max_answer_length.\n",
    "        if end_index < start_index or end_index - start_index + 1 > max_answer_length:\n",
    "            continue\n",
    "        if start_index <= end_index: # We need to refine that test to check the answer is inside the context\n",
    "            start_char = offset_mapping[start_index][0]\n",
    "            end_char = offset_mapping[end_index][1]\n",
    "            valid_answers.append(\n",
    "                {\n",
    "                    \"score\": start_logits[start_index] + end_logits[end_index],\n",
    "                    \"text\": context[start_char: end_char]\n",
    "                }\n",
    "            )\n",
    "\n",
    "valid_answers = sorted(valid_answers, key=lambda x: x[\"score\"], reverse=True)[:n_best_size]\n",
    "valid_answers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "2183cb07",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': ['France', 'France', 'France', 'France'],\n",
       " 'answer_start': [159, 159, 159, 159]}"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datasets[\"test\"][0][\"answers\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "861b66bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections\n",
    "\n",
    "examples = datasets[\"test\"]\n",
    "features = validation_features\n",
    "\n",
    "example_id_to_index = {k: i for i, k in enumerate(examples[\"id\"])}\n",
    "features_per_example = collections.defaultdict(list)\n",
    "for i, feature in enumerate(features):\n",
    "    features_per_example[example_id_to_index[feature[\"example_id\"]]].append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "c806f5d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Postprocess QA predictions\n",
    "def postprocess_qa_predictions(examples, features, raw_predictions, n_best_size=20, max_answer_length=30):\n",
    "    all_start_logits, all_end_logits = raw_predictions\n",
    "    example_id_to_index = {k: i for i, k in enumerate(examples[\"id\"])}\n",
    "    features_per_example = collections.defaultdict(list)\n",
    "\n",
    "    for i, feature in enumerate(features):\n",
    "        features_per_example[example_id_to_index[feature[\"example_id\"]]].append(i)\n",
    "\n",
    "    predictions = collections.OrderedDict()\n",
    "\n",
    "    print(f\"Post-processing {len(examples)} example predictions split into {len(features)} features.\")\n",
    "\n",
    "    for example_index, example in enumerate(tqdm(examples)):\n",
    "        feature_indices = features_per_example[example_index]\n",
    "        min_null_score = None\n",
    "        valid_answers = []\n",
    "        context = example[\"context\"]\n",
    "\n",
    "        for feature_index in feature_indices:\n",
    "            start_logits = all_start_logits[feature_index]\n",
    "            end_logits = all_end_logits[feature_index]\n",
    "            offset_mapping = features[feature_index][\"offset_mapping\"]\n",
    "\n",
    "            cls_index = features[feature_index][\"input_ids\"].index(tokenizer.cls_token_id)\n",
    "            feature_null_score = start_logits[cls_index] + end_logits[cls_index]\n",
    "\n",
    "            if min_null_score is None or min_null_score < feature_null_score:\n",
    "                min_null_score = feature_null_score\n",
    "\n",
    "            start_indexes = np.argsort(start_logits)[-1: -n_best_size - 1: -1].tolist()\n",
    "            end_indexes = np.argsort(end_logits)[-1: -n_best_size - 1: -1].tolist()\n",
    "\n",
    "            for start_index in start_indexes:\n",
    "                for end_index in end_indexes:\n",
    "                    if (\n",
    "                        start_index >= len(offset_mapping)\n",
    "                        or end_index >= len(offset_mapping)\n",
    "                        or offset_mapping[start_index] is None\n",
    "                        or offset_mapping[end_index] is None\n",
    "                    ):\n",
    "                        continue\n",
    "\n",
    "                    if end_index < start_index or end_index - start_index + 1 > max_answer_length:\n",
    "                        continue\n",
    "\n",
    "                    start_char = offset_mapping[start_index][0]\n",
    "                    end_char = offset_mapping[end_index][1]\n",
    "                    valid_answers.append(\n",
    "                        {\n",
    "                            \"score\": start_logits[start_index] + end_logits[end_index],\n",
    "                            \"text\": context[start_char: end_char]\n",
    "                        }\n",
    "                    )\n",
    "\n",
    "        if len(valid_answers) > 0:\n",
    "            best_answer = sorted(valid_answers, key=lambda x: x[\"score\"], reverse=True)[0]\n",
    "        else:\n",
    "            best_answer = {\"text\": \"\", \"score\": 0.0}\n",
    "\n",
    "        if not squad_v2:\n",
    "            predictions[example[\"id\"]] = best_answer[\"text\"]\n",
    "        else:\n",
    "            answer = best_answer[\"text\"] if best_answer[\"score\"] > min_null_score else \"\"\n",
    "            predictions[example[\"id\"]] = answer\n",
    "\n",
    "    return predictions\n",
    "\n",
    "# Map validation features to GPU\n",
    "validation_features = datasets[\"test\"].map(\n",
    "    prepare_validation_features,\n",
    "    batched=True,\n",
    "    remove_columns=datasets[\"test\"].column_names\n",
    ")\n",
    "validation_features.set_format(type=validation_features.format[\"type\"], columns=list(validation_features.features.keys()))\n",
    "\n",
    "# Predictions on GPU\n",
    "raw_predictions = trainer.predict(validation_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "7b05eaa7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Post-processing 11873 example predictions split into 12134 features.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████| 11873/11873 [00:38<00:00, 310.06it/s]\n"
     ]
    }
   ],
   "source": [
    "# Postprocess predictions\n",
    "final_predictions = postprocess_qa_predictions(datasets[\"test\"], validation_features, raw_predictions.predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "f06e2c8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2045908/2905994612.py:1: FutureWarning: load_metric is deprecated and will be removed in the next major version of datasets. Use 'evaluate.load' instead, from the new library 🤗 Evaluate: https://huggingface.co/docs/evaluate\n",
      "  metric = load_metric(\"squad_v2\" if squad_v2 else \"squad\")\n"
     ]
    }
   ],
   "source": [
    "metric = load_metric(\"squad_v2\" if squad_v2 else \"squad\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "214c07c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'exact': 63.65703697464836,\n",
       " 'f1': 67.592173589653,\n",
       " 'total': 11873,\n",
       " 'HasAns_exact': 67.49325236167341,\n",
       " 'HasAns_f1': 75.37481056510593,\n",
       " 'HasAns_total': 5928,\n",
       " 'NoAns_exact': 59.83179142136249,\n",
       " 'NoAns_f1': 59.83179142136249,\n",
       " 'NoAns_total': 5945,\n",
       " 'best_exact': 63.65703697464836,\n",
       " 'best_exact_thresh': 0.0,\n",
       " 'best_f1': 67.59217358965324,\n",
       " 'best_f1_thresh': 0.0}"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metric = load_metric(\"squad_v2\" if squad_v2 else \"squad\")\n",
    "\n",
    "if squad_v2:\n",
    "    formatted_predictions = [{\"id\": k, \"prediction_text\": v, \"no_answer_probability\": 0.0} for k, v in final_predictions.items()]\n",
    "else:\n",
    "    formatted_predictions = [{\"id\": k, \"prediction_text\": v} for k, v in final_predictions.items()]\n",
    "references = [{\"id\": ex[\"id\"], \"answers\": ex[\"answers\"]} for ex in datasets[\"test\"]]\n",
    "metric.compute(predictions=formatted_predictions, references=references)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "b3c2e977",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA04AAAIjCAYAAAA0vUuxAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAACcUUlEQVR4nOzdd3RUVdvG4d/MpHcCAZIQQid0kN5B6RhBsNGxoCJgQRT9bOBre18sKChiAxVQEQFBkSqI9N47hIQSakghPZn5/hgSCAkkQCaTcl9rnSWzc87MMzsj5M45+zkGi8ViQURERERERG7IaO8CRERERERECjsFJxERERERkVwoOImIiIiIiORCwUlERERERCQXCk4iIiIiIiK5UHASERERERHJhYKTiIiIiIhILhScREREREREcqHgJCIiIiIikgsFJxGRGxg6dCiVKlW6rWPHjRuHwWDI34IKmePHj2MwGJg+fXqBv7bBYGDcuHGZj6dPn47BYOD48eO5HlupUiWGDh2ar/XcyWdFRESKBgUnESlyDAZDnrZVq1bZu9QS79lnn8VgMHDkyJEb7vPaa69hMBjYtWtXAVZ2606fPs24cePYsWOHvUvJlBFeP/zwQ3uXkidnz55lzJgxhISE4Obmhru7O40bN+add94hOjra3uWJiNyUg70LEBG5VT/++GOWxz/88APLli3LNl6rVq07ep2vv/4as9l8W8e+/vrrvPLKK3f0+sXBgAEDmDRpErNmzeLNN9/McZ+ffvqJevXqUb9+/dt+nUGDBvHII4/g7Ox828+Rm9OnTzN+/HgqVapEw4YNs3ztTj4rJcXmzZvp0aMHly9fZuDAgTRu3BiALVu28MEHH7B69WqWLl1q5ypFRG5MwUlEipyBAwdmebxhwwaWLVuWbfx6CQkJuLm55fl1HB0db6s+AAcHBxwc9Fds8+bNqVatGj/99FOOwWn9+vWEhYXxwQcf3NHrmEwmTCbTHT3HnbiTz0pJEB0dzf3334/JZGL79u2EhIRk+fq7777L119/nS+vFR8fj7u7e748l4jItXSpnogUSx06dKBu3bps3bqVdu3a4ebmxv/93/8B8Pvvv9OzZ08CAgJwdnamatWq/Oc//yE9PT3Lc1y/buXay6K++uorqlatirOzM02bNmXz5s1Zjs1pjZPBYGDkyJHMnz+funXr4uzsTJ06dVi8eHG2+letWkWTJk1wcXGhatWqTJ06Nc/rpv79918efPBBKlasiLOzM0FBQbzwwgskJiZme38eHh6cOnWK3r174+HhgZ+fH2PGjMk2F9HR0QwdOhRvb298fHwYMmRIni+tGjBgAAcOHGDbtm3ZvjZr1iwMBgP9+vUjJSWFN998k8aNG+Pt7Y27uztt27Zl5cqVub5GTmucLBYL77zzDhUqVMDNzY2OHTuyd+/ebMdGRUUxZswY6tWrh4eHB15eXnTv3p2dO3dm7rNq1SqaNm0KwKOPPpp5OWjG+q6c1jjFx8fz4osvEhQUhLOzMzVr1uTDDz/EYrFk2e9WPhe369y5czz++OOUK1cOFxcXGjRowPfff59tv59//pnGjRvj6emJl5cX9erV49NPP838empqKuPHj6d69eq4uLhQunRp2rRpw7Jly276+lOnTuXUqVN8/PHH2UITQLly5Xj99dczH1+/hi3D9evTMr7v//zzD8888wxly5alQoUKzJkzJ3M8p1oMBgN79uzJHDtw4AAPPPAAvr6+uLi40KRJExYsWJDluNt97yJSfOjXoSJSbF28eJHu3bvzyCOPMHDgQMqVKwdYf9jy8PBg9OjReHh48Pfff/Pmm28SGxvLhAkTcn3eWbNmERcXx1NPPYXBYOB///sfffr04dixY7meeVizZg1z587lmWeewdPTk88++4y+ffsSERFB6dKlAdi+fTvdunXD39+f8ePHk56ezttvv42fn1+e3vevv/5KQkICw4cPp3Tp0mzatIlJkyZx8uRJfv311yz7pqen07VrV5o3b86HH37I8uXL+eijj6hatSrDhw8HrAGkV69erFmzhqeffppatWoxb948hgwZkqd6BgwYwPjx45k1axZ33XVXlteePXs2bdu2pWLFily4cIFvvvmGfv36MWzYMOLi4vj222/p2rUrmzZtynZ5XG7efPNN3nnnHXr06EGPHj3Ytm0bXbp0ISUlJct+x44dY/78+Tz44INUrlyZs2fPMnXqVNq3b8++ffsICAigVq1avP3227z55ps8+eSTtG3bFoBWrVrl+NoWi4X77ruPlStX8vjjj9OwYUOWLFnCSy+9xKlTp/jkk0+y7J+Xz8XtSkxMpEOHDhw5coSRI0dSuXJlfv31V4YOHUp0dDTPPfccAMuWLaNfv37cc889/Pe//wVg//79rF27NnOfcePG8f777/PEE0/QrFkzYmNj2bJlC9u2baNz5843rGHBggW4urrywAMP3NF7uZFnnnkGPz8/3nzzTeLj4+nZsyceHh7Mnj2b9u3bZ9n3l19+oU6dOtStWxeAvXv30rp1awIDA3nllVdwd3dn9uzZ9O7dm99++43777//jt67iBQjFhGRIm7EiBGW6/86a9++vQWwfPnll9n2T0hIyDb21FNPWdzc3CxJSUmZY0OGDLEEBwdnPg4LC7MAltKlS1uioqIyx3///XcLYFm4cGHm2FtvvZWtJsDi5ORkOXLkSObYzp07LYBl0qRJmWOhoaEWNzc3y6lTpzLHDh8+bHFwcMj2nDnJ6f29//77FoPBYAkPD8/y/gDL22+/nWXfRo0aWRo3bpz5eP78+RbA8r///S9zLC0tzdK2bVsLYJk2bVquNTVt2tRSoUIFS3p6eubY4sWLLYBl6tSpmc+ZnJyc5bhLly5ZypUrZ3nssceyjAOWt956K/PxtGnTLIAlLCzMYrFYLOfOnbM4OTlZevbsaTGbzZn7/d///Z8FsAwZMiRzLCkpKUtdFov1e+3s7JxlbjZv3nzD93v9ZyVjzt55550s+z3wwAMWg8GQ5TOQ189FTjI+kxMmTLjhPhMnTrQAlhkzZmSOpaSkWFq2bGnx8PCwxMbGWiwWi+W5556zeHl5WdLS0m74XA0aNLD07NnzpjXlpFSpUpYGDRrkef/rv78ZgoODs3zvMr7vbdq0yVZ3v379LGXLls0yHhkZaTEajVm+r/fcc4+lXr16Wf7fN5vNllatWlmqV6+eOXa7711Eig9dqicixZazszOPPvpotnFXV9fMP8fFxXHhwgXatm1LQkICBw4cyPV5H374YUqVKpX5OOPsw7Fjx3I9tlOnTlStWjXzcf369fHy8so8Nj09neXLl9O7d28CAgIy96tWrRrdu3fP9fkh6/uLj4/nwoULtGrVCovFwvbt27Pt//TTT2d53LZt2yzvZdGiRTg4OGSegQLrmqJRo0blqR6wrks7efIkq1evzhybNWsWTk5OPPjgg5nP6eTkBIDZbCYqKoq0tDSaNGmS42V+N7N8+XJSUlIYNWpUlssbn3/++Wz7Ojs7YzRa/zlMT0/n4sWLeHh4ULNmzVt+3QyLFi3CZDLx7LPPZhl/8cUXsVgs/PXXX1nGc/tc3IlFixZRvnx5+vXrlznm6OjIs88+y+XLlzMvZ/Px8SE+Pv6ml575+Piwd+9eDh8+fEs1xMbG4unpeXtvIA+GDRuWbY3bww8/zLlz57J015wzZw5ms5mHH34YsF6m+ffff/PQQw9l/l1w4cIFLl68SNeuXTl8+DCnTp0Cbv+9i0jxoeAkIsVWYGBg5g/i19q7dy/3338/3t7eeHl54efnl9lYIiYmJtfnrVixYpbHGSHq0qVLt3xsxvEZx547d47ExESqVauWbb+cxnISERHB0KFD8fX1zVy3lHG50vXvz8XFJdslgNfWAxAeHo6/vz8eHh5Z9qtZs2ae6gF45JFHMJlMzJo1C4CkpCTmzZtH9+7ds4TQ77//nvr162euIfHz8+PPP//M0/flWuHh4QBUr149y7ifn1+W1wNrSPvkk0+oXr06zs7OlClTBj8/P3bt2nXLr3vt6wcEBGQLCxmdHjPqy5Db5+JOhIeHU7169cxweKNannnmGWrUqEH37t2pUKECjz32WLZ1Vm+//TbR0dHUqFGDevXq8dJLL+WpjbyXlxdxcXF3/F5upHLlytnGunXrhre3N7/88kvm2C+//ELDhg2pUaMGAEeOHMFisfDGG2/g5+eXZXvrrbcA6/+TcPvvXUSKDwUnESm2rj3zkiE6Opr27duzc+dO3n77bRYuXMiyZcsy13TkpaX0jbq3Wa5b9J/fx+ZFeno6nTt35s8//2Ts2LHMnz+fZcuWZTYxuP79FVQnurJly9K5c2d+++03UlNTWbhwIXFxcQwYMCBznxkzZjB06FCqVq3Kt99+y+LFi1m2bBl33323TVt9v/fee4wePZp27doxY8YMlixZwrJly6hTp06BtRi39eciL8qWLcuOHTtYsGBB5vqs7t27Z1nL1q5dO44ePcp3331H3bp1+eabb7jrrrv45ptvbvrcISEhHDp0KNv6slt1fdOSDDn9v+7s7Ezv3r2ZN28eaWlpnDp1irVr12aebYKr/z+MGTOGZcuW5bhl/MLidt+7iBQfag4hIiXKqlWruHjxInPnzqVdu3aZ42FhYXas6qqyZcvi4uKS4w1jb3YT2Qy7d+/m0KFDfP/99wwePDhz/E46fwUHB7NixQouX76c5azTwYMHb+l5BgwYwOLFi/nrr7+YNWsWXl5ehIaGZn59zpw5VKlShblz52a5vC7jN/+3WjPA4cOHqVKlSub4+fPns53FmTNnDh07duTbb7/NMh4dHU2ZMmUyH+elo+G1r798+XLi4uKynHXKuBQ0o76CEBwczK5duzCbzVnOOuVUi5OTE6GhoYSGhmI2m3nmmWeYOnUqb7zxRmaA8PX15dFHH+XRRx/l8uXLtGvXjnHjxvHEE0/csIbQ0FDWr1/Pb7/9luWSwRspVapUtq6NKSkpREZG3spb5+GHH+b7779nxYoV7N+/H4vFkiU4ZXw2HB0d6dSpU67PdzvvXUSKD51xEpESJeM3+9f+Jj8lJYUvvvjCXiVlYTKZ6NSpE/Pnz+f06dOZ40eOHMm2LuZGx0PW92exWLK0lL5VPXr0IC0tjSlTpmSOpaenM2nSpFt6nt69e+Pm5sYXX3zBX3/9RZ8+fXBxcblp7Rs3bmT9+vW3XHOnTp1wdHRk0qRJWZ5v4sSJ2fY1mUzZzuz8+uuvmWtbMmTcGygvbdh79OhBeno6kydPzjL+ySefYDAY8rxeLT/06NGDM2fOZLlkLS0tjUmTJuHh4ZF5GefFixezHGc0GjNvSpycnJzjPh4eHlSrVi3z6zfy9NNP4+/vz4svvsihQ4eyff3cuXO88847mY+rVq2aZT0cwFdffXXDM0430qlTJ3x9ffnll1/45ZdfaNasWZbL+sqWLUuHDh2YOnVqjqHs/PnzmX++3fcuIsWHzjiJSInSqlUrSpUqxZAhQ3j22WcxGAz8+OOPBXpJVG7GjRvH0qVLad26NcOHD8/8Abxu3brs2LHjpseGhIRQtWpVxowZw6lTp/Dy8uK33367o7UyoaGhtG7dmldeeYXjx49Tu3Zt5s6de8vrfzw8POjdu3fmOqdrL9MDuPfee5k7dy73338/PXv2JCwsjC+//JLatWtz+fLlW3qtjPtRvf/++9x777306NGD7du389dff2U5i5Txum+//TaPPvoorVq1Yvfu3cycOTPLmSqw/jDv4+PDl19+iaenJ+7u7jRv3jzH9TWhoaF07NiR1157jePHj9OgQQOWLl3K77//zvPPP5+lEUR+WLFiBUlJSdnGe/fuzZNPPsnUqVMZOnQoW7dupVKlSsyZM4e1a9cyceLEzDNiTzzxBFFRUdx9991UqFCB8PBwJk2aRMOGDTPXQ9WuXZsOHTrQuHFjfH192bJlC3PmzGHkyJE3ra9UqVLMmzePHj160LBhQwYOHEjjxo0B2LZtGz/99BMtW7bM3P+JJ57g6aefpm/fvnTu3JmdO3eyZMmSbN+73Dg6OtKnTx9+/vln4uPj+fDDD7Pt8/nnn9OmTRvq1avHsGHDqFKlCmfPnmX9+vWcPHky835et/veRaQYsUcrPxGR/HSjduR16tTJcf+1a9daWrRoYXF1dbUEBARYXn75ZcuSJUssgGXlypWZ+92oHXlOrZ+5rn3yjdqRjxgxItux17dYtlgslhUrVlgaNWpkcXJyslStWtXyzTffWF588UWLi4vLDWbhqn379lk6depk8fDwsJQpU8YybNiwzPbW17bSHjJkiMXd3T3b8TnVfvHiRcugQYMsXl5eFm9vb8ugQYMs27dvz3M78gx//vmnBbD4+/tnawFuNpst7733niU4ONji7OxsadSokeWPP/7I9n2wWHJvR26xWCzp6emW8ePHW/z9/S2urq6WDh06WPbs2ZNtvpOSkiwvvvhi5n6tW7e2rF+/3tK+fXtL+/bts7zu77//bqldu3Zma/iM955TjXFxcZYXXnjBEhAQYHF0dLRUr17dMmHChCzt0TPeS14/F9fL+EzeaPvxxx8tFovFcvbsWcujjz5qKVOmjMXJyclSr169bN+3OXPmWLp06WIpW7asxcnJyVKxYkXLU089ZYmMjMzc55133rE0a9bM4uPjY3F1dbWEhIRY3n33XUtKSspN68xw+vRpywsvvGCpUaOGxcXFxeLm5mZp3Lix5d1337XExMRk7peenm4ZO3aspUyZMhY3NzdL165dLUeOHLlhO/LNmzff8DWXLVtmASwGg8Fy4sSJHPc5evSoZfDgwZby5ctbHB0dLYGBgZZ7773XMmfOnHx77yJS9BkslkL0a1YREbmh3r17qx2yiIiInWiNk4hIIZSYmJjl8eHDh1m0aBEdOnSwT0EiIiIlnM44iYgUQv7+/gwdOpQqVaoQHh7OlClTSE5OZvv27dnuTSQiIiK2p+YQIiKFULdu3fjpp584c+YMzs7OtGzZkvfee0+hSURExE50xklERERERCQXWuMkIiIiIiKSCwUnERERERGRXJS4NU5ms5nTp0/j6emJwWCwdzkiIiIiImInFouFuLg4AgICMBpvfk6pxAWn06dPExQUZO8yRERERESkkDhx4gQVKlS46T4lLjh5enoC1snx8vKyczWQmprK0qVL6dKlC46OjvYup9jR/NqW5te2NL+2pfm1Lc2vbWl+bUvza1uFaX5jY2MJCgrKzAg3U+KCU8bleV5eXoUmOLm5ueHl5WX3D05xpPm1Lc2vbWl+bUvza1uaX9vS/NqW5te2CuP85mUJj5pDiIiIiIiI5ELBSUREREREJBcKTiIiIiIiIrkocWuc8sJisZCWlkZ6errNXys1NRUHBweSkpIK5PVKmsI2vyaTCQcHB7XCFxERESliFJyuk5KSQmRkJAkJCQXyehaLhfLly3PixAn9MG0DhXF+3dzc8Pf3x8nJyd6liIiIiEgeKThdw2w2ExYWhslkIiAgACcnJ5v/sG02m7l8+TIeHh653nRLbl1hml+LxUJKSgrnz58nLCyM6tWr270mEREREckbBadrpKSkYDabCQoKws3NrUBe02w2k5KSgouLi36ItoHCNr+urq44OjoSHh6eWZeIiIiIFH72/0myECoMP2BL8aXPl4iIiEjRo5/gREREREREcqHgJCIiIiIikgsFJxtJN1tYf/Qiv+84xfqjF0k3W+xd0i2rVKkSEydOzPP+q1atwmAwEB0dbbOaRERERETsQc0hbGDxnkjGL9xHZExS5pi/twtvhdamW13/fH+93Dr/vfXWW4wbN+6Wn3fz5s24u7vnef9WrVoRGRmJt7f3Lb/WrVi1ahUdO3bk0qVL+Pj42PS1RERERERAwSnfLd4TyfAZ27j+/NKZmCSGz9jGlIF35Xt4ioyMzPzzL7/8wptvvsnBgwczxzw8PDL/bLFYSE9Px8Eh92+9n5/fLdXh5ORE+fLlb+kYEREREZGiQJfq5cJisZCQkpanLS4plbcW7M0WmoDMsXEL9hGXlJrluMSU9Byfz2LJ2+V95cuXz9y8vb0xGAyZjw8cOICnpyd//fUXjRs3xtnZmTVr1nD06FF69epFuXLl8PDwoGnTpixfvjzL815/qZ7BYOCbb77h/vvvx83NjerVq7NgwYLMr19/qd706dPx8fFhyZIl1KpVCw8PD7p165Yl6KWlpfHss8/i4+ND6dKlGTt2LEOGDKF37955eu85uXTpEoMHD6ZUqVJ4eHjwwAMPcPjw4cyvh4eHExoaSqlSpXB3d6dOnTosWrQo89gBAwbg5+eHq6sr1atXZ9q0abddi4iIiIhcw5yOIXwNgVHrMYSvAXO6vSvKM51xykViajq131ySL89lAc7EJlFv3NI87b/v7a64OeXPt+iVV17hww8/pEqVKpQqVYoTJ07Qo0cP3n33XZydnfnhhx8IDQ3l4MGDVKxY8YbPM378eP73v/8xYcIEJk2axIABAwgPD8fX1zfH/RMSEvjwww/58ccfMRqNDBw4kDFjxjBz5kwA/vvf/zJz5kymTZtGrVq1+PTTT5k/fz4dO3a87fc6dOhQDh8+zIIFC/Dw8OCll17i3nvvZd++fTg6OjJixAhSUlJYvXo17u7u7Nu3L/Os3BtvvMG+ffv466+/KFOmDEeOHCExMfG2axERERGRK/YtgMVjcYg9TROA8CngFQDd/gu177N3dblScCoh3n77bTp37pz52NfXlwYNGmQ+/s9//sO8efNYsGABI0eOvOHzDB06lH79+gHw3nvv8dlnn7Fp0ya6deuW4/6pqal8+eWXVK1aFYCRI0fy9ttvZ3590qRJvPrqq9x///0ATJ48OfPsz+3ICExr166lVatWmM1mvvrqK+rWrcv8+fN58MEHiYiIoG/fvtSrVw+AKlWqZB4fERFBo0aNaNKkCWA96yYiIiIid2jfApg9GK6/Nis20jr+0A+FPjwpOOXC1dHEvre75mnfTWFRDJ22Odf9pj/alGaVrWdozGYzcbFxeHp5Zrsxqquj6dYLvoGMIJDh8uXLjBs3jj///JPIyEjS0tJITEwkIiLips9Tv379zD+7u7vj5eXFuXPnbri/m5tbZmgC8Pf3z9w/JiaGs2fP0qxZs8yvm0wmGjdujNlsvqX3l2H//v04ODjQvHnzzDFfX19q1qzJ/v37AXj22WcZPnw4S5cupVOnTvTt2zfzfQ0fPpy+ffuybds2unTpQu/evWnVqtVt1SIiIiIiWC/HWzyWbKEJrowZYPErENITjPn3829+0xqnXBgMBtycHPK0ta3uh7+3CzfqcWfA2l2vbXW/LMe5OplyfL7cuuXdiuu7440ZM4Z58+bx3nvv8e+//7Jjxw7q1atHSkrKTZ/H0dEx63syGG4acnLaP69rt2zliSee4NixYwwaNIjdu3fTpEkTJk2aBED37t0JDw/nhRde4PTp09xzzz2MGTPGrvWKiIiIFGnh6yD29E12sEDsKet+hZiCUz4yGQ28FVobIFt4ynj8VmhtTMb8C0S3a+3atQwdOpT777+fevXqUb58eY4fP16gNXh7e1OuXDk2b756li49PZ1t27bd9nPWqlWLtLQ0Nm7cmDkWFRXFwYMHqV27duZYUFAQTz/9NHPnzuXFF1/k66+/zvyan58fQ4YMYcaMGUycOJGvvvrqtusRERERKdHS02D/gtz3A7h81ra13CFdqpfPutX1Z8rAu7Ldx6m8De/jdDuqV6/O3LlzCQ0NxWAw8MYbb9z25XF3YtSoUbz//vtUq1aNkJAQJk2axKVLl/J0tm337t14enpmPjYYDDRo0IBevXoxbNgwpk6diru7Oy+99BKBgYH06tULgOeff57u3btTo0YNLl26xMqVK6lVqxYAb775Jo0bN6ZOnTokJyfzxx9/ZH5NRERERPIoJR62z4D1kyH65ktBMnmUs21Nd0jByQa61fWnc+3ybAqL4lxcEmU9XWhW2bdQnGnK8PHHH/PYY4/RqlUrypQpw9ixY4mNjS3wOsaOHcuZM2cYPHgwJpOJJ598kq5du2Iy5X59a7t27bI8NplMpKWlMW3aNJ577jnuvfdeUlJSaNWqFX/88UfmZYPp6emMGDGCkydP4uXlRbdu3fjkk08A672oXn31VY4fP46rqytt27bl559/zv83LiIiIlIcXT4Pm76CzV9D4iXrmKsvmFMh+TI5r3MyWLvrBRfudeUGi70XnBSw2NhYvL29iYmJwcvLK8vXkpKSCAsLo3Llyri4uBRIPWazmdjYWLy8vLI1hyiJzGYztWrV4qGHHuI///lPvjxfYZtfe3zObCU1NZVFixbRo0ePbOvZ5M5pfm1L82tbml/b0vzalub3Nlw8Cusmwc6fIO3KVVelKkOrkdCgPxxZfqWrHmQNT1dOLNipq97NssH1dMZJ7Co8PJylS5fSvn17kpOTmTx5MmFhYfTv39/epYmIiIhIbk5shnWfwv4/yAxEgY2h1bNQK/Rql7za91nD0eKxWRtFeAVAtw8KfStyUHASOzMajUyfPp0xY8ZgsVioW7cuy5cv17oiERERkcLKbIbDS2DtZxBxTSe86l2h9XPWS+5yWq9e+z4I6UnasdXs+HcJDdt2xaFKu0LdgvxaCk5iV0FBQaxdu9beZYiIiIhIbtKSYdds6yV5Fw5ax4yOUP9h6yV5ZfPwi2+jCUtwG07tjaVBcJsiE5pAwUlERERERG4mMRq2fAcbp8LlM9YxZy9o8ig0f9p6uV0JoOAkIiIiIiLZxZyEDVNg63RIuWwd8wyAFsOh8VBwuXkzheJGwUlERERERK46s8d6Od6eOWBOs46VrQ2tRkHdB8DByb712YmCk4iIiIhISWexQNhqWPeZtXV4hkptrQ0fqnXKueFDCaLgJCIiIiJSUqWnwf7fYe2nELnTOmYwQu1e1pbigXfZt75CRMFJRERERKSkSYmH7TNg/WSIjrCOObhCo4HQcgT4VrZvfYWQ0d4FFFvmdAj7F3bPsf7XnG7vinLVoUMHnn/++czHlSpVYuLEiTc9xmAwMH/+/Dt+7fx6HhERERG5icvn4e934ZM68NfL1tDkVho6vAov7IWeHyo03YDOONnCvgU3uCvyf21yV+TQ0FBSU1NZvHhxtq/9+++/tGvXjp07d1K/fv1bet7Nmzfj7u6eX2UCMG7cOObPn8+OHTuyjEdGRlKqVKl8fa3rTZ8+neeff57o6Gibvo6IiIhIoXPxqPXs0o5ZkJZkHStVydrwoUF/cHKza3lFgYJTftu3AGYPBixZx2MjreMP/ZDv4enxxx+nb9++nDx5kgoVKmT52rRp02jSpMkthyYAPz+//CoxV+XLly+w1xIREREpMU5usa5f2r+QzJ9PA+6yNnyoFVqkbkBrb7pULzcWi/Ua0LxsSbHWU57XhybrE1n/s3isdb9rj0tNyPn5LDk9T3b33nsvfn5+TJ8+Pcv45cuX+fXXX3n88ce5ePEi/fr1IzAwEDc3N+rVq8dPP/100+e9/lK9w4cP065dO1xcXKhduzbLli3LdszYsWOpUaMGbm5uVKlShTfeeIPU1FTAesZn/Pjx7Ny5E4PBgMFgyKz5+kv1du/ezd13342rqyulS5fmySef5PLly5lfHzp0KL179+bDDz/E39+f0qVLM2LEiMzXuh0RERH06tULDw8PvLy8eOihhzh79mzm13fu3EnHjh3x9PTEy8uLxo0bs2XLFgDCw8MJDQ2lVKlSuLu7U6dOHRYtWnTbtYiIiIjcNrMZDi6G77rDN/fA/gWABap3haF/wrC/oU5vhaZbpDNOuUlNgPfy627IFuvlex8EZY4YAZ8b7f5/p8Ep90vlHBwcGDx4MNOnT+e1117DcKVV5K+//kp6ejr9+vXj8uXLNG7cmLFjx+Ll5cWff/7JoEGDqFq1Ks2aNcv1NcxmM3369KFcuXJs3LiRmJiYLOuhMnh6ejJ9+nQCAgLYvXs3w4YNw9PTk5dffpmHH36YPXv2sHjxYpYvt7a59Pb2zvYc8fHxdO3alZYtW7J582bOnTvHE088wciRI7OEw5UrV+Lv78/KlSs5cuQIDz/8MA0bNmTYsGG5vp+c3l9GaPrnn39IS0tjxIgRPPzww6xatQqAAQMG0KhRI6ZMmYLJZGLHjh04OjoCMGLECFJSUli9ejXu7u7s27cPDw+PW65DRERE5LalJcOu2dZ7MF04aB0zOkL9h6yX5JWtZd/6ijgFp2LiscceY8KECfzzzz906NABsF6m17dvX7y9vfH29mbMmDGZ+48aNYolS5Ywe/bsPAWn5cuXc+DAAZYsWUJAgDVIvvfee3Tv3j3Lfq+//nrmnytVqsSYMWP4+eefefnll3F1dcXDwwMHB4ebXpo3a9YskpKS+OGHHzLXWE2ePJnQ0FD++9//Uq5cOQBKlSrF5MmTMZlMhISE0LNnT1asWHFbwWnFihXs3r2bsLAwgoKswfaHH36gTp06bN68maZNmxIREcFLL71ESEgIANWrV888PiIigr59+1KvXj0AqlSpcss1iIiIiNyWxGjYOg02fAmXz1jHnL2g8VBoMdy61l7umIJTbhzdrGd+8iJ8Hcx8IPf9BsyB4FaA9UxHbFwcXp6eGI3XXTnpmPdFeiEhIbRq1YrvvvuODh06cOTIEf7991/efvttANLT03nvvfeYPXs2p06dIiUlheTkZNzc8vYa+/fvJygoKDM0AbRs2TLbfr/88gufffYZR48e5fLly6SlpeHl5ZXn95HxWg0aNMjSmKJ169aYzWYOHjyYGZzq1KmDyXT1FLO/vz+7d+++pde69jWDgoIyQxNA7dq18fHxYf/+/TRt2pTRo0fzxBNP8OOPP9KpUycefPBBqlatCsCzzz7L8OHDWbp0KZ06daJv3763ta5MREREJM9iTsGGL2Dr95ASZx3z9IcWz0DjIeCS/coeuX1a45Qbg8F6uVxetqp3X0n0N7qrsgG8Aq37XXuco1vOz3eLd2d+/PHH+e2334iLi2PatGlUrVqV9u3bAzBhwgQ+/fRTxo4dy8qVK9mxYwddu3YlJSXlzubnGuvXr2fAgAH06NGDP/74g+3bt/Paa6/l62tcK+MyuQwGgwGz2WyT1wJrR8C9e/fSs2dP/v77b2rXrs28efMAeOKJJzh27BiDBg1i9+7dNGnShEmTJtmsFhERESnBzu6FeU/Dp/WtnfJS4sCvFvSeAs/tgtbPKjTZgIJTfjKarC3Hgezh6crjbh/YbCHeQw89hNFoZNasWfzwww889thjmeud1q5dS69evRg4cCANGjSgSpUqHDp0KM/PXatWLU6cOEFkZGTm2IYNG7Lss27dOoKDg3nttddo0qQJ1atXJzw8PMs+Tk5OpKff/J5WtWrVYufOncTHx2eOrV27FqPRSM2aNfNc863IeH8nTpzIHNu3bx/R0dHUrl07c6xGjRq88MILLF26lD59+jBt2rTMrwUFBfH0008zd+5cXnzxRb7++mub1CoiIiIlkMUCYathRl+Y0gp2/gTmNKjUFvr/Cs+sh4b9wcHJ3pUWWwpO+a32fdaW417+Wce9AmzSivxaHh4ePPzww7z66qtERkYydOjQzK9Vr16dZcuWsW7dOvbv389TTz2VpWNcbjp16kSNGjUYMmQIO3fu5N9//+W1117Lsk/16tWJiIjg559/5ujRo3z22WeZZ2QyVKpUibCwMHbs2MGFCxdITk7O9loDBgzAxcWFIUOGsGfPHlauXMmoUaMYNGhQ5mV6tys9PZ0dO3Zk2fbv30+nTp2oV68eAwYMYNu2bWzatInBgwfTvn17mjRpQmJiIiNHjmTVqlWEh4ezdu1aNm/eTK1a1kWWzz//PEuWLCEsLIxt27axcuXKzK+JiIiI3Lb0NNjzG3zVAb4PhSPLwWCE2r2t3fGG/gE1utzylUpy67TGyRZq3wchPa1rni6fBY9y1jVNBdDy8fHHH+fbb7+lR48eWdYjvf766xw7doyuXbvi5ubGk08+Se/evYmJicnT8xqNRubNm8fjjz9Os2bNqFSpEp999hndunXL3Oe+++7jhRdeYOTIkSQnJ9OzZ0/eeOMNxo0bl7lP3759mTt3Lh07diQ6Oppp06ZlCXgAbm5uLFmyhOeee46mTZvi5uZG3759+fjjj+9obsDaor1Ro0ZZxqpWrcqRI0f4/fffGTVqFO3atcNoNNKtW7fMy+1MJhMXL15k8ODBnD17ljJlytCnTx/Gjx8PWAPZiBEjOHnyJF5eXnTr1o1PPvnkjusVERGREiolHrbPtF6KF33lCh4HV2g0AFqOAF81oipoBosljzcLKiZiY2Px9vYmJiYmW9OCpKQkwsLCqFy5Mi4uLgVSj9lsJjY2Fi8vr+zNIeSOFcb5tcfnzFZSU1NZtGgRPXr0yLbmTO6c5te2NL+2pfm1Lc2vbdl1fuMvwKavrFviJeuYqy80fwqaDgP30gVbjw0Ups/vzbLB9XTGSURERETE3i4etZ5d2jEL0pKsY6UqQcuR0HAAOOW927LYhoKTiIiIiIi9nNwCaz+F/QuBKxeCBdxl7YxX674CWeoheaPgJCIiIiJSkMxmOLwU1n0G4WuvjlfvAq2ehUpt1OyhEFJwEhEREREpCGnJsPtXWDcJzh+wjhkdof5D0GoUlFVH3sLMrqvlV69eTWhoKAEBARgMBubPn5/nY9euXYuDgwMNGzbM97pKWL8MKWD6fImIiJQwSTGwZiJMrA+/j7CGJidP69ml53dB7y8UmooAu55xio+Pp0GDBjz22GP06dMnz8dFR0czePBg7rnnnlu6F1FuMrp6JCQk4Orqmm/PK3KthIQEALt3kREREREbizkFG76Ard9DSpx1zNMfWgyHxkPBxduu5cmtsWtw6t69O927d7/l455++mn69++PyWS6pbNUuTGZTPj4+HDu3DnAej8hg42vLzWbzaSkpJCUlFRo2mUXJ4Vpfi0WCwkJCZw7dw4fHx9MJi32FBERKZbO7rVejrf7VzCnWcf8alkvx6v3IDg42bc+uS1Fbo3TtGnTOHbsGDNmzOCdd97Jdf/k5GSSk5MzH8fGxgLW/vGpqanZ9i9dujTp6en5eibrZiwWC0lJSbi4uNg8pJVEhXF+vby8KF26dI6fv6Im4z0Uh/dSGGl+bUvza1uaX9vS/NrWbc2vxYIhfA3GDZ9jPLo8c9hcsRXmFiOxVOsEBqO1cV4J/74Vps/vrdRQpILT4cOHeeWVV/j3339xcMhb6e+//z7jx4/PNr506VLc3G7cD99gMOiMgOS79PT0YrnGadmyZfYuoVjT/NqW5te2NL+2pfm1rbzMr8GSjn/0Fqqf/ROfxOMAWDBw2qcpR8r2INq9ChxOg8OLbVxt0VMYPr8ZSyjyosgEp/T0dPr378/48eOpUaNGno979dVXGT16dObj2NhYgoKC6NKlS653By4IqampLFu2jM6dO2vNiw1ofm1L82tbml/b0vzalubXtjS/tpWn+U1NwLjzJ4wbv8AQHQ6AxcEVc4N+mJsPp2ypypQtwJqLksL0+c24Gi0vikxwiouLY8uWLWzfvp2RI0cC1vUrFosFBwcHli5dyt13353tOGdnZ5ydnbONOzo62v0bda3CVk9xo/m1Lc2vbWl+bUvza1uaX9vS/NpWjvMbfwE2fQWbvobEKOuYqy80exJDs2GY3Muga5bypjB8fm/l9YtMcPLy8mL37t1Zxr744gv+/vtv5syZQ+XKle1UmYiIiIgUexePwvrPYcdMSEuyjpWqBC1HQsMB4HTjJSBSPNg1OF2+fJkjR45kPg4LC2PHjh34+vpSsWJFXn31VU6dOsUPP/yA0Wikbt26WY4vW7YsLi4u2cZFRERERPLFya2w7lPYvxAsZutYQCPrPZhq3QemInMeQu6QXb/TW7ZsoWPHjpmPM9YiDRkyhOnTpxMZGUlERIS9yhMRERGRkshiplzMDkw/ToGI9VfHq3exBqZKbaCQdOuVgmPX4NShQ4ebdhibPn36TY8fN24c48aNy9+iRERERKRkSkuG3b/isPYzWlw4aB0zOlrvvdRqFJSrbd/6xK50blFERERESrakGNgyDTZ+CXGRGIBUowvGZo9jajkCvAPtXaEUAgpOIiIiIlIyxZyCjVNgy3RIibOOefqT3nQYSy8E0OWeBzCpa6FcoeAkIiIiIiXL2X2wbhLs/hXMqdYxvxDr+qV6D2K2GEhbtMi+NUqho+AkIiIiIsWfxQLH18DaT+HIsqvjwW2g9bNQrTMYjdax1FT71CiFmoKTiIiIiBRf6WmwfwGs+wxOb7eOGYxQKxRaPQcVGtu3PikyFJxEREREpPhJSbDerHb9ZLh03Drm4GK9WW3LEVC6ql3Lk6JHwUlEREREio/4C7Dpa9j0FSRGWcdcfaHZMGj2JLiXsW99UmQpOImIiIhI0Rd1DNZ/DttnQFqSdcwn2Hr/pYYDwMnNvvVJkafgJCIiIiJF16mt1oYP+xeCxWwdC2hk7ZBX6z4w6cddyR/6JImIiIhI0WI2Wzvjrf0MwtdcHa/WGVo/B5XagMFgv/qkWFJwEhEREZGiIS3Feu+ldZPg/H7rmNEB6j1ovSSvXB371ifFmoKTiIiIiBRuSTGwdTps+BLiTlvHnDyh8RBoMRy8K9i1PCkZFJxEREREpHCKPQ0bpsCWaZASZx3zKG8NS00eBRdv+9YnJYqCk4iIiIgULmf3WS/H2/0rmFOtY34h1svx6j0IDs72rU9KJAUnEREREbE/iwWOr4F1n8HhpVfHg1tbGz5U6wxGo/3qkxJPwUlERERE7MecDvsXWDvknd52ZdAAtUKtgalCE7uWJ5JBwUlERERECl5KAuyYab1p7aUw65iDi/VmtS1HQOmq9q1P5DoKTiIiIiJScOIvwuavYdNXkHDROuZaCpo9CU2HgYeffesTuQEFJxERERGxvahj1rNL22dCWqJ1zCcYWo6ERgPAyd2+9YnkQsFJRERERGzn1Fbr+qX9C8Bito75N7SuX6p1H5j046gUDfqkioiIiEj+sljg8DJrh7zj/14dr9bJGpgqtQWDwX71idwGBScRERERyR9pKbBnjvUeTOf2WceMDtZ7L7UaBeXq2Lc+kTug4CQiIiIidyYpFrZOhw1TIO60dczJExoPgRbDwbuCXcsTyQ8KTiIiIiJye2JPW8PS1umQHGsd8ygPLZ6Gxo+Cq489qxPJVwpOdpRutrAxLIqtFwyUDouiZbWymIy63ldEREQKuXP7rZfj7ZoN5lTrWJma0PpZ62V5Ds72rU/EBhSc7GTxnkjGL9xHZEwSYOKHw1vw93bhrdDadKvrb+/yRERERLKyWCB8rbVD3uElV8crtrI2fKjeBYxG+9UnYmMKTnaweE8kw2dsw3Ld+JmYJIbP2MaUgXcpPImIiEjhYE6H/Qth7adwetuVQQPUCrUGpgpN7FqeSEFRcCpg6WYL4xfuyxaaACyAARi/cB+da5fXZXsiIiJiP6mJsGMmrJsMl8KsYw4u0LC/9aa1pavatz6RAqbgVMA2hUVduTwvZxYgMiaJTWFRtKxauuAKExEREQGIvwibv4ZNX0HCReuYayloOgyaPQkefvatT8ROFJwK2Lm4G4em29lPREREJF9EhcH6z2H7DEhLtI75VISWo6DRAHByt299Inam4FTAynq65Ot+IiIiInfk1DZY9xns+x0sZuuYf0Nrh7xavcCkHxdFQMGpwDWr7Iu/twtnYpJyXOcEUM7LmWaVfQu0LhERESlBLBY4stza8OH4v1fHq3WCVs9C5XZg0FprkWspOBUwk9HAW6G1GT5jGwbIMTylplnYdzqWehW8C7o8ERERKc7SUmDPHOs9mM7ts44ZHaDuA9BqFJSva9/6RAoxNdu3g251/Zky8C7Ke2e9HM/Pw5myns5EJaTQ98t1/LrlhJ0qFBERkWIlKdZ6/6VPG8D84dbQ5ORh7Y733E7oM1WhSSQXOuNkJ93q+tO5dnnWHznH0n830qVtc1pWK8vl5DRenL2D5fvP8dKcXew8Gc2b99bByUEZV0RERG5RbCRsnAJbpkFyrHXMoxy0GA6NHwVXH7uWJ1KUKDjZkclooHllXy7ut9C8si8mowFvV0e+GtSEySuP8MnyQ8zYEMG+07FMGdiYcl5qGCEiIlLimdMxhK8hMGo9hnAvqNIOjKas+5w7YL0cb9cvYE61jpWpab0cr/5D4OBc8HWLFHEKToWQ0Wjg2XuqUy/Qm2d/3s62iGjunbSGLwbcRdNKahohIiJSYu1bAIvH4hB7miYA4VPAKwC6/RdqhUL4OmvDh8NLrh5TsZW1Q171rmDUFSwit0vBqRDrGFKWhSPb8NSPWzl4No5+X23gjXtrM7hlMAZ1uhERESlZ9i2A2YPJ1loqNhJmDwLfKhB17MqgAWrdC62eg6CmBV2pSLGkXzsUcpXKuDNvRCtCGwSQZrbw1oK9vDh7J4kp6fYuTURERAqKOR0WjyXnfrxXxqKOgdHJunZp1FZ4eIZCk0g+UnAqAtycHPjskYa83rMWJqOBudtP0XfKOk5EJdi7NBERESkI4esg9nTu+z3wHYROhNJVbV6SSEmjS/WKCIPBwBNtq1A7wItRs7azLzKW0MlrmNSvEW2r+9m7PBEREckvidFw4RCcPwDnD1q3U9vydmx6sk1LEynJFJzsKS9dca7TqmoZFo5qw/AZW9l5MoYh321iTNeaDG9fVeueREREigqLBeIvwIWDWQPS+YNw+cztP69HufyrUUSyUHCyl5t1xal9300PDfBx5ZenWvLW73v5ZcsJ/rf4ILtOxPDhQw3wcNa3VEREpNCwWKyX2F3ICEYH4PyVs0mJUTc+zjMA/Gpe3UpXh9+egMtnyXmdk8H6c0RwK1u9E5ESTz9l28NNu+IMhod+yDU8uTia+O8D9WkQ5MNbC/aweO8ZDk+OY+qgJlQr62G72kVERCQ7sxmiw63h6PqQlBJ3g4MM4FMR/EKuCUkhUKY6uHhn373HhCs/PxjI+jPElStOun2Q65UrInL7FJwKWq5dcQyw+BUI6Zmnv/z6N69IiL8nz8zYxtHz8fT+fC0fPdSArnXK53flIiIikp4KUWHWUHRtQLpwBNIScz7GYLK2Cs8IRteeRXJyy/tr177P+svVxWOzNorwCrCGplx+6Soid0bBqaDl2hXHArGnrPtVbpunp7yrYikWjmrDiFnb2BQWxVM/bmVkx2q80LkGJqPWPYmIiNyy1CS4eOTq+qOMkHTxKJhTcz7G5ARlalg3vxDwu/Jf36rg4JQ/ddW+D0J6knZsNTv+XULDtl1xyMMaaRG5cwpOBe3y2bzt9+9HEB0BAQ2hTE0w3fxb5efpzMwnmvP+ogN8tzaMySuPsPtUDJ8+0hAft3z6y1pERKS4Sb58JRRdWXeU0c3u0nGwmHM+xtHdGorK1Mx6FsknONd/r/OF0YQluA2n9sbSILiNQpNIAVFwKmh57XZzbKV1A3BwhfL1rCEqoBH4N7T+Nuu6v5wdTUbeDK1N/QrevDJ3F/8cOk/o5DVMHdiE2gFe+fo2REREipTES1k712WEpJgTNz7GxftqKCpT8+pZJK8KYNStMEVKGgWnghbcynotcmwkOa9zAlxLQYN+ELkLIndAymU4ucm6ZXBwBf/61hAV0OjKmakaYDTRu1EgNcp58tSMLZyISqTPlLV80Kc+vRsF2v79iYiI2IvFAvHnr2vvfSUg3eyKD3e/6wLSlZDkURZ0qw8RuULBqaAZTdaW4zfrihP62dUFnmYzRB2F09vh9A5rkIrcaQ1TJzZatwyOblC+PgQ0pLZ/Q/58pC7PLrvMqsNRPP/LDnaejOb/etTC0aTfkomISBFmubIe+Pr7H50/AEnRNz7Oq8LVdUfXhiQ33wIrXUSKLgUne7iVrjhGo7UtaZnqUP8h65jZbF2wenq7NUid3mENU6nxcGKDdQO8gGmO7pzyq8bSS/7sXl+Zl8Mb8X+DQvHzvoUuPiIiIvZgTreuNcpYd5QRkC4csv4CMUcGKFXpuvbeNa+0+NZl6yJy+xSc7OVOuuIYjVd+Y1YDGjxsHTOnXwlTO64GqsidGFLjqZC6k8ccdlr3uwAJn7gQV64+npWbXL3Ur3Q1Xa8tIiL2kZYCUcey3//owiFIT875GKODtVud33UNGkpXA0fXgq1fREoEBSd7ys+uOEbT1X88rg1TFw5fOSu1ncSIrRC5CzeS4Owm65bByePKZX6Nrjah8K2qMCUiIvknNdH671Jme+8rZ5GijoE5LedjTM5X2nvXzBqSfKuAybFg6xeREk3BqTgzmqBsiHVr8AiuwOXEZN6etZDoo5upZwyjo9cpglOOYki5DBHrrFsGJ09rA4qMTn4Bjaz/UClMiYjIzSTHYYjcR9DFfzH+vRkuHr7S4jucGzZGcvK45v5H14Qkn2C12xaRQkHBqYTxcHXmjcf68uU/jfjPkgOMj4JGgR5M7e5J2csHrl7qd2Y3pMRB+FrrlsHZK7MBRWagUpgSESmZEqKuubTumpvExp7CAbgLIOK6Y1x8rglH19wk1itQHexEpFBTcCqBDAYDwztUpW6gF6N+2s72U5fp/lMKk/p3oVWP/tad0tOs/wBmdPLLCFPJsRC+xrplcPYC/wbWMJVxZqpUZYUpEZHiwGKxtvLOWHd07U1i48/f+DD3slwwlMG3ZktM5WpdDUvufgpIIlIkKTiVYG2r+7FwZBuenrGVvadjGfTtJl7tHsLjbSpjMDlAuTrWrdEA6wHpadZ/KDM6+Z3eDmf3WMPU8X+tWwZn76uX+WUEKt8q+sdSRKSwMpsh9mTW1t4ZZ5GSYm58nHdQ9vsf+dUgzcGDdYsW0aNbD0yOWoskIkWfglMJF+Trxm/DW/F/c3czd/sp3vlzPztPxvDfvvVwc7ru42FygPJ1rVujgdax9FTrP65ZzkztgeSY7GHKxdt6Zuram/aWqqwwJSJSkNLTIDr8SjC69izSYettLXJiMF5p8X3d/Y/K1ABnj5yPSU212VsQEbEHBSfBxdHERw81oGFFH95euI+FO09z6EwcUwc1plIZ95sfbHKE8vWsG4OsY5lhavs1Z6b2Wn9jGbbaumW+uM/Vy/wy1kyVqqQwJSJyp9JSrDdQv/4msRcPQ3pKzscYHa3tvDPWHWU0ayhdDRxdCrZ+EZFCRsFJAOu6p8EtK1HL34tnZm7j4Nk4Qiev4dNHGnJ3SLlbe7Jrw9Rdg61j6alwbn/Wm/ae3WO9w3vYP9Ytg4tP1vVSAQ2tXZUUpkREsktJsK45uv4msVHHwJKe8zEOLte1+L5yk1jfymrxLSJyAwpOkkXTSr78MaoNz8zcxtbwSzz+/Raev6cGo+6uhtF4B8HF5Ghd8+RfHxhiHUtLgfP7r56Zitxx5cxUNBxbZd0yuJa6EqQaXj0z5VNRYUpESo6kmCs3hT2YNSBFR3DjFt+e2bvXlalh/ftTLb5FRG6JgpNkU87LhZ+GteA/f+zjxw3hfLL8ELtORvPxww3xds3H30Q6OF1Z89QAGl8ZS0uBc/uuOzO1FxIvwbGV1i2Dq2/2M1PeQQpTIlK0xV+8uv7o2rNIcZE3PsbVN/v9j/xCwNNffyeKiOQTBSfJkZODkf/0rkv9Ct68Nn8PKw6co/fna5k6qDE1ynna7oUdnK6cVWp4dSwt+UqY2nE1UJ3dB4lRcPRv65bB1TdrJ7+y9aytdEVEChOLxRqEMs4aXbimk13CxRsf5+l/zU1iM/4bAu5lCq52EZESSsFJburBJkGElPfi6RlbCbsQT+/P1zLhgQb0rO9fcEU4OF8JQ42AR61jacnWM1EZnfxO77CGq8QoOLrCugGOQDcHT0yxP0Bgo6uX+ulGiyJSEMxmiIm42rnu2pCUHHvj43wqXtfe+0oHO1efAitdRESyUnCSXNWr4M3CUW0Y9dM21h65yIhZ29h1sgovda2Jg8lON7l1cIbAu6xbhtQkOLc3y5kpy7n9OKfFwbEV1i2DW5ms66UCGoFXgMKUSElhTscQvobAqPUYwr2gSrs7W/OTngaXwrKuPbpw0BqY0hJzPsZgtN7f7trudX41rH92yqWjqYiIFDi7BqfVq1czYcIEtm7dSmRkJPPmzaN379433H/u3LlMmTKFHTt2kJycTJ06dRg3bhxdu3YtuKJLKF93J75/tBkTlh5k6j/HmLr6GLtPxTCpXyNKezjbuzwrRxcIbGzdrkhLjGPdvK9pU8Ud09ldcHqn9cxUwgU4sty6ZXD3y7peKqCR1geIFEf7FsDisTjEnqYJQPgU6y9Ouv0Xat9382PTkuHikaz3Pzp/0DpmvsF9i4yOUKZ69pvElq5q/SWQiIgUCXYNTvHx8TRo0IDHHnuMPn365Lr/6tWr6dy5M++99x4+Pj5MmzaN0NBQNm7cSKNGjQqg4pLNwWTk1e61qB/ow0tzdrLu6EXum7yWLwc2pl4Fb3uXlzMHF6Ldq2JufM2d61MTrZf5XdvN79x+iD8PR5ZZtwzuZXM4M1WAlymKSP7atwBmDyZbF7rYSOv4Qz9Yw1NK/JXGDAezhqRLYWAx5/zcjm5XAtK1Z5BCrPemM+kCDxGRos6uf5N3796d7t2753n/iRMnZnn83nvv8fvvv7Nw4UIFpwLUs74/1ct58NSP1nVPfb9cx7u96/JgkyB7l5Y3jq5QoYl1y5CaCGf2XO3kd3q79Yek+HNweKl1y+BRLuuZKf+GClMiRYE5HRaPJefW3VfG5j4Bi8tC7IkbP4+z95XGDNfc/8ivprWrp9FOly+LiIjNFelfgZnNZuLi4vD19b3hPsnJySQnJ2c+jo21LsZNTU0lNfUGl1UUoIwaCkMtt6Kyrwu/PdWMMXP28PfB87w0ZxfbI6J4rXsITg6F5weHvM+vA5RvaN0yMnhqAoazezFE7sRwZieGyB1w4SCGy2fh8BLrdoXFoxyW8g2w+DfE4t8AS/kG4FneBu+ocCmqn9+iQvN7CywWSI6DxCgMiZes94NLvIQhMdraNCbpEobzhzDGnr7586QlZ4Ymi1sZLGVqYClTA8rUvPpnj/I5X8Kbnm7dBNDn19Y0v7al+bWtwjS/t1KDwWIpHL2aDQZDrmucrve///2PDz74gAMHDlC2bNkc9xk3bhzjx4/PNj5r1izc3Nxut1y5wmyBZacM/HXCiAUDlTwsPFYzHW8ne1dmGyZzMl6JEfgkhOGTcByfhDA8k05jyOE32ImOpYh2rUS0W2Vi3CoR7VaJZEefgi9apCixmHFIT8Qp/TJOafE4XvmvU3o8jmmXrxu/bB1Pj8cxLR4jN7iE7hYdKN+bML/OpDjY8NYLIiJSKCQkJNC/f39iYmLw8vK66b5FNjjNmjWLYcOG8fvvv9OpU6cb7pfTGaegoCAuXLiQ6+QUhNTUVJYtW0bnzp1xdMzHm8sWsFWHzvPir7uJTUqjjIcTkx5pQJPgUvYuq2DmNyUew7m9GCJ3ZJ6d4sIhDDmsg7B4+mc/M+WRc+gvCorL57ewKtLzazFDUszVsz5Jl6782fpfkqKv/jnxEoakS5AYbR2/0RqivLysg6u1ZbdrKSwuPtZ7u7n6YHEtBYkxmHb8kOtzpA2cjyW4zW3XIFZF+vNbBGh+bUvza1uFaX5jY2MpU6ZMnoJTkbxU7+eff+aJJ57g119/vWloAnB2dsbZOXvXIkdHR7t/o65V2Oq5VZ3rBLCgnDdPz9jKgTNxDPpuC2/cW5vBLYMxFIKudDadX0cfqNzaumVIiYczu7M2oDh/EENcJIa4SDi8+Oq+XoFX1kw1vNqEwsPPNrXaSFH//BZ2dp1fc3pmAMrcEqKyPk68ZL0cLsvjaHJeS5RHjm7gWurGm5tvjuMGR9fMp8j2N485HY4ttzaCyLE2A3gF4HCnrcklC/39YFuaX9vS/NpWYZjfW3n9IhecfvrpJx577DF+/vlnevbsae9y5BqVyrgz95lWjP1tNwt3nuatBXvZeSKad++vh6tTCfshxMkdKrawbhmSL18NUxlNKC4cgthT1u3gn1f39apwtfFERhMK9zIF+hakmElPuy4A5RB+cgpESTHcWQByvxJ0cgpAOYQfN19w8bHeXiC/GU3WluOzB2ONVde+rysxq9sHCk0iIpIjuwany5cvc+TIkczHYWFh7NixA19fXypWrMirr77KqVOn+OEH66UVs2bNYsiQIXz66ac0b96cM2fOAODq6oq3dyFth13CuDk58NkjDWlQwZv3/zrA3O2nOHAmjqmDGhPkW8LXlDl7QHBL65YhOe5KmNpxNVBdOAyxJ63bgT+u7psRpjLPTDUC99IF+x7E/tLTMhsf5Bx2cgpElyA55s5e18kj87K33M/8ZIz5FL77FNW+z9pyfPFYuLZRhFeANTTldh8nEREpsewanLZs2ULHjh0zH48ePRqAIUOGMH36dCIjI4mIiMj8+ldffUVaWhojRoxgxIgRmeMZ+0vhYDAYeKJtFWoHeDFq1nb2RcYSOnkNnz3SiHY1itYlaDbn7AnBraxbhuQ4iNx15azUlUv9Lt4gTHkHXXdmqpH1B1kp/NJTrZez3eTsjynhIi1PHMH07UdXw1Jy7J29rrNX9vBzozM/GX928QGHYtTxpfZ9ENKTtGOr2fHvEhq27arL80REJFd2DU4dOnTgZr0prg9Dq1atsm1Bkq9aVS3DwlFtGD5jKztPxjBk2ibGdKnJMx2qFop1T4WWsydUam3dMiTFwpldWc9MXTwCMSes2/6FV/f1rnj1zFRGoFKYsp20FGuoydO6nytnfxIvQUpcrk9tBMoC5LSrs3fWAHTTMz+lrp4BMulafQCMJizBbTi1N5YGwW0UmkREJFdFbo2TFC0BPq788lRLxi3Yy8+bTzBhyUF2n4zhw4ca4OGsj1+euXhBpTbWLUNSTPYzU1FHISbCuu1fcHVfn4pXG09kBCqFqazSkq+cAYrKduYn50AUfSUAXb6z13XxvmHYSXf2YufBCOq36ICDp1/WM0Am/f8jIiJSkPQvr9ici6OJD/rWp0GQD2/9vpfFe89weHIcUwc1oVpZD3uXV3S5eEPlttYtQ1IMRO7MemYq6hhER1i3fb9f3dcn+GrjiYxA5XoLLeTN6RjC1xAYtR5DuBcUlkud0pJv/exP4iVIjb+DFzVkDUB5Ovtz5QzQTebMnJrKiQuLqFe9C6irk4iIiF0pOEmB6desIjXLe/LMjG0cPR9P78/X8tFDDehap7y9Sys+XLyhcjvrliEx2hqmMjr5nd4Ol8IgOty67Zt/dd9SlbJ28vNvkHOY2rcAFo/FIfY0TQDCp1xZXP/f/Ftcn5qYt65v12+pCXfwooZrLn/LZd3PtZuLd+EIjSIiImIzCk5SoO6qWIqFo9owYtY2NoVF8dSPWxnRsSqjO9fEZNS6J5tw9YEq7a1bhsRLV89MZVzqd+n41S1LmKqc9R5Tsadh/nCytaiOjbS2eX7oh6zhKSUhD2d+rrn0LWNLS7z992wwWi9ny+uZn4xW2c7eYDTe/uuKiIhIsaXgJAXOz9OZmU805/1FB/hubRifrzzKnlOxfPpIQ3zcilHnrsLMtRRU6WDdMmSGqe1Xz0xFh1vPTl0Kg73zcnnSK0Hqt8dhZdWrXeDSkm6/ToMpjzc/9ckaiJy9FIBEREQkXyk4iV04moy8GVqbBkHejP1tF/8cOk/o5DVMHdiE2gFe9i6vZMopTCVEXQ1TkTsgfD3En7v586SnwPn9WceMDrmc+fHJORA5eSoAiYiISKGg4CR21athINXLevLUjC2ciEqkz5S1fNCnPr0bBdq7NAFrkKna0boB7J5jPaOUmzajoXava84AeYJa0IuIiEgRpl/lit3VDvBi4cg2tK/hR1Kqmed/2cH4hXtJTTfbuzS5nke5vO1X9W7ruqhSwdZW6gpNIiIiUsQpOEmh4OPmxHdDmzLq7moATFt7nAHfbOR8XLKdK5MsgltZu+dxoyBkAK9A634iIiIixYiCkxQaJqOBF7vU5KtBjfFwdmBTWBT3TvqXbRGX7F2aZDCarC3Hgezh6crjbh+oNbeIiIgUOwpOUuh0qVOe30e2plpZD87GJvPw1PXM3BiOxWLJ/WCxvdr3WVuOe/lnHfcKyN6KXERERKSYUHCSQqmqnwfzR7Sme93ypKZbeG3eHl75bTdJqen2Lk3AGo6e30PawPlsCR5O2sD58PxuhSYREREpthScpNDycHbgiwF3MbZbCEYD/LLlBA9PXc/p6Du4MarkH6MJS3AbTvm2xBLcRpfniYiISLGm4CSFmsFgYHiHqnz/WDN83BzZeTKG0ElrWHf0gr1LExEREZESRMFJioS21f1YOLINdQK8uBifwqBvN/HNv8e07klERERECoSCkxQZQb5u/Da8FX3uCiTdbOGdP/cz6qftJKSk2bs0ERERESnmFJykSHFxNPHRgw14u1cdHIwG/tgVyf2fr+P4hXh7lyYiIiIixZiCkxQ5BoOBwS0r8fOTLfDzdObg2ThCJ6/h7wNn7V2aiIiIiBRTCk5SZDWp5Msfo9rQOLgUcUlpPP79Fj5dfhizWeueRERERCR/KThJkVbOy4WfhrVgUItgLBb4ZPkhhv2whZjEVHuXJiIiIiLFiIKTFHlODkb+07suEx6oj5ODkRUHztH787UcPBNn79JEREREpJhQcJJi48EmQfz2dCsCfVwJuxDP/V+sZdHuM/YuS0RERESKAQUnKVbqVfBm4ag2tK5WmoSUdJ6bvYvfw42kpZvtXZqIiIiIFGEKTlLs+Lo78f2jzXi6fVUA/j5t5LEftnHxcrKdKxMRERGRokrBSYolB5ORV7qH8NnD9XEyWlh/LIr7Jq9l18loe5cmIiIiIkWQgpMUa93rlmd0vXQqlXbjVHQiD3y5ntlbTti7LBEREREpYhScpNjzd4O5TzenU61ypKSZeXnOLl6bt5uUNK17EhEREZG8UXCSEsHTxZGvBjXmxc41MBhg5sYIHvlqPWdjk+xdmoiIiIgUAQpOUmIYjQZG3VOd74Y0xcvFgW0R0fT8bA2bwqLsXZqIiIiIFHIKTlLidAwpy4KRbQgp78mFy8n0/3oD09eGYbFY7F2aiIiIiBRSCk5SIlUq487cZ1oR2iCANLOFcQv38eLsnSSmpNu7NBEREREphBScpMRyc3Lgs0ca8nrPWpiMBuZuP0XfKes4EZVg79JEREREpJBRcJISzWAw8ETbKsx4vDml3Z3YFxlL6OQ1rD503t6liYiIiEghouAkArSsWpo/nm1DgyAfohNSGTJtE5+vPKJ1TyIiIiICKDiJZPL3duWXJ1vwSNMgLBaYsOQgT8/YyuXkNHuXJiIiIiJ2puAkcg0XRxMf9K3P+33q4WQysmTvWXpNXsORc5ftXZqIiIiI2JGCk0gO+jWryC9PtaC8lwtHz8fT+/O1LNl7xt5liYiIiIidKDiJ3ECjiqVYOKoNzSr7cjk5jad+3MqEJQdIN2vdk4iIiEhJo+AkchN+ns7MfKI5j7WuDMDnK4/y6PTNRCek2LkyERERESlICk4iuXA0GXkztDafPtIQF0cjqw+dJ3TyGvadjrV3aSIiIiJSQBScRPKoV8NA5j3Tmoq+bpyISqTPlLXM337K3mWJiIiISAFQcBK5BbX8vVg4sg0davqRlGrm+V92MH7hXlLTzfYuTURERERsSMFJ5BZ5uzny7ZCmjLq7GgDT1h5nwNcbOReXZOfKRERERMRWFJxEboPJaODFLjX5alBjPJwd2HQ8itBJa9gWccnepYmIiIiIDSg4idyBLnXK8/vI1lQr68HZ2GQenrqemRvDsVjUslxERESkOFFwErlDVf08mD+iNd3rlic13cJr8/bwym+7SUpNt3dpIiIiIpJPFJxE8oGHswNfDLiLV7qHYDTAL1tO8NDU9ZyKTrR3aSIiIiKSDxScRPKJwWDg6fZV+f6xZvi4ObLrZAyhk9aw7ugFe5cmIiIiIndIwUkkn7Wt7sfCkW2oE+BFVHwKA7/ZyNerj2ndk4iIiEgRpuAkYgNBvm78NrwVfe4KxGyBdxftZ9RP20lISbN3aSIiIiJyGxScRGzExdHERw824D+96uBgNPDHrkju/3wdxy/E27s0EREREblFCk4iNmQwGBjUshI/P9kCP09nDp6NI3TyGv4+cNbepYmIiIjILVBwEikATSr58seoNjQOLkVcUhqPTd/CxOWHMJu17klERESkKFBwEikg5bxc+GlYCwa3DAZg4vLDDPthCzGJqXauTERERERyo+AkUoCcHIy83asuHz7YAGcHIysOnKP352s5eCbO3qWJiIiIyE0oOInYwQONK/Db8FYE+rgSdiGe+79Yyx+7Ttu7LBERERG5AQUnETupG+jNwlFtaFOtDAkp6YyctZ33Fu0nLd1s79JERERE5DoKTiJ25OvuxPRHm/J0+6oAfLX6GIO/28TFy8l2rkxERERErqXgJGJnDiYjr3QP4YsBd+HmZGLd0YvcN3ktu05G27s0EREREblCwUmkkOhRz5/fR7SmShl3TkUn8sCX65m95YS9yxIRERERFJxECpXq5TyZP7I1nWqVIyXNzMtzdvHavN2kpGndk4iIiIg9KTiJFDJeLo58NagxL3augcEAMzdG8PBX6zkbm2Tv0kRERERKLAUnkULIaDQw6p7qfDekKV4uDmyPiKbnZ2vYFBZl79JERERESiQFJ5FCrGNIWRaOakNIeU8uXE6m/9cbmL42DIvFYu/SREREREoUuwan1atXExoaSkBAAAaDgfnz5+d6zKpVq7jrrrtwdnamWrVqTJ8+3eZ1ithTcGl35j7TivsaBJBmtjBu4T5enL2TxJR0e5cmIiIiUmLYNTjFx8fToEEDPv/88zztHxYWRs+ePenYsSM7duzg+eef54knnmDJkiU2rlTEvtycHPj0kYa8cW9tTEYDc7efou+UdZyISrB3aSIiIiIlgoM9X7x79+507949z/t/+eWXVK5cmY8++giAWrVqsWbNGj755BO6du1qqzJFCgWDwcDjbSpT29+LkbO2sS8ylnsnrWFSv0a0q+Fn7/JEREREijW7BqdbtX79ejp16pRlrGvXrjz//PM3PCY5OZnk5OTMx7GxsQCkpqaSmppqkzpvRUYNhaGW4qg4zm+Til7MG96CkT/vYNfJWIZM28Toe6rxVLvKGAyGAq2lOM5vYaL5tS3Nr21pfm1L82tbml/bKkzzeys1GCyFZJW5wWBg3rx59O7d+4b71KhRg0cffZRXX301c2zRokX07NmThIQEXF1dsx0zbtw4xo8fn2181qxZuLm55UvtIvaQZoY5YUbWn7NecVvf18yAqmZcitSvQ0RERETsJyEhgf79+xMTE4OXl9dN9y32P2K9+uqrjB49OvNxbGwsQUFBdOnSJdfJKQipqaksW7aMzp074+joaO9yip3iPr/3Ab9sOcn4P/azK8rIZaMnX/RvSFU/9wJ5/eI+v/am+bUtza9taX5tS/NrW5pf2ypM85txNVpeFKngVL58ec6ePZtl7OzZs3h5eeV4tgnA2dkZZ2fnbOOOjo52/0Zdq7DVU9wU5/kd2LIydQJ9GD5jG8cuxPPA1I189FADutYpX2A1FOf5LQw0v7al+bUtza9taX5tS/NrW4Vhfm/l9YvUfZxatmzJihUrsowtW7aMli1b2qkikcKhUcVSLBzVhuaVfbmcnMZTP25lwpIDpJsLxZW4IiIiIkWeXYPT5cuX2bFjBzt27ACs7cZ37NhBREQEYL3MbvDgwZn7P/300xw7doyXX36ZAwcO8MUXXzB79mxeeOEFe5QvUqj4eToz44nmPN6mMgCfrzzKo9M3E52QYufKRERERIo+uwanLVu20KhRIxo1agTA6NGjadSoEW+++SYAkZGRmSEKoHLlyvz5558sW7aMBg0a8NFHH/HNN9+oFbnIFY4mI2/cW5tPH2mIi6OR1YfOEzp5DXtPx9i7NBEREZEiza5rnDp06MDNmvpNnz49x2O2b99uw6pEir5eDQOpUc6Tp37cSkRUAn2nrOODPvXp3SjQ3qWJiIiIFElFao2TiORdLX8vFo5sQ4eafiSlmnn+lx2MX7iX1HSzvUsTERERKXIUnESKMW83R74d0pRn764GwLS1xxnw9UbOxSXZuTIRERGRokXBSaSYMxkNjO5Sk68HN8HT2YFNx6MInbSGreGX7F2aiIiISJGh4CRSQnSuXY75I1tTrawHZ2OTeeSr9czcGH7TdYYiIiIiYqXgJFKCVPXzYP6I1nSvW57UdAuvzdvD2N92kZSabu/SRERERAo1BSeREsbD2YEvBtzFK91DMBpg9paTPDR1PaeiE+1dmoiIiEihpeAkUgIZDAaebl+VHx5rTik3R3adjCF00hrWHb1g79JERERECqXbCk4nTpzg5MmTmY83bdrE888/z1dffZVvhYmI7bWpXoYFI9tQN9CLqPgUBn6zka9XH9O6JxEREZHr3FZw6t+/PytXrgTgzJkzdO7cmU2bNvHaa6/x9ttv52uBImJbQb5uzHm6FX3vqoDZAu8u2s+on7aTkJJm79JERERECo3bCk579uyhWbNmAMyePZu6deuybt06Zs6cyfTp0/OzPhEpAC6OJj58sD7/6VUHB6OBP3ZFcv/n6zh+Id7epYmIiIgUCrcVnFJTU3F2dgZg+fLl3HfffQCEhIQQGRmZf9WJSIExGAwMalmJn59sgZ+nMwfPxhE6eQ1/Hzhr79JERERE7O62glOdOnX48ssv+ffff1m2bBndunUD4PTp05QuXTpfCxSRgtWkki9/jmpDk+BSxCWl8dj0LUxcfgizWeueREREpOS6reD03//+l6lTp9KhQwf69etHgwYNAFiwYEHmJXwiUnSV9XJh1rAWDG4ZDMDE5YcZ9sMWYhJT7VyZiIiIiH043M5BHTp04MKFC8TGxlKqVKnM8SeffBI3N7d8K05E7MfJwcjbvepSv4IPr83bzYoD5+g1eQ1TBzWhZnlP0s0WNoZFsfWCgdJhUbSsVhaT0WDvskVERERs4raCU2JiIhaLJTM0hYeHM2/ePGrVqkXXrl3ztUARsa8HGlcgpLwnT/24leMXE7j/i7X0b16RP3dFEhmTBJj44fAW/L1deCu0Nt3q+tu7ZBEREZF8d1uX6vXq1YsffvgBgOjoaJo3b85HH31E7969mTJlSr4WKCL2VzfQm4Wj2tCmWhkSUtL55t+wK6HpqjMxSQyfsY3Fe9QgRkRERIqf2wpO27Zto23btgDMmTOHcuXKER4ezg8//MBnn32WrwWKSOHg6+7Ed0Ob4u5kyvHrGa0jxi/cR7oaSYiIiEgxc1vBKSEhAU9PTwCWLl1Knz59MBqNtGjRgvDw8HwtUEQKj63hl4hPSb/h1y1AZEwSm8KiCq4oERERkQJwW8GpWrVqzJ8/nxMnTrBkyRK6dOkCwLlz5/Dy8srXAkWk8DgXl5T7Trewn4iIiEhRcVvB6c0332TMmDFUqlSJZs2a0bJlS8B69qlRo0b5WqCIFB5lPV3ytN/Fy8k2rkRERESkYN1WV70HHniANm3aEBkZmXkPJ4B77rmH+++/P9+KE5HCpVllX/y9XTgTk8TNVjG9/cd+NhyL4pXuIVTx8yiw+kRERERs5bbOOAGUL1+eRo0acfr0aU6ePAlAs2bNCAkJybfiRKRwMRkNvBVaG4Dr79iU8bht9TKYjAaW7jtLl09WM27BXqLiUwq0ThEREZH8dlvByWw28/bbb+Pt7U1wcDDBwcH4+Pjwn//8B7PZnN81ikgh0q2uP1MG3kV576yX7ZX3duHLgXfx4+PNWfxcW+4OKUua2cL0dcdpP2ElX60+SlLqjRtLiIiIiBRmt3Wp3muvvca3337LBx98QOvWrQFYs2YN48aNIykpiXfffTdfixSRwqVbXX861y7P+iPnWPrvRrq0bU7LamUxGa3nnaqX8+S7oU1Ze+QC7/y5n/2Rsby36AA/rA9nbLcQ7q3vj8Fw/TkrERERkcLrtoLT999/zzfffMN9992XOVa/fn0CAwN55plnFJxESgCT0UDzyr5c3G+heWXfzNB0rdbVyvDHqDbM3XaSD5ce5OSlREb9tJ1v14Txes9aNKnka4fKRURERG7dbV2qFxUVleNappCQEKKidP8WEbnKZDTwYJMgVo7pwOjONXBzMrHjRDQPfLme4TO2En4x3t4lioiIiOTqtoJTgwYNmDx5crbxyZMnU79+/TsuSkSKHzcnB569pzqrxnSgX7MgjAb4a88ZOn38D//5Yx/RCWogISIiIoXXbV2q97///Y+ePXuyfPnyzHs4rV+/nhMnTrBo0aJ8LVBEipeyXi6836c+Q1pV4r1FB1h96DzfrgljztaTjLq7GoNbVsLJ4bYbfoqIiIjYxG39dNK+fXsOHTrE/fffT3R0NNHR0fTp04e9e/fy448/5neNIlIMhZT34ofHmvH9Y80IKe9JTGIq7/y5n86f/MOi3ZFYLDe7U5SIiIhIwbqtM04AAQEB2ZpA7Ny5k2+//ZavvvrqjgsTkZKhfQ0/2lQrw69bTvDRskOEX0zgmZnbaBJcitd61qJRxVL2LlFERETk9m+AKyKSX0xGA480q8iqMR149p7quDga2RJ+ifu/WMfIWds4EZVg7xJFRESkhFNwEpFCw93ZgdGda7BqTEcebFwBgwH+2BXJPR/9w3uL9hOTmGrvEkVERKSEUnASkUKnvLcLEx5swB+j2tC6WmlS0s18tfoYHSasZPraMFLTzfYuUUREREqYW1rj1KdPn5t+PTo6+k5qERHJok6ANzMeb86qg+d5d9F+jpy7zLiF+/h+fTivdA+hS+1yGAzZb7wrIiIikt9uKTh5e3vn+vXBgwffUUEiItcyGAx0DClL2+pl+GXLCT5ZdoiwC/E89eNWmlX25fWetahfwcfeZYqIiEgxd0vBadq0abaqQ0TkphxMRgY0D+a+BgF8+c9Rvvk3jE1hUdw3eS29GwbwUrcQAn1c7V2miIiIFFNa4yQiRYqniyMvdQ1h5ZgO9GkUCMD8Hafp+OEq/rv4AHFJaiAhIiIi+U/BSUSKpAAfVz5+uCF/jGpDiyq+pKSZmbLqKB0mrOLHDeGkqYGEiIiI5CMFJxEp0uoGevPTsBZ8PbgJVcq4czE+hTfm76HrxNWs2H8Wi8Vi7xJFRESkGFBwEpEiz2Aw0Ll2OZa80I63e9XB192Jo+fjefz7LQz4ZiN7TsXYu0QREREp4hScRKTYcDQZGdyyEqte6sBT7avg5GBk3dGLhE5ew4uzdxIZk2jvEkVERKSIUnASkWLHy8WRV7vXYsXo9tzXIACLBX7bdpKOH67io6UHuZycZu8SRUREpIhRcBKRYivI143P+jVi/ojWNK1UiqRUM5P+PkKHCauYtTFCDSREREQkzxScRKTYaxjkw+ynWvLlwLuoVNqNC5eT+b95u+nx2b+sPHhODSREREQkVwpOIlIiGAwGutX1Z+kL7Xnz3tr4uDly6OxlHp22mcHfbWJ/ZKy9SxQREZFCTMFJREoUJwcjj7WpzD9jOjKsbWWcTEb+PXyBHp/9y8tzdnI2NsneJYqIiEghpOAkIiWSt5sjr/WszfLR7elZ3x+LBWZvOUmHCauYuPwQCSlqICEiIiJXKTiJSIlWsbQbn/e/i9+Gt6JRRR8SU9OZuPwwHSasYvbmE6Sbtf5JREREFJxERABoHFyKucNb8Xn/uwjydeVcXDIv/7aLnp/9y7+Hz9u7PBEREbEzBScRkSsMBgM96/uzfHR7XutRCy8XBw6ciWPQt5sYOm0Th87G2btEERERsRMFJxGR6zg7mBjWrgr/vNSRR1tXwsFoYNXB83SbuJpX5+7mfFyyvUsUERGRAqbgJCJyA6XcnXgrtA7LRrenW53ymC3w06YIOkxYyaQVh0lMSbd3iSIiIlJAFJxERHJRuYw7Xw5qzOynWtKggjfxKel8tOwQd3+0it+2nsSsBhIiIiLFnoKTiEgeNavsy7xnWvPpIw0J9HElMiaJF3/dSejkNaw7esHe5YmIiIgNKTiJiNwCo9FAr4aBrHixPa90D8HT2YG9p2Pp//VGnvh+M0fOXbZ3iSIiImIDCk4iIrfBxdHE0+2rsuqlDgxuGYzJaGD5/nN0nbiaN+bv4eJlNZAQEREpThScRETuQGkPZ97uVZelL7SjU61ypJst/LghnPYTVvHFqiMkpaqBhIiISHGg4CQikg+q+nnwzZAm/DSsBXUDvbicnMb/Fh/kno/+Yf72U2ogISIiUsQpOImI5KOWVUuzYEQbPn6oAf7eLpyKTuT5X3Zw/xdr2Xjsor3LExERkduk4CQiks+MRgN97qrA3y924KWuNXF3MrHzZAwPf7WBJ3/YwrHzaiAhIiJS1Cg4iYjYiKuTiREdq7HqpY70b14RowGW7jtLl09WM27BXi7Fp9i7RBEREckjBScRERvz83TmvfvrseT5dnSs6Uea2cL0dcdpN2ElX60+SnKaGkiIiIgUdgpOIiIFpHo5T6Y92owZjzenlr8XcUlpvLfoAPd89A8Ld57GYlEDCRERkcJKwUlEpIC1qV6GP0a14X8P1KeclzMnLyUy6qft9Jmyjq3hUfYuT0RERHKg4CQiYgcmo4GHmgSxckwHXuhUAzcnE9sjouk7ZT3PzNxK+MV4e5coIiIi17B7cPr888+pVKkSLi4uNG/enE2bNt10/4kTJ1KzZk1cXV0JCgrihRdeICkpqYCqFRHJX25ODjzXqTqrxnTgkaZBGA2waPcZOn38D+/9dZD4VHtXKCIiImDn4PTLL78wevRo3nrrLbZt20aDBg3o2rUr586dy3H/WbNm8corr/DWW2+xf/9+vv32W3755Rf+7//+r4ArFxHJX2W9XPigb30WPdeWttXLkJpuYdq6cN7ZbmLaunBS0sz2LlFERKREs2tw+vjjjxk2bBiPPvootWvX5ssvv8TNzY3vvvsux/3XrVtH69at6d+/P5UqVaJLly7069cv17NUIiJFRUh5L358vDnfP9aMGmU9SEg38N5fB+n8yT/8tTtSDSRERETsxMFeL5ySksLWrVt59dVXM8eMRiOdOnVi/fr1OR7TqlUrZsyYwaZNm2jWrBnHjh1j0aJFDBo06Iavk5ycTHJycubj2NhYAFJTU0lNtf81MBk1FIZaiiPNr21pfm2nVWUffnuyCe/OWsHyc66EX0xg+MxtNK7owyvdatAwyMfeJRZ5+vzalubXtjS/tqX5ta3CNL+3UoPBYqdfX54+fZrAwEDWrVtHy5YtM8dffvll/vnnHzZu3JjjcZ999hljxozBYrGQlpbG008/zZQpU274OuPGjWP8+PHZxmfNmoWbm9udvxERERtLTocVp4z8HWkg1WwA4K7SZu6taKa0i52LExERKcISEhLo378/MTExeHl53XRfu51xuh2rVq3ivffe44svvqB58+YcOXKE5557jv/85z+88cYbOR7z6quvMnr06MzHsbGxBAUF0aVLl1wnpyCkpqaybNkyOnfujKOjo73LKXY0v7al+bWtjPm9t1tn7nd05ExsEp8sP8K8HafZdtHI7mgTQ1oGM7xdZbxcNf+3Sp9f29L82pbm17Y0v7ZVmOY342q0vLBbcCpTpgwmk4mzZ89mGT979izly5fP8Zg33niDQYMG8cQTTwBQr1494uPjefLJJ3nttdcwGrMv2XJ2dsbZ2TnbuKOjo92/UdcqbPUUN5pf29L82lbG/AaVduTjhxvxeNsqvPvnftYdvcg3a47z27ZTPHdPdQa0CMbRZPdmqUWOPr+2pfm1Lc2vbWl+baswzO+tvL7d/oV1cnKicePGrFixInPMbDazYsWKLJfuXSshISFbODKZTABaMC0iJUadAG9mPtGc74Y2oVpZDy4lpDJu4T66fLKaJXvP6O9DERERG7DrpXqjR49myJAhNGnShGbNmjFx4kTi4+N59NFHARg8eDCBgYG8//77AISGhvLxxx/TqFGjzEv13njjDUJDQzMDlIhISWAwGLg7pBztqvvx8+YTfLLsEGEX4nnqx600r+zLaz1rUb+Cj73LFBERKTbsGpwefvhhzp8/z5tvvsmZM2do2LAhixcvply5cgBERERkOcP0+uuvYzAYeP311zl16hR+fn6Ehoby7rvv2ustiIjYlYPJyMAWwfRqGMCX/xzlm3/D2BgWxX2T19K7YQAvdQsh0MfV3mWKiIgUeXZvDjFy5EhGjhyZ49dWrVqV5bGDgwNvvfUWb731VgFUJiJSdHi6OPJS1xD6Nw/mwyUHmbf9FPN3nOavPWd4vE1lhneoiqeLrtMXERG5XVpFLCJSjAT6uPLJww1ZOLINzSv7kpxm5otVR+kwYRU/bggnLd1s7xJFRESKJAUnEZFiqF4Fb35+sgVfDWpMlTLuXIxP4Y35e+g6cTUr9p9VAwkREZFbpOAkIlJMGQwGutQpz5IX2jH+vjqUcnPk6Pl4Hv9+CwO+2cje0zH2LlFERKTIUHASESnmHE1GhrSqxD8vd+Sp9lVwMhlZd/Qi905aw4uzd3ImJsneJYqIiBR6Ck4iIiWEl4sjr3avxYoX2xPaIACLBX7bdpIOH67k46UHuZycZu8SRURECi0FJxGREibI141J/Rox75lWNAkuRVKqmc/+PkKHCav4aVOEGkiIiIjkQMFJRKSEalSxFL8+3ZIvB95FcGk3LlxO5tW5u+n52RpWHTxn7/JEREQKFQUnEZESzGAw0K2uP8teaM8b99bG29WRg2fjGDptM4O+3cj+yFh7lygiIlIoKDiJiAhODkYeb1OZ1S915Ik2lXE0Gfj38AV6fvYvY+fs4mysGkiIiEjJpuAkIiKZvN0cef3e2iwf3Z6e9fwxW+CXLSfoMGEVE5cfIiFFDSRERKRkUnASEZFsgku78/mAu/hteEsaVfQhMTWdicsP02HCKmZvPkG6WTfQFRGRkkXBSUREbqhxsC9zh7dicv9GBPm6ci4umZd/20XPz/5lzeEL9i5PRESkwCg4iYjITRkMBu6tH8Dy0e15rUctPF0cOHAmjoHfbmTotE0cOhtn7xJFRERsTsFJRETyxNnBxLB2VVj9UkcebV0JB6OBVQfP023iav5v3m7OxyXbu0QRERGbUXASEZFbUsrdibdC67BsdHu61imH2QKzNkbQYcJKJv99mMSUdHuXKCIiku8UnERE5LZULuPO1EFN+OXJFtSv4E18SjofLj3E3R+t4retJzGrgYSIiBQjCk4iInJHmlcpzfxnWvPpIw0J9HElMiaJF3/dyX2fr2H90Yv2Lk9ERCRfKDiJiMgdMxoN9GoYyIoX2zO2Wwiezg7sORVLv6838MT3mzly7rK9SxQREbkjCk4iIpJvXBxNDO9QlVUvdWBwy2BMRgPL95+j68TVvDF/Dxcvq4GEiIgUTQpOIiKS70p7OPN2r7oseb4dnWqVJd1s4ccN4XSYsIopq46SlKoGEiIiUrQoOImIiM1UK+vBN0OaMmtYc+oGehGXnMZ/Fx/gno/+4fcdp9RAQkREigwFJxERsblWVcuwYEQbPnqwAeW9XDgVnchzP+/g/i/Wsiksyt7liYiI5ErBSURECoTRaKBv4wqsHNOBMV1q4O5kYufJGB6aup6nftxC2IV4e5coIiJyQwpOIiJSoFydTIy8uzqrXupI/+YVMRpgyd6zdP74H8Yt2Mul+BR7lygiIpKNgpOIiNiFn6cz791fj8XPt6NjTT/SzBamrztOuwkr+Wr1UZLT1EBCREQKDwUnERGxqxrlPJn2aDNmPN6ckPKexCWl8d6iA3T6+B/+2HUai0UNJERExP4UnEREpFBoU70Mfz7blv89UJ+yns6ciEpk5Kzt9Jmyjq3haiAhIiL2peAkIiKFhslo4KEmQax6qQPPd6qOq6OJ7RHR9J2ynhEztxF+UQ0kRETEPhScRESk0HFzcuD5TjX456UOPNwkCIMB/twdSaeP/+GdP/YRk5Bq7xJFRKSEUXASEZFCq6yXC/99oD6Lnm1L2+plSE238M2aMNpNWMm3a8JISTPbu0QRESkhFJxERKTQq+XvxY+PN2f6o02pUc6DmMRU/vPHPjp/8g9/7Y5UAwkREbE5BScRESkyOtQsy6Jn2/J+n3qU8XAm/GICw2du46Gp69lxItre5YmISDGm4CQiIkWKg8lIv2YVWfVSB569uxoujkY2H79E78/XMuqn7ZyISrB3iSIiUgwpOImISJHk4ezA6C41WTmmAw80roDBAAt3nuaej/7h/UX7iUlUAwkREck/Ck4iIlKk+Xu78uGDDVg4sg2tqpYmJd3M1NXH6DBhJd+vO05quhpIiIjInVNwEhGRYqFuoDczn2jOt0OaUNXPnUsJqby1YC9dP1nN0r1nsjSQSDdb2BgWxdYLBjaGRZFuVnMJERG5OQd7FyAiIpJfDAYD99QqR/safvy0+QQTlx3i2IV4nvxxK80r+/Jaz1qcjk5k/MJ9RMYkASZ+OLwFf28X3gqtTbe6/vZ+CyIiUkjpjJOIiBQ7DiYjg1oEs+qlDjzToSpODkY2hkVx3+S1PD1j25XQdNWZmCSGz9jG4j2RdqpYREQKOwUnEREptjxdHHm5Wwgrx3Sgd8OAG+6XcaHe+IX7dNmeiIjkSMFJRESKvUAfVx5uWvGm+1iAyJgkNoVFFUxRIiJSpCg4iYhIiXAuLin3nYBT0boPlIiIZKfgJCIiJUJZT5c87ffWgr28++c+jl+It3FFIiJSlCg4iYhIidCssi/+3i4YbrKP0QDxyel8/W8YHT5cxaBvN7J4zxnSdC8oEZEST+3IRUSkRDAZDbwVWpvhM7Zh4GpDCCAzTE3udxdODkZmbAznn0Pn+ffwBf49fIHyXi480iyIfs0qUs4rb2euRESkeFFwEhGREqNbXX+mDLzrmvs4WZW/7j5OnWqXI+JiArM2RTB7ywnOxCYxcflhJv19hM61yjGwRTCtqpbGaLzZ+SsRESlOFJxERKRE6VbXn861y7P+yDmW/ruRLm2b07JaWUzXhaCKpd14pXsIL3SuzuI9Z5ixIZzNxy+xeO8ZFu89Q+Uy7gxoXpEHGlfAx83JTu9GREQKioKTiIiUOCajgeaVfbm430Lzyr7ZQtO1nB1M9GoYSK+GgRw4E8vMDRHM236KsAvxvPPnfiYsOci99QMY2KIiDYN8MBh0FkpEpDhScBIREcmjkPJe/Kd3XcZ2D+H3HaeYsSGC/ZGx/LbtJL9tO0mdAC8GtgimV8MA3Jz0T6yISHGirnoiIiK3yMPZgQHNg1n0bBt+G96KPo0CcXIwsvd0LK/O3U3zd1fw1u97OHw2zt6liohIPtGvw0RERG6TwWCgcXApGgeX4vV7azNn6wlmbowg/GIC368P5/v14TSr7MvAFsF0q1MeJwf9vlJEpKhScBIREckHvu5OPNmuKk+0qcKaIxeYsSGc5fvPsiksik1hUZTxcOKhJtaW5kG+bvYuV0REbpGCk4iISD4yGg20q+FHuxp+RMYk8tOmE/y8KYJzccl8seooU/45SseaZRnYoiLta2Tv5iciIoWTgpOIiIiN+Hu7MrpzDUbdXY3l+84yY2M4a49c5O8D5/j7wDkCfVzp37wiDzUJws/T2d7liojITSg4iYiI2JijyUj3ev50r+fPsfOXmbkxgjlbT3IqOpEJSw4ycfkhutYpz8AWwTSv7KuW5iIihZCCk4iISAGq4ufBG/fW5qWuNVm48zQzNkaw80Q0f+yK5I9dkVQv68HAFsHcf1cgXi6O9i5XRESuUHASERGxAxdHEw82CeLBJkHsORXDzI3hzN9+msPnLvPWgr188NcBejUMYGCLYOoGetu7XBGREk/BSURExM7qBnrzfp/6vNqjFvO2nWLGhnAOn7vMz5tP8PPmEzQI8mFg84qENgjAxdFk73JFREokBScREZFCwsvFkSGtKjG4ZTCbwqKYsTGCxXsi2Xkimp0nonnnz/080LgCA5pXpIqfh73LFREpURScREREChmDwUDzKqVpXqU05+NqM3vLCWZtjOBUdCLfrgnj2zVhtK5WmoHNg+lUuxyOJt1YV0TE1hScRERECjE/T2dGdKzG0+2r8s+hc8zYEMHKg+dYe+Qia49cpKynM480q0i/ZkH4e7vau1wRkWJLwUlERKQIMBkN3B1SjrtDynEiKoGfNkUwe8sJzsUl89mKw3y+8gj3hJRlYItg2lQrg1E31hURyVcKTiIiIkVMkK8bL3cL4flONVi89wwzNoSzKSyKpfvOsnTfWSqVdqN/84o82DiIUu5O9i5XRKRYUHASEREpopwcjNzXIID7GgRw6GwcMzeEM3fbKY5fTOC9RQf4cOkh7q3nz4AWwdxV0Uc31hURuQMKTiIiIsVAjXKejO9Vl5e7hbBg52lmbAhn7+lY5m4/xdztp6jl78XAFhXp3TAQd2f98y8icqvUhkdERKQYcXd2oF+zivwxqg3znmlF37sq4OxgZH9kLK/N20Pz91bwxvw9HDwTZ+9SRUSKFLsHp88//5xKlSrh4uJC8+bN2bRp0033j46OZsSIEfj7++Ps7EyNGjVYtGhRAVUrIiJSNBgMBhpVLMVHDzVg4//dw+s9a1G5jDuXk9P4cUM4XSeu5sEv1/H7jlMkp6Xbu1wRkULPrufqf/nlF0aPHs2XX35J8+bNmThxIl27duXgwYOULVs22/4pKSl07tyZsmXLMmfOHAIDAwkPD8fHx6fgixcRESkifNyceKJtFR5rXZl1Ry8yY0M4y/afZfPxS2w+fonS7k482CSIAc0rEuTrZu9yRUQKJbsGp48//phhw4bx6KOPAvDll1/y559/8t133/HKK69k2/+7774jKiqKdevW4ejoCEClSpUKsmQREZEiy2g00KZ6GdpUL8OZmCR+2XyCnzZFcCY2iS//OcrU1UdpX8OPAc2DuTukLCa1NBcRyWS34JSSksLWrVt59dVXM8eMRiOdOnVi/fr1OR6zYMECWrZsyYgRI/j999/x8/Ojf//+jB07FpPJlOMxycnJJCcnZz6OjY0FIDU1ldTU1Hx8R7cno4bCUEtxpPm1Lc2vbWl+baukz29pNxPPtK/Ek20qsvLgBWZtPsGaIxdZdfA8qw6ex9/bhYebVOChxoH4eTrf8vOX9Pm1Nc2vbWl+baswze+t1GCwWCwWG9ZyQ6dPnyYwMJB169bRsmXLzPGXX36Zf/75h40bN2Y7JiQkhOPHjzNgwACeeeYZjhw5wjPPPMOzzz7LW2+9lePrjBs3jvHjx2cbnzVrFm5uuhxBREQkw/lEWHfWyIbzBhLSrGebjAYL9X0ttClnoZqXBXU0F5HiJCEhgf79+xMTE4OXl9dN9y1SwalGjRokJSURFhaWeYbp448/ZsKECURGRub4OjmdcQoKCuLChQu5Tk5BSE1NZdmyZXTu3Dnz8kPJP5pf29L82pbm17Y0vzeWnJrOX3vPMmvTCbafiMkcr1LGnX7NKtCnYQBerjefM82vbWl+bUvza1uFaX5jY2MpU6ZMnoKT3S7VK1OmDCaTibNnz2YZP3v2LOXLl8/xGH9/fxwdHbNcllerVi3OnDlDSkoKTk7Z747u7OyMs3P2SwwcHR3t/o26VmGrp7jR/NqW5te2NL+2pfnNztHRkQebBvNg02D2nY5lxsZw5m8/xbEL8by76CAfLTvMfQ0CGNgimPoVfHJ9Ls2v7Wh+bUvza1uFYX5v5fXt1o7cycmJxo0bs2LFiswxs9nMihUrspyBulbr1q05cuQIZrM5c+zQoUP4+/vnGJpERETkztQO8OK9++ux8f/u4T+96lCznCdJqWZmbznJfZPXct/kNczefILEFLU0F5Hiza73cRo9ejRff/0133//Pfv372f48OHEx8dndtkbPHhwluYRw4cPJyoqiueee45Dhw7x559/8t577zFixAh7vQUREZESwdPFkUEtK7H4+bb8+nRLejUMwMlkZNfJGF7+bRfN31vO+IV7OXLusr1LFRGxCbu2I3/44Yc5f/48b775JmfOnKFhw4YsXryYcuXKARAREYHReDXbBQUFsWTJEl544QXq169PYGAgzz33HGPHjrXXWxARESlRDAYDTSv50rSSL2/em8zsLSeZtSmcE1GJTFt7nGlrj9OySmn6NQ0k3Zz784mIFBV2DU4AI0eOZOTIkTl+bdWqVdnGWrZsyYYNG2xclYiIiOSmtIczwztU5al2Vfjn8Hlmbgjn7wPnWH/sIuuPXcTL0cQRlyMMbFmJAB9Xe5crInJH7B6cREREpGgzGg10rFmWjjXLcio6kZ82RvDz5gguXE7hi3+O8eXqY9wdUo6BLSrSrrofRt1YV0SKILuucRIREZHiJdDHlTFda/LPi+0YWj2d5pVLYbbA8v1nGTptMx0+XMWX/xzl4uXk3J9MRKQQ0RknERERyXdODkYalbHwWo+mhF9KYsaGCH7bdpKIqAQ++OsAHy89RI965RnYIpjGwaUw6M66IlLIKTiJiIiITVUr68m4++rwcreaLNx5mhkbIth9Kob5O04zf8dpQsp7MqBFMPc3CsTDWT+aiEjhpL+dREREpEC4OTnwcNOKPNy0IjtPRDNjQzgLd53mwJk43pi/hw8W7ad3o0AGtgimlr+XvcsVEclCwUlEREQKXIMgHxoE+fB6z9rM2XaSmRvDOXY+npkbI5i5MYLGwaUY2KIi3ev64+Josne5IiIKTiIiImI/3m6OPN6mMo+1rsT6YxeZuSGCJXvPsDX8ElvDL/H2wn081CSI/s0rElza3d7likgJpuAkIiIidmcwGGhVtQytqpbhXGwSv2w+wU+bIjgdk8TU1ceYuvoY7Wr4MaB5Re4JKYuDSY2BRaRgKTiJiIhIoVLWy4VR91RneIeqrDx4nhkbwll9+DyrD1k3f28XHmlakUeaBVHOy8Xe5YpICaHgJCIiIoWSg8lI59rl6Fy7HBEXE5i5KZxft5wkMiaJT5YfYtLfh+lcuxwDWwTTqmpptTQXEZtScBIREZFCr2JpN17tXovRnWvw1+4zzNgQzpbwS/y15wx/7TlDlTLu9G9ekQcbB+Ht5mjvckWkGFJwEhERkSLD2cFE70aB9G4UyP7IWGZuDGfetlMcuxDPO3/uZ8KSg4Q2CGBgi2AaVPDWWSgRyTcKTiIiIlIk1fL34p3e9Xiley3mbz/FjA3hHDgTx5ytJ5mz9SR1A70Y2DyY+xoG4OakH3lE5M6oJY2IiIgUaR7ODgxsEcxfz7Xlt+Etub9RIE4mI3tOxfLK3N00f28F4xbs5fDZOHuXKiJFmH79IiIiIsWCwWCgcbAvjYN9eePe2vy65QQzN0YQEZXA9HXHmb7uOM0r+zKwRTBd65THyUG/PxaRvFNwEhERkWLH192Jp9pXZVjbKvx75AIzNoSzYv9ZNoZFsTEsijIezjzctAL9mlWkQik3e5crIkWAgpOIiIgUW0ajgfY1/Ghfw4/T0Yn8vCmCnzef4FxcMp+vPMqUVUfpWLMsA1sE066GHyajmkmISM4UnERERKRECPBxZXSXmoy6pzrL9p1lxoZw1h29yIoD51hx4BwVSrnSv3lFHmoSRBkPZ3uXKyKFjIKTiIiIlCiOJiM96vnTo54/R89fZtbGCOZsPcnJS4n8b/FBPll2iO51/RnYIpimlUqppbmIAApOIiIiUoJV9fPgjXtr81LXmizceZoZGyPYeSKaBTtPs2DnaWqU82Bgi2B6NwrEy0U31hUpyRScREREpMRzcTTxYJMgHmwSxO6TMczcGM78Hac4dPYyb/6+lw/+OkCvhgEMaB5M3UBve5crInag4CQiIiJyjXoVvPmgQn1e7VGLedtOMmNjBEfOXeanTSf4adMJGgb5MLBFMPfW98fF0WTvckWkgCg4iYiIiOTA29WRoa0rM6RVJTaGRTFjQzhL9p5hx4lodpyI5p0/9/HAXRUY0CKYymXc7V2uiNiYgpOIiIjITRgMBlpUKU2LKqU5H5fM7C0nmLUxglPRiXyzJoxv1oTRploZBraoSKda5XAw6ca6IsWRgpOIiIhIHvl5OjOiYzWebl+VVQfPMWNDOKsOnWfNkQusOXKBcl7OPNK0Iv2aVaS8t4u9yxWRfKTgJCIiInKLTEYD99Qqxz21ynEiKoFZmyKYvfkEZ2OT+XTFYSavPEKnWtYb67auWgajbqwrUuQpOImIiIjcgSBfN8Z2C+H5TtVZvOcMMzdEsOl4FEv2nmXJ3rNULuNO/2YVeaBxBUq5O9m7XBG5TQpOIiIiIvnA2cFEr4aB9GoYyMEzcczcGM7cbacIuxDPu4v2M2HpQe6tb72xbqMgH91YV6SIUXASERERyWc1y3vydq+6jO0Wwu87TjNjQzj7/r+9ew+Osr73OP7Z3BPI1ZBkE3IBgUDAACESg1JURBDKkR47oiINltZqwQPHWoseW0jtHO3U8TKtBUcLHKstFUeoVkURJSAikpBggBgBSbjkApjbEkiK5Dl/bIguuewm8GR3w/s1szPss79Hvs+XrzP55vnu76ls0Bu7jumNXceUZg3T3dck69Yx8eoXyI9jgDdg2xcAAACT9Av0011ZSXr7v67TGz+foP/MSFCAn4/2VTbo0XXFuuZ/N+k3/9yjL6tt7g4VgBP8igMAAMBkFotFGUmRykiK1K9npOn1gqN6dUe5yr4+rZe3l+vl7eUanxKlOdckadqoOAX68WBdwNPQOAEAAPSiyH4B+un3Bmv+dYO07eBJvfJpuT4oOa7Pymr0WVmNrugXoNuvTtRd45OUGBXS7vxzLYZ2HKpRwUmLrjhUo+whMfJl1z7AdDROAAAAbuDjY9HEoQM0cegAVdU36e+fHdaanYdV3dCs5ZsPakXeQV0/bIDuviZZ16fam6MNeyqV+9Y+VdY3SfLVy/vzZQ0P0tKZaZo2yuruSwL6NBonAAAAN4sLD9J/TxmmhTcO0aaS43p1R7m27j+pj0pP6KPSE0qICFZmSqT+WVTR7tyq+ibd/8ouLb87g+YJMBGNEwAAgIfw9/XRtFFxmjYqTodONupvO8q1tuCojtWd0bGiMx2eY0iySMp9a5+mpMUxtgeYhF31AAAAPNCg6H76nxlp+vSRybp/0pVdrjUkVdY36bNDNb0THHAZ4o4TAACABwvy99Vwa6hLa5e9uVfTRsUpMyVSY5Mi1Z9nRAGXDP83AQAAeLiY0CCX1pVW21Ta+kwoH4s0PC5MmSmRGpccqcyUKCVEBJsZJtCn0TgBAAB4uPGDomQND1JVfZOMDj63SIruH6iFk4eosLxW+eW1Olp7RvsqG7SvskEvby+XJMWHB2lcSpQyk+3N1PC4UPn58s0NwBU0TgAAAB7O18eipTPTdP8ru2SRHJqn81tBPD5rpKaNsionO0WSfbe9/PIa5ZfVqqC8VvsqG1RR36SK3RV6a7d9d75+Ab4am3T+jhTjfUBX+D8DAADAC0wbZdXyuzO+8xwnu7hOnuMUFx6k76fH6/vp8ZKkxuZvtPtInfJb70gVltfK1vyNPj5wUh8fOCnJPt43whpmvyPVemcqnvE+QBKNEwAAgNeYNsqqKWlx2n7guN7fukM3T8xS9pAYl7Yg7xfopwlDojVhSLQk6VyLoS+rbcovq7E3U2W1OlZ3RnsrGrS3okH/18l43whrGFue47JE4wQAAOBFfH0syhoUpa9LDGUNiupxE+PrY9EIa5hGWMM0t5vjfRmtTVRmcpTGJEUw3ofLAlUOAAAASZ2P9+0sq1V+eY0KD9fpVPM32rr/pLbuZ7wPlxcaJwAAAHSoo/G+0iqbCsqdj/dlpkS1bYU+PI7xPng/GicAAAC4xNfHorT4MKXFfzveV1l/pm20L7+8RiWVNlXUN+nN3RV6s3W8r3+gn8YmRbSN941NilA/xvvgZahYAAAA9Jg1PFgzRwdr5uhvx/uKjtQp38l4X1p8mDKTo9q2QreGM94Hz0bjBAAAgEumX6Cfrh0SrWu/M973RVWD/Y5U652pY3VntOdYg/Yca9DqT8okSQkRwW1NFON98EQ0TgAAADCNr49FI+PDNTI+XD/qZLxvX0WDjtWd0bG6M+3G+zKT7d+VGpPIeB/ci+oDAABAr+psvG9nWY0Kyms7HO+zb58eyngf3IbGCQAAAG51seN9V6dEalxylFLjQhnvg2lonAAAAOBRuhrvyy+zb4VeUtl+vC800E9jGO+DSagkAAAAeLwLx/tONX+josN1yi+3j/ftKq+VrYvxvswU+1boceFB7rwMeDEaJwAAAHid/oF+um5otK4b6jjeZ98GvVYFZTWqqG/qcLzP3kQx3ofuoXECAACA1/vueF/OhBRJUkXdmbYmymG8r+iM/lnkON53dUqUMpMjNSYpQv70UegAjRMAAAD6pPiIYP1HRLD+o4PxvvyyWhUe7mS8Ly5UUS0+UnGVsq4cwHgfJNE4AQAA4DJx4XjfN+da9EWVrfV5Ut8Z76tokOSjLa99LslxvC8zJUrDYhnvuxzROAEAAOCy5Ofro1EJ4RqV4Djet+PgCb2xdbdOKlyl1bYOx/vGJrc2Uq3jfSEB/Fjd1/EvDAAAALSKjwjW99Ot8jlaqOnTs9XcYlHh4W+fJ3V+vG/Llye05csTkuzjfWnWsNZnStl38IsNY7yvr6FxAgAAADrRP9BPE4cO0MShAyQ5jvftLLNvhV5Z36TiY/UqPlbftnvfwMhg+859rZtOMN7n/WicAAAAABd1NN53rO6M8lubqPyyWn1R1aCjtWd0tPaM1nc03tf6cF7G+7wL/1oAAADARUiICFbCmATdOiZBkmRrOquiI3Wtz5SqUeHhug7H+0bG28f7zj+gl/E+z0bjBAAAAFxCoUH+HY735bc+T+r8eN/nR+v1+dF6rdpWJonxPk9H4wQAAACY6LvjffOuHSTJxfG+ID9lJEW2NlOM97mbR2T++eef1x/+8AdVVVVp9OjR+uMf/6jx48c7PW/NmjW68847deutt2r9+vXmBwoAAABcAh2N9xUermu9I9U63tf0jfK+PKG81vE+Px+L0hjvcxu3N07/+Mc/9OCDD2rFihXKysrSs88+q6lTp6q0tFQxMTGdnldWVqaHHnpIEydO7MVoAQAAgEsvNMhf3xs2QN8b1vF4X35Zraoa2o/3JUYFKzM5yt5MpURqWEyofBjvM4XbG6enn35aP/3pT3XPPfdIklasWKG3335bK1eu1JIlSzo859y5c5ozZ45yc3O1detW1dXV9WLEAAAAgLkuHO8zDEPH6s60jfbll9vH+47UnNGRmmNaV3hMkuN4X2ZKlMYkRig4wNfNV9M3uLVx+ve//62CggI98sgjbcd8fHx00003afv27Z2e99vf/lYxMTGaP3++tm7d2uXf0dzcrObm5rb3DQ0NkqSzZ8/q7NmzF3kFF+98DJ4QS19Efs1Ffs1Ffs1Ffs1Ffs1Ffs3lqfmN7e+v6SNjNH2kfSrL1vSNio7WaVd5nXYdrlPR0fqOx/usocpIilBGUoTGJUcqJjTQnZfhUfntTgwWwzAME2PpUkVFhRISEvTJJ58oOzu77fjDDz+svLw87dixo905H3/8se644w4VFRUpOjpa8+bNU11dXaffcVq2bJlyc3PbHf/b3/6mkJCQS3YtAAAAgDudM6SKRukrm0WHbBZ9ZbOo/t/tx/auCDQ0KNT+GhxqKC5Eulyn+06fPq277rpL9fX1CgsL63Kt20f1usNms2nu3Ll68cUXFR0d7dI5jzzyiB588MG29w0NDUpMTNTNN9/sNDm94ezZs9q4caOmTJkif39/d4fT55Bfc5Ffc5Ffc5Ffc5Ffc5Ffc/WV/BqGoYr6JhW03pEqOFyn0mqbvm626Otmi/JP2teFBflpbOL5O1IRSk8IN3W8z5Pye34azRVubZyio6Pl6+ur6upqh+PV1dWKi4trt/7gwYMqKyvTzJkz2461tLRIkvz8/FRaWqorr7zS4ZzAwEAFBra/Henv7+/2f6jv8rR4+hryay7yay7yay7yay7yay7ya66+kN+UAQFKGRCm2zKTJEkNrbv3FbRuOlF0pE4NTd8ob/9J5e23d1J+bQ/nte/cl5kcqRgTdu/zhPx25+93a+MUEBCgcePGadOmTZo1a5YkeyO0adMmLVy4sN364cOHq7i42OHYY489JpvNpueee06JiYm9ETYAAADglcKC/DVp2ABN+s7ufSWVNuWXn9+9r0bVDc3afbReu4/Wa+W2Q5KkpKiQtudJZSZHaWhM/8tu9z63j+o9+OCDysnJUWZmpsaPH69nn31WjY2Nbbvs/ehHP1JCQoKeeOIJBQUFadSoUQ7nR0RESFK74wAAAAC65ufro6sGhuuqgeG6p3X3vqO1rbv3ldcov6xWpdU2Ha45rcM1p/VG6+59YUF+ykhufThvsuu7951rMbTjUI0KTlp0xaEaZQ+Jka+XNGBub5xmz56tEydO6De/+Y2qqqo0ZswYbdiwQbGxsZKkw4cPy8fHx81RAgAAAH2fxWJRYlSIEqNCNGus/eG8F473FR62j/dtLj2hzaXf7t43MiHcvg16652pmFDH8b4NeyqV+9Y+VdY3SfLVy/vzZQ0P0tKZaZo2ytrbl9ptbm+cJGnhwoUdjuZJ0ubNm7s8d/Xq1Zc+IAAAAACS2o/3nT3XopLKBuWX1bbdmapuaNbuI3XafaROf/m4/Xhf09kW/e5f+3Thdt5V9U26/5VdWn53hsc3Tx7ROAEAAADwDv6+PkofGKH0gRH68XWuj/d1xJBkkZT71j5NSYvz6LE9GicAAAAAPdbZeN+ucvsdqU0lx7WvsvNtvw1JlfVN+uxQjbKvvKKXou4+vjwEAAAA4JIKC/LX9akx+sXNqfrZpMEunXPc1mRyVBeHxgkAAACAaS7cJOJi17kLjRMAAAAA04wfFCVreJA6+/aSRZI1PEjjB0X1ZljdRuMEAAAAwDS+PhYtnZkmSe2ap/Pvl85M8+iNISQaJwAAAAAmmzbKquV3Zygu3HEcLy48yCu2IpfYVQ8AAABAL5g2yqopaXHafuC43t+6QzdPzFL2kBiPv9N0Ho0TAAAAgF7h62NR1qAofV1iKGtQlNc0TRKjegAAAADgFI0TAAAAADhB4wQAAAAATtA4AQAAAIATNE4AAAAA4ASNEwAAAAA4QeMEAAAAAE7QOAEAAACAEzROAAAAAOAEjRMAAAAAOEHjBAAAAABO0DgBAAAAgBM0TgAAAADghJ+7A+hthmFIkhoaGtwcid3Zs2d1+vRpNTQ0yN/f393h9Dnk11zk11zk11zk11zk11zk11zk11yelN/zPcH5HqErl13jZLPZJEmJiYlujgQAAACAJ7DZbAoPD+9yjcVwpb3qQ1paWlRRUaHQ0FBZLBZ3h6OGhgYlJibqyJEjCgsLc3c4fQ75NRf5NRf5NRf5NRf5NRf5NRf5NZcn5dcwDNlsNsXHx8vHp+tvMV12d5x8fHw0cOBAd4fRTlhYmNsLpy8jv+Yiv+Yiv+Yiv+Yiv+Yiv+Yiv+bylPw6u9N0HptDAAAAAIATNE4AAAAA4ASNk5sFBgZq6dKlCgwMdHcofRL5NRf5NRf5NRf5NRf5NRf5NRf5NZe35vey2xwCAAAAALqLO04AAAAA4ASNEwAAAAA4QeMEAAAAAE7QOAEAAACAEzROJtqyZYtmzpyp+Ph4WSwWrV+/3uk5mzdvVkZGhgIDAzVkyBCtXr3a9Di9VXfzu3nzZlkslnavqqqq3gnYyzzxxBO6+uqrFRoaqpiYGM2aNUulpaVOz1u7dq2GDx+uoKAgXXXVVXrnnXd6IVrv05P8rl69ul39BgUF9VLE3mX58uVKT09ve7hidna23n333S7PoXZd1938UrsX58knn5TFYtHixYu7XEcN94wr+aWGXbds2bJ2uRo+fHiX53hL7dI4maixsVGjR4/W888/79L6Q4cOacaMGbrhhhtUVFSkxYsX6yc/+Ynee+89kyP1Tt3N73mlpaWqrKxse8XExJgUoXfLy8vTggUL9Omnn2rjxo06e/asbr75ZjU2NnZ6zieffKI777xT8+fPV2FhoWbNmqVZs2Zpz549vRi5d+hJfiX7U9a/W7/l5eW9FLF3GThwoJ588kkVFBQoPz9fN954o2699Vbt3bu3w/XUbvd0N78StdtTO3fu1AsvvKD09PQu11HDPeNqfiVquDtGjhzpkKuPP/6407VeVbsGeoUkY926dV2uefjhh42RI0c6HJs9e7YxdepUEyPrG1zJ70cffWRIMmpra3slpr7m+PHjhiQjLy+v0zW33367MWPGDIdjWVlZxs9+9jOzw/N6ruR31apVRnh4eO8F1cdERkYaL730UoefUbsXr6v8Urs9Y7PZjKFDhxobN240Jk2aZCxatKjTtdRw93Unv9Sw65YuXWqMHj3a5fXeVLvccfIg27dv10033eRwbOrUqdq+fbubIuqbxowZI6vVqilTpmjbtm3uDsdr1NfXS5KioqI6XUMN95wr+ZWkU6dOKTk5WYmJiU5/ww+7c+fOac2aNWpsbFR2dnaHa6jdnnMlvxK12xMLFizQjBkz2tVmR6jh7utOfiVquDv279+v+Ph4DR48WHPmzNHhw4c7XetNtevn7gDwraqqKsXGxjoci42NVUNDg86cOaPg4GA3RdY3WK1WrVixQpmZmWpubtZLL72k66+/Xjt27FBGRoa7w/NoLS0tWrx4sa699lqNGjWq03Wd1TDfI+uaq/lNTU3VypUrlZ6ervr6ej311FOaMGGC9u7dq4EDB/ZixN6huLhY2dnZampqUv/+/bVu3TqlpaV1uJba7b7u5Jfa7b41a9Zo165d2rlzp0vrqeHu6W5+qWHXZWVlafXq1UpNTVVlZaVyc3M1ceJE7dmzR6Ghoe3We1Pt0jjhspGamqrU1NS29xMmTNDBgwf1zDPP6K9//asbI/N8CxYs0J49e7qcUUbPuZrf7Oxsh9/oT5gwQSNGjNALL7ygxx9/3OwwvU5qaqqKiopUX1+v119/XTk5OcrLy+v0h3t0T3fyS+12z5EjR7Ro0SJt3LiRDQhM0JP8UsOuu+WWW9r+nJ6erqysLCUnJ+u1117T/Pnz3RjZxaNx8iBxcXGqrq52OFZdXa2wsDDuNplk/PjxNANOLFy4UP/617+0ZcsWp79V66yG4+LizAzRq3Unvxfy9/fX2LFjdeDAAZOi824BAQEaMmSIJGncuHHauXOnnnvuOb3wwgvt1lK73ded/F6I2u1aQUGBjh8/7jANce7cOW3ZskV/+tOf1NzcLF9fX4dzqGHX9SS/F6KGXRcREaFhw4Z1mitvql2+4+RBsrOztWnTJodjGzdu7HJmHBenqKhIVqvV3WF4JMMwtHDhQq1bt04ffvihBg0a5PQcath1Pcnvhc6dO6fi4mJq2EUtLS1qbm7u8DNq9+J1ld8LUbtdmzx5soqLi1VUVNT2yszM1Jw5c1RUVNThD/XUsOt6kt8LUcOuO3XqlA4ePNhprryqdt29O0VfZrPZjMLCQqOwsNCQZDz99NNGYWGhUV5ebhiGYSxZssSYO3du2/qvvvrKCAkJMX75y18aJSUlxvPPP2/4+voaGzZscNcleLTu5veZZ54x1q9fb+zfv98oLi42Fi1aZPj4+BgffPCBuy7Bo91///1GeHi4sXnzZqOysrLtdfr06bY1c+fONZYsWdL2ftu2bYafn5/x1FNPGSUlJcbSpUsNf39/o7i42B2X4NF6kt/c3FzjvffeMw4ePGgUFBQYd9xxhxEUFGTs3bvXHZfg0ZYsWWLk5eUZhw4dMj7//HNjyZIlhsViMd5//33DMKjdi9Xd/FK7F+/CXd+o4UvLWX6pYdf94he/MDZv3mwcOnTI2LZtm3HTTTcZ0dHRxvHjxw3D8O7apXEy0fntry985eTkGIZhGDk5OcakSZPanTNmzBgjICDAGDx4sLFq1apej9tbdDe/v//9740rr7zSCAoKMqKioozrr7/e+PDDD90TvBfoKLeSHGpy0qRJbfk+77XXXjOGDRtmBAQEGCNHjjTefvvt3g3cS/Qkv4sXLzaSkpKMgIAAIzY21pg+fbqxa9eu3g/eC/z4xz82kpOTjYCAAGPAgAHG5MmT236oNwxq92J1N7/U7sW78Ad7avjScpZfath1s2fPNqxWqxEQEGAkJCQYs2fPNg4cOND2uTfXrsUwDKP37m8BAAAAgPfhO04AAAAA4ASNEwAAAAA4QeMEAAAAAE7QOAEAAACAEzROAAAAAOAEjRMAAAAAOEHjBAAAAABO0DgBAAAAgBM0TgAAdIPFYtH69evdHQYAoJfROAEAvMa8efNksVjavaZNm+bu0AAAfZyfuwMAAKA7pk2bplWrVjkcCwwMdFM0AIDLBXecAABeJTAwUHFxcQ6vyMhISfYxuuXLl+uWW25RcHCwBg8erNdff93h/OLiYt14440KDg7WFVdcoXvvvVenTp1yWLNy5UqNHDlSgYGBslqtWrhwocPnJ0+e1A9+8AOFhIRo6NChevPNN829aACA29E4AQD6lF//+te67bbbtHv3bs2ZM0d33HGHSkpKJEmNjY2aOnWqIiMjtXPnTq1du1YffPCBQ2O0fPlyLViwQPfee6+Ki4v15ptvasiQIQ5/R25urm6//XZ9/vnnmj59uubMmaOamppevU4AQO+yGIZhuDsIAABcMW/ePL3yyisKCgpyOP7oo4/q0UcflcVi0X333afly5e3fXbNNdcoIyNDf/7zn/Xiiy/qV7/6lY4cOaJ+/fpJkt555x3NnDlTFRUVio2NVUJCgu655x797ne/6zAGi8Wixx57TI8//rgkezPWv39/vfvuu3zXCgD6ML7jBADwKjfccINDYyRJUVFRbX/Ozs52+Cw7O1tFRUWSpJKSEo0ePbqtaZKka6+9Vi0tLSotLZXFYlFFRYUmT57cZQzp6eltf+7Xr5/CwsJ0/Pjxnl4SAMAL0DgBALxKv3792o3OXSrBwcEurfP393d4b7FY1NLSYkZIAAAPwXecAAB9yqefftru/YgRIyRJI0aM0O7du9XY2Nj2+bZt2+Tj46PU1FSFhoYqJSVFmzZt6tWYAQCejztOAACv0tzcrKqqKodjfn5+io6OliStXbtWmZmZuu666/Tqq6/qs88+01/+8hdJ0pw5c7R06VLl5ORo2bJlOnHihB544AHNnTtXsbGxkqRly5bpvvvuU0xMjG655RbZbDZt27ZNDzzwQO9eKADAo9A4AQC8yoYNG2S1Wh2Opaam6osvvpBk3/FuzZo1+vnPfy6r1aq///3vSktLkySFhITovffe06JFi3T11VcrJCREt912m55++um2/1ZOTo6ampr0zDPP6KGHHlJ0dLR++MMf9t4FAgA8ErvqAQD6DIvFonXr1mnWrFnuDgUA0MfwHScAAAAAcILGCQAAAACc4DtOAIA+g+lzAIBZuOMEAAAAAE7QOAEAAACAEzROAAAAAOAEjRMAAAAAOEHjBAAAAABO0DgBAAAAgBM0TgAAAADgBI0TAAAAADjx/3P8v4dH9EdyAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Create a DataFrame with your data\n",
    "data = {\n",
    "    'Epoch': [1, 2, 3, 4, 5],\n",
    "    'Training Loss': [1.303400,0.935300,0.675900,0.485000,0.377500],\n",
    "    'Validation Loss': [1.258837,1.165385,1.198490,1.274215,1.487636]\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Plot the training and validation loss curves\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(df['Epoch'], df['Training Loss'], label='Training Loss', marker='o')\n",
    "plt.plot(df['Epoch'], df['Validation Loss'], label='Validation Loss', marker='o')\n",
    "\n",
    "# Add labels and legend\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training and Validation Loss Curves')\n",
    "plt.legend()\n",
    "\n",
    "# Show the plot\n",
    "plt.grid()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b6435be",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36fabad4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tor] *",
   "language": "python",
   "name": "conda-env-tor-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
